[
  {
    "objectID": "tutorials/index.html",
    "href": "tutorials/index.html",
    "title": "Tutorials",
    "section": "",
    "text": "Basic usage - Euclidean distance, Random 2D points.\nIncremental construction - Manhattan distance, Random 8D points.\nAutomatic hyperparameter optimization - Squared Euclidean distance Random 16D points.\nSolving single queries - Euclidean distance, Random points.\nParallel construction and search - Euclidean distance, Random 2D points."
  },
  {
    "objectID": "tutorials/parallel-construction-and-search.html",
    "href": "tutorials/parallel-construction-and-search.html",
    "title": "Parallel construction and parallel search",
    "section": "",
    "text": "by: Eric S. TÃ©llez\nusing SimilaritySearch\nSimilarity search on very large datasets and high-dimensional datasets require high computational resources. In this example we show how to arallelize both the construction and search to be able to handle this kind of databases.\ndim = 16\n1db = MatrixDatabase(randn(Float32, dim, 10^5))\n2queries = MatrixDatabase(randn(Float32, dim, 30))\n3dist = SqL2Distance()\n4ctx = SearchGraphContext(parallel_first_block=256, parallel_block=512)\n5G = SearchGraph(; dist, db)\n6index!(G, ctx)\n\n\n1\n\nA synthetic database of dimension 16 and \\(10^5\\) vectors.\n\n2\n\nA synthetic query set of \\(30\\) points.\n\n3\n\nThe distance function.\n\n4\n\nThe search context working with SearchGraph; a set of hyperparameters for the index.\n\n5\n\nThe index definition.\n\n6\n\nThe index construction.\nThe SearchGraph construction algorithm is incremental:\nThe parallel construction is made with index! or append_items!; for this matter these functions accept a parallel_block argument via the ctx context, that controls how many elements are inserted at once, i.e., looking for its nearest neighbors in parallel and connected also in parallel.\nAs in the sequential version, a minimum number of elements must exists to work, and therefore, the parallel_first_block argument can also be specified. By default, it is equal to parallel_block. The parallel_block argument should be set to at least the number of available threads, and perhaps multiplying it by a small constant is also a good approach.\nNote that you must not call push_item!, append_items!, or index! from several threads. The default algorithm will takes advantage of the available threads using a single call."
  },
  {
    "objectID": "tutorials/parallel-construction-and-search.html#searching",
    "href": "tutorials/parallel-construction-and-search.html#searching",
    "title": "Parallel construction and parallel search",
    "section": "Searching",
    "text": "Searching\nOnce the index is constructed, you can solve batches in parallel and also single queries. In contrast with append, these functions can be called in multithreading algorithms. However, you must pause the searching requests while perform insertions (parallel or sequential); mixing insertions and search produces an undefined behavior for search results.\n\nI, D = searchbatch(G, ctx, queries, 10)\n\nThreads.@threads for i in eachindex(queries)\n    p = search(G, ctx, queries[i], KnnResult(10))\n    res = p.res\n    \n    print(\"=== $i -- nearest neighbor:\")\n    println(res[1])\n    print(\"=== $i -- result set:\")\n    println(collect(res))\n    print(\"=== $i -- identifiers:\")\n    println(collect(IdView(res))) # do something with `res`\n    print(\"=== $i -- distances:\")\n    println(collect(DistView(res))) # do something with `res`\nend\n\n=== 10 -- nearest neighbor:=== 28 -- nearest neighbor:=== 2 -- nearest neighbor:=== 20 -- nearest neighbor:=== 17 -- nearest neighbor:=== 7 -- nearest neighbor:=== 18 -- nearest neighbor:=== 1 -- nearest neighbor:=== 23 -- nearest neighbor:=== 27 -- nearest neighbor:=== 6 -- nearest neighbor:=== 14 -- nearest neighbor:=== 5 -- nearest neighbor:=== 9 -- nearest neighbor:=== 26 -- nearest neighbor:=== 13 -- nearest neighbor:=== 12 -- nearest neighbor:=== 21 -- nearest neighbor:=== 30 -- nearest neighbor:=== 8 -- nearest neighbor:=== 22 -- nearest neighbor:=== 4 -- nearest neighbor:=== 11 -- nearest neighbor:=== 25 -- nearest neighbor:=== 3 -- nearest neighbor:=== 24 -- nearest neighbor:=== 15 -- nearest neighbor:=== 29 -- nearest neighbor:=== 16 -- nearest neighbor:IdWeight(=== 19 -- nearest neighbor:0x0000cc52, 3.147786f0)\n=== 28 -- result set:IdWeight(0x00008c42, 3.73225f0)\n=== 11 -- result set:IdWeight(0x0000fdc9, 7.146419f0)\n=== 30 -- result set:IdWeight(0x0000a5ea, 3.4980834f0)\n=== 21 -- result set:IdWeight(0x000032dc, 6.4164953f0)\nIdWeight=== 23 -- result set:(0x00005937, 5.0722613f0)\n=== 16 -- result set:IdWeight(0x0001721f, 4.7959347f0)\n=== 15 -- result set:IdWeight(0x0000360e, 4.4203563f0)\n=== 2 -- result set:IdWeight(0x0000e627, 6.152143f0)\n=== 6 -- result set:IdWeight(0x0000ff34, 4.4726005f0)\n=== 24 -- result set:IdWeight(0x00009977, 5.0267553f0)\n=== 9 -- result set:IdWeight(0x0001811c, 2.3141243f0)\n=== 18 -- result set:IdWeight(0x00004656, 3.9603493f0)\n=== 5 -- result set:IdWeight(0x0000f15c, 9.193828f0)\n=== 22 -- result set:IdWeight(0x000154b1, 6.0533586f0)\n=== 25 -- result set:IdWeight(0x0000ab7f, 8.899307f0)\n=== 12 -- result set:IdWeight(0x00001ec8, 1.965283f0)\n=== 20 -- result set:IdWeight(0x0000185f, 2.4382908f0)\n=== 7 -- result set:IdWeight(0x000045be, 3.8189826f0)\n=== 14 -- result set:IdWeight(0x00014cf6, 7.2126055f0)\n=== 13 -- result set:IdWeight(0x0001530e, 2.573769f0)\nIdWeight=== 10 -- result set:(0x00007a19, 4.03551f0)\n=== 1 -- result set:IdWeight(0x00000244, 5.2145047f0)\n=== 29 -- result set:IdWeight(0x00013026, 5.390626f0)\n=== 27 -- result set:IdWeight(0x000119ac, 3.4117002f0)\n=== 4 -- result set:IdWeight(0x000032e8, 4.0888176f0)\n=== 3 -- result set:IdWeight(0x00017acd, 5.726545f0)\n=== 26 -- result set:IdWeight(0x000107b8, 3.0218663f0)\n=== 8 -- result set:IdWeight(0x0000b7e4, 4.274204f0)\n=== 19 -- result set:IdWeight(0x0000bdac, 5.2745876f0)\n=== 17 -- result set:IdWeight[IdWeight(0x0000cc52, 3.147786f0), IdWeight(0x00003555, 3.8929074f0), IdWeight(0x00012d38, 3.9253385f0), IdWeight(0x0001530e, 4.091182f0), IdWeight(0x0000f314, 4.1683755f0), IdWeight(0x00012521, 4.2477016f0), IdWeight(0x00007ca5, 4.304034f0), IdWeight(0x0000b459, 4.316153f0), IdWeight(0x00000e1f, 4.3633614f0), IdWeight(0x0000270f, 4.44652f0)]\n=== 28 -- identifiers:IdWeight[IdWeight(0x0001530e, 2.573769f0), IdWeight(0x000005b8, 2.7496862f0), IdWeight(0x0000fb7d, 2.9666526f0), IdWeight(0x0000247f, 2.9732895f0), IdWeight(0x0000bf33, 3.5768433f0), IdWeight(0x00005628, 3.6061654f0), IdWeight(0x00005888, 3.6454985f0), IdWeight(0x00015dda, 3.6685057f0), IdWeight(0x0000e7a5, 3.806617f0), IdWeight(0x00012b06, 3.8794928f0)]\n=== 10 -- identifiers:IdWeight[IdWeight(0x00005937, 5.0722613f0), IdWeight(0x0001544f, 5.463666f0), IdWeight(0x00003327, 5.9964733f0), IdWeight(0x00005cd9, 6.0189514f0), IdWeight(0x0000add5, 6.035078f0), IdWeight(0x000148e3, 6.17049f0), IdWeight(0x00013daa, 6.3066783f0), IdWeight(0x00008aee, 6.3714485f0), IdWeight(0x000036cc, 6.4586406f0), IdWeight(0x00004abe, 6.4766154f0)]\n=== 16 -- identifiers:IdWeight[IdWeight(0x0000ff34, 4.4726005f0), IdWeight(0x00006f53, 4.785658f0), IdWeight(0x00004873, 4.9192986f0), IdWeight(0x00008e93, 4.934017f0), IdWeight(0x000119f8, 4.9390864f0), IdWeight(0x0000f058, 5.2061806f0), IdWeight(0x00013853, 5.334557f0), IdWeight(0x00009d59, 5.581282f0), IdWeight(0x00015466, 5.709755f0), IdWeight(0x00013d8b, 5.716966f0)]\n=== 24 -- identifiers:IdWeight[IdWeight(0x00013026, 5.390626f0), IdWeight(0x00003c92, 7.403925f0), IdWeight(0x000044bf, 7.4913073f0), IdWeight(0x00008ff0, 7.5654616f0), IdWeight(0x000038d9, 8.156989f0), IdWeight(0x00014374, 8.321898f0), IdWeight(0x000105b2, 8.891943f0), IdWeight(0x00009deb, 9.014965f0), IdWeight(0x00015dde, 9.17036f0), IdWeight(0x0001370f, 9.404676f0)]\n=== 27 -- identifiers:IdWeight[IdWeight(0x0000360e, 4.4203563f0), IdWeight(0x0001561c, 4.6113424f0), IdWeight(0x00015058, 5.004443f0), IdWeight(0x0000bbd1, 5.0229335f0), IdWeight(0x00006031, 5.2730675f0), IdWeight(0x00003bd0, 5.3338995f0), IdWeight(0x00010de5, 5.357499f0), IdWeight(0x00008ce2, 5.410845f0), IdWeight(0x00017c95, 5.579874f0), IdWeight(0x0000a937, 5.610617f0)]\n=== 2 -- identifiers:IdWeight[IdWeight(0x0000fdc9, 7.146419f0), IdWeight(0x000099c6, 7.6548395f0), IdWeight(0x0000a6fc, 7.6628113f0), IdWeight(0x00017fcc, 7.7666984f0), IdWeight(0x00014151, 8.21031f0), IdWeight(0x0000256a, 8.259998f0), IdWeight(0x0000ca8c, 8.2795315f0), IdWeight(0x00013b4f, 8.29027f0), IdWeight(0x000123d6, 8.521764f0), IdWeight(0x00013812, 8.537868f0)]\n=== 30 -- identifiers:IdWeight[IdWeight(0x0000ab7f, 8.899307f0), IdWeight(0x000006a1, 9.490221f0), IdWeight(0x0000b57d, 9.776374f0), IdWeight(0x000069f0, 9.888553f0), IdWeight(0x0000c66e, 10.09094f0), IdWeight(0x0000ab2d, 11.118255f0), IdWeight(0x0000dff5, 11.204079f0), IdWeight(0x0000b247, 11.3221035f0), IdWeight(0x00001d2d, 11.578979f0), IdWeight(0x0000ccfe, 11.599606f0)]\n=== 12 -- identifiers:IdWeight[IdWeight(0x000032e8, 4.0888176f0), IdWeight(0x000133d3, 5.198706f0), IdWeight(0x000065aa, 5.2775083f0), IdWeight(0x00016970, 5.346553f0), IdWeight(0x00008ae2, 5.5973034f0), IdWeight(0x0001560a, 5.8229513f0), IdWeight(0x0000f95b, 5.866308f0), IdWeight(0x00007f4a, 5.952819f0), IdWeight(0x00001acc, 6.023663f0), IdWeight(0x0000797d, 6.0717235f0)]\n=== 3 -- identifiers:IdWeight[IdWeight(0x000032dc, 6.4164953f0), IdWeight(0x00009ae3, 6.776382f0), IdWeight(0x0000f9f8, 7.134707f0), IdWeight(0x0000def2, 8.10099f0), IdWeight(0x0000f97c, 8.182668f0), IdWeight(0x000135de, 8.228857f0), IdWeight(0x0000304d, 8.349739f0), IdWeight(0x000168a3, 8.477403f0), IdWeight(0x00016c4e, 8.622601f0), IdWeight(0x00013fbf, 8.879154f0)]\n=== 23 -- identifiers:IdWeight[IdWeight(0x0000185f, 2.4382908f0), IdWeight(0x00005222, 3.1227078f0), IdWeight(0x00011262, 3.8674657f0), IdWeight(0x00014848, 4.3323894f0), IdWeight(0x0000c82c, 4.82807f0), IdWeight(0x0000e664, 4.8599615f0), IdWeight(0x0000c914, 4.863696f0), IdWeight(0x0000cff0, 4.9403586f0), IdWeight(0x000066bd, 5.116307f0), IdWeight(0x000129ff, 5.262404f0)]\n=== 7 -- identifiers:IdWeight[IdWeight(0x0000a5ea, 3.4980834f0), IdWeight(0x0001252d, 6.7795095f0), IdWeight(0x000108c2, 6.959316f0), IdWeight(0x00010b46, 7.244296f0), IdWeight(0x00011226, 7.2853017f0), IdWeight(0x0000e4a3, 7.8786387f0), IdWeight(0x000114ad, 7.9160266f0), IdWeight(0x0000fc49, 7.983876f0), IdWeight(0x000100f4, 8.027033f0), IdWeight(0x00005a97, 8.440343f0)]\n=== 21 -- identifiers:IdWeight[IdWeight(0x000107b8, 3.0218663f0), IdWeight(0x00009792, 3.4218574f0), IdWeight(0x0001229d, 3.9089339f0), IdWeight(0x00005a32, 4.108682f0), IdWeight(0x000109c8, 4.128976f0), IdWeight(0x0000467c, 4.132928f0), IdWeight(0x00011f13, 4.3134365f0), IdWeight(0x00003d97, 4.497098f0), IdWeight(0x0000ae90, 4.561669f0), IdWeight(0x00002c67, 4.636936f0)]\n=== 8 -- identifiers:IdWeight[IdWeight(0x00004656, 3.9603493f0), IdWeight(0x0000ad4a, 4.075366f0), IdWeight(0x000038fd, 4.349281f0), IdWeight(0x00011c35, 4.542161f0), IdWeight(0x0000e5c2, 4.568691f0), IdWeight(0x0000629f, 4.762635f0), IdWeight(0x000000b6, 4.8440332f0), IdWeight(0x0000d539, 4.878849f0), IdWeight(0x0000f050, 4.920123f0), IdWeight(0x0000aefa, 5.074725f0)]\n=== 5 -- identifiers:IdWeight[IdWeight(0x00008c42, 3.73225f0), IdWeight(0x0000d290, 3.8267496f0), IdWeight(0x0001852b, 3.8798156f0), IdWeight(0x00014835, 3.896295f0), IdWeight(0x00001f44, 4.2590437f0), IdWeight(0x0001244a, 4.3881903f0), IdWeight(0x000037a0, 4.4591255f0), IdWeight(0x0000da2a, 4.4796567f0), IdWeight(0x00004252, 4.479895f0), IdWeight(0x00006ebc, 4.492508f0)]\n=== 11 -- identifiers:IdWeight[IdWeight(0x00009977, 5.0267553f0), IdWeight(0x00007fcf, 5.943399f0), IdWeight(0x00007a8d, 6.225438f0), IdWeight(0x00002ea9, 6.6744537f0), IdWeight(0x0001213f, 6.7110944f0), IdWeight(0x00004f8b, 6.73041f0), IdWeight(0x0000334f, 6.7516375f0), IdWeight(0x000054df, 6.796702f0), IdWeight(0x00007db6, 6.9638524f0), IdWeight(0x00011e1b, 7.0452642f0)]\n=== 9 -- identifiers:IdWeight[IdWeight(0x00001ec8, 1.965283f0), IdWeight(0x000148eb, 3.1877782f0), IdWeight(0x00008b89, 3.249923f0), IdWeight(0x000030bb, 3.628541f0), IdWeight(0x0000ec85, 3.7055597f0), IdWeight(0x00005bcc, 3.825026f0), IdWeight(0x00001f9d, 3.8452713f0), IdWeight(0x000043b9, 3.8862011f0), IdWeight(0x0000c2e9, 3.9847722f0), IdWeight(0x00000b89, 4.0222106f0)]\n=== 20 -- identifiers:IdWeight[IdWeight(0x0001721f, 4.7959347f0), IdWeight(0x0001368a, 5.6685944f0), IdWeight(0x0000beec, 6.2683506f0), IdWeight(0x00017599, 6.2745705f0), IdWeight(0x000062f7, 6.390696f0), IdWeight(0x00002289, 6.768043f0), IdWeight(0x000042c6, 7.0031466f0), IdWeight(0x0000e1e5, 7.0897584f0), IdWeight(0x00005ee6, 7.268764f0), IdWeight(0x00000545, 7.3031964f0)]\n=== 15 -- identifiers:IdWeight[IdWeight(0x00007a19, 4.03551f0), IdWeight(0x000173ae, 5.223899f0), IdWeight(0x00016a15, 5.6033916f0), IdWeight(0x00008d80, 5.848182f0), IdWeight(0x00006fd3, 5.8650727f0), IdWeight(0x0000ae3a, 5.8921704f0), IdWeight(0x00015585, 6.045236f0), IdWeight(0x00012bf9, 6.055215f0), IdWeight(0x00007542, 6.064277f0), IdWeight(0x0000f419, 6.1185017f0)]\n=== 1 -- identifiers:IdWeight[IdWeight(0x0000f15c, 9.193828f0), IdWeight(0x0000f5e6, 10.864647f0), IdWeight(0x00016730, 11.26052f0), IdWeight(0x00008515, 11.285156f0), IdWeight(0x00010ba7, 11.50055f0), IdWeight(0x0000a040, 11.775035f0), IdWeight(0x00008aa2, 12.119754f0), IdWeight(0x00001263, 12.143553f0), IdWeight(0x00002c0b, 12.352108f0), IdWeight(0x00018037, 12.460969f0)]\n=== 22 -- identifiers:IdWeight[IdWeight(0x0000bdac, 5.2745876f0), IdWeight(0x00008d3c, 5.8291106f0), IdWeight(0x00001971, 6.4070086f0), IdWeight(0x00003e7d, 6.795627f0), IdWeight(0x00017462, 6.9853f0), IdWeight(0x000096e0, 7.147513f0), IdWeight(0x00002391, 7.184842f0), IdWeight(0x000001e5, 7.1906123f0), IdWeight(0x0000be8f, 7.2757754f0), IdWeight(0x0000eb41, 7.331565f0)]\n=== 17 -- identifiers:IdWeight[IdWeight(0x000154b1, 6.0533586f0), IdWeight(0x00014824, 6.298763f0), IdWeight(0x000055e8, 6.97188f0), IdWeight(0x00010f92, 7.1849685f0), IdWeight(0x0000f7f6, 7.2015147f0), IdWeight(0x000123c8, 7.3086305f0), IdWeight(0x000087ed, 7.4306865f0), IdWeight(0x0000fd0b, 7.9000106f0), IdWeight(0x00005278, 8.029214f0), IdWeight(0x0000fd84, 8.058967f0)]\n=== 25 -- identifiers:IdWeight[IdWeight(0x00014cf6, 7.2126055f0), IdWeight(0x0000e12d, 7.359127f0), IdWeight(0x000038ad, 7.4707f0), IdWeight(0x0000487b, 7.5330343f0), IdWeight(0x0001369f, 7.6445327f0), IdWeight(0x0000bf81, 7.768216f0), IdWeight(0x0000e1a6, 7.852289f0), IdWeight(0x00018147, 8.215154f0), IdWeight(0x00012922, 8.352378f0), IdWeight(0x00013215, 8.544362f0)]\n=== 13 -- identifiers:IdWeight[IdWeight(0x00017acd, 5.726545f0), IdWeight(0x0000d07e, 6.347835f0), IdWeight(0x00015cf8, 7.8558307f0), IdWeight(0x0000f5f5, 7.9286184f0), IdWeight(0x00017186, 8.059452f0), IdWeight(0x00013f0c, 8.47074f0), IdWeight(0x0001090f, 9.214812f0), IdWeight(0x00014edd, 9.29467f0), IdWeight(0x00001f9c, 9.351808f0), IdWeight(0x00008d1a, 9.368945f0)]\n=== 26 -- identifiers:IdWeight[IdWeight(0x0001811c, 2.3141243f0), IdWeight(0x00006e78, 3.7611763f0), IdWeight(0x0000a7d3, 4.263225f0), IdWeight(0x0001198d, 4.462967f0), IdWeight(0x00010da6, 4.561663f0), IdWeight(0x000152ba, 4.723583f0), IdWeight(0x0000a485, 4.8436794f0), IdWeight(0x000032d8, 4.932152f0), IdWeight(0x0000bbf3, 4.9954405f0), IdWeight(0x0000e6f3, 5.0165505f0)]\n=== 18 -- identifiers:IdWeight[IdWeight(0x000119ac, 3.4117002f0), IdWeight(0x000055e4, 4.9005895f0), IdWeight(0x0000724a, 5.4857664f0), IdWeight(0x00000ffa, 5.571561f0), IdWeight(0x000025c2, 5.8690004f0), IdWeight(0x0000efbb, 6.0611997f0), IdWeight(0x0000e326, 6.1128445f0), IdWeight(0x0000ff9a, 6.301587f0), IdWeight(0x00001884, 6.67636f0), IdWeight(0x00000ab0, 6.7609825f0)]\n=== 4 -- identifiers:IdWeight[IdWeight(0x000045be, 3.8189826f0), IdWeight(0x00007af0, 4.861901f0), IdWeight(0x0000fa7d, 5.2630305f0), IdWeight(0x000084fd, 5.529071f0), IdWeight(0x00012e44, 5.73982f0), IdWeight(0x00009ee8, 5.851315f0), IdWeight(0x00008507, 5.885683f0), IdWeight(0x00005f8f, 6.0396266f0), IdWeight(0x0000a821, 6.221147f0), IdWeight(0x0000e8bb, 6.2740703f0)]\n=== 14 -- identifiers:IdWeight[IdWeight(0x0000b7e4, 4.274204f0), IdWeight(0x0001317d, 5.2577176f0), IdWeight(0x0000ca09, 5.5245667f0), IdWeight(0x0000080a, 5.666194f0), IdWeight(0x0000232b, 5.9326954f0), IdWeight(0x0000c5c4, 6.423924f0), IdWeight(0x0000084e, 6.459067f0), IdWeight(0x00009ed5, 6.669644f0), IdWeight(0x000022cf, 6.8179555f0), IdWeight(0x0000586b, 6.8334846f0)]\n=== 19 -- identifiers:IdWeight[IdWeight(0x00000244, 5.2145047f0), IdWeight(0x00004d61, 5.333848f0), IdWeight(0x00003d45, 5.9869747f0), IdWeight(0x0001454b, 6.042752f0), IdWeight(0x0001643b, 6.0887012f0), IdWeight(0x00003759, 6.1249385f0), IdWeight(0x000008d5, 6.3808045f0), IdWeight(0x00006222, 6.4381137f0), IdWeight(0x00010788, 6.4861426f0), IdWeight(0x0001148a, 6.5507874f0)]\n=== 29 -- identifiers:UInt32[0x0000f15c, 0x0000f5e6, 0x00016730, 0x00008515, 0x00010ba7, 0x0000a040, 0x00008aa2, 0x00001263, 0x00002c0b, 0x00018037]\n=== 22 -- distances:UInt32[0x00014cf6, 0x0000e12d, 0x000038ad, 0x0000487b, 0x0001369f, 0x0000bf81, 0x0000e1a6, 0x00018147, 0x00012922, 0x00013215]\n=== 13 -- distances:UInt32[0x00000244, 0x00004d61, 0x00003d45, 0x0001454b, 0x0001643b, 0x00003759, 0x000008d5, 0x00006222, 0x00010788, 0x0001148a]\n=== 29 -- distances:UInt32[0x0000bdac, 0x00008d3c, 0x00001971, 0x00003e7d, 0x00017462, 0x000096e0, 0x00002391, 0x000001e5, 0x0000be8f, 0x0000eb41]\n=== 17 -- distances:UInt32[0x0000a5ea, 0x0001252d, 0x000108c2, 0x00010b46, 0x00011226, 0x0000e4a3, 0x000114ad, 0x0000fc49, 0x000100f4, 0x00005a97]\n=== 21 -- distances:UInt32[0x000032dc, 0x00009ae3, 0x0000f9f8, 0x0000def2, 0x0000f97c, 0x000135de, 0x0000304d, 0x000168a3, 0x00016c4e, 0x00013fbf]\n=== 23 -- distances:UInt32[0x0000ab7f, 0x000006a1, 0x0000b57d, 0x000069f0, 0x0000c66e, 0x0000ab2d, 0x0000dff5, 0x0000b247, 0x00001d2d, 0x0000ccfe]\n=== 12 -- distances:UInt32[0x0000fdc9, 0x000099c6, 0x0000a6fc, 0x00017fcc, 0x00014151, 0x0000256a, 0x0000ca8c, 0x00013b4f, 0x000123d6, 0x00013812]\n=== 30 -- distances:IdWeight[IdWeight(0x0000e627, 6.152143f0), IdWeight(0x0000dc76, 6.3324933f0), IdWeight(0x000066f0, 7.0652313f0), IdWeight(0x0000f1a7, 7.072897f0), IdWeight(0x0000b0c6, 7.1499515f0), IdWeight(0x00008fc4, 7.312863f0), IdWeight(0x00016096, 7.3377275f0), IdWeight(0x00013383, 7.443193f0), IdWeight(0x0001709e, 7.5871773f0), IdWeight(0x00004054, 7.606157f0)]\n=== 6 -- identifiers:UInt32[0x00007a19, 0x000173ae, 0x00016a15, 0x00008d80, 0x00006fd3, 0x0000ae3a, 0x00015585, 0x00012bf9, 0x00007542, 0x0000f419]\n=== 1 -- distances:UInt32[0x00005937, 0x0001544f, 0x00003327, 0x00005cd9, 0x0000add5, 0x000148e3, 0x00013daa, 0x00008aee, 0x000036cc, 0x00004abe]\n=== 16 -- distances:UInt32[0x0000e627, 0x0000dc76, 0x000066f0, 0x0000f1a7, 0x0000b0c6, 0x00008fc4, 0x00016096, 0x00013383, 0x0001709e, 0x00004054]\n=== 6 -- distances:UInt32[0x000107b8, 0x00009792, 0x0001229d, 0x00005a32, 0x000109c8, 0x0000467c, 0x00011f13, 0x00003d97, 0x0000ae90, 0x00002c67]\n=== 8 -- distances:UInt32[0x0001721f, 0x0001368a, 0x0000beec, 0x00017599, 0x000062f7, 0x00002289, 0x000042c6, 0x0000e1e5, 0x00005ee6, 0x00000545]\n=== 15 -- distances:UInt32[0x000154b1, 0x00014824, 0x000055e8, 0x00010f92, 0x0000f7f6, 0x000123c8, 0x000087ed, 0x0000fd0b, 0x00005278, 0x0000fd84]\n=== 25 -- distances:UInt32[0x0000ff34, 0x00006f53, 0x00004873, 0x00008e93, 0x000119f8, 0x0000f058, 0x00013853, 0x00009d59, 0x00015466, 0x00013d8b]\n=== 24 -- distances:UInt32[0x0001811c, 0x00006e78, 0x0000a7d3, 0x0001198d, 0x00010da6, 0x000152ba, 0x0000a485, 0x000032d8, 0x0000bbf3, 0x0000e6f3]\n=== 18 -- distances:UInt32[0x0000360e, 0x0001561c, 0x00015058, 0x0000bbd1, 0x00006031, 0x00003bd0, 0x00010de5, 0x00008ce2, 0x00017c95, 0x0000a937]\n=== 2 -- distances:UInt32[0x00013026, 0x00003c92, 0x000044bf, 0x00008ff0, 0x000038d9, 0x00014374, 0x000105b2, 0x00009deb, 0x00015dde, 0x0001370f]\n=== 27 -- distances:UInt32[0x000119ac, 0x000055e4, 0x0000724a, 0x00000ffa, 0x000025c2, 0x0000efbb, 0x0000e326, 0x0000ff9a, 0x00001884, 0x00000ab0]\n=== 4 -- distances:UInt32[0x0000185f, 0x00005222, 0x00011262, 0x00014848, 0x0000c82c, 0x0000e664, 0x0000c914, 0x0000cff0, 0x000066bd, 0x000129ff]\n=== 7 -- distances:UInt32[0x000032e8, 0x000133d3, 0x000065aa, 0x00016970, 0x00008ae2, 0x0001560a, 0x0000f95b, 0x00007f4a, 0x00001acc, 0x0000797d]\n=== 3 -- distances:UInt32[0x0000b7e4, 0x0001317d, 0x0000ca09, 0x0000080a, 0x0000232b, 0x0000c5c4, 0x0000084e, 0x00009ed5, 0x000022cf, 0x0000586b]\n=== 19 -- distances:UInt32[0x0001530e, 0x000005b8, 0x0000fb7d, 0x0000247f, 0x0000bf33, 0x00005628, 0x00005888, 0x00015dda, 0x0000e7a5, 0x00012b06]\n=== 10 -- distances:UInt32[0x00009977, 0x00007fcf, 0x00007a8d, 0x00002ea9, 0x0001213f, 0x00004f8b, 0x0000334f, 0x000054df, 0x00007db6, 0x00011e1b]\n=== 9 -- distances:UInt32[0x00001ec8, 0x000148eb, 0x00008b89, 0x000030bb, 0x0000ec85, 0x00005bcc, 0x00001f9d, 0x000043b9, 0x0000c2e9, 0x00000b89]\n=== 20 -- distances:UInt32[0x00017acd, 0x0000d07e, 0x00015cf8, 0x0000f5f5, 0x00017186, 0x00013f0c, 0x0001090f, 0x00014edd, 0x00001f9c, 0x00008d1a]\n=== 26 -- distances:UInt32[0x00004656, 0x0000ad4a, 0x000038fd, 0x00011c35, 0x0000e5c2, 0x0000629f, 0x000000b6, 0x0000d539, 0x0000f050, 0x0000aefa]\n=== 5 -- distances:UInt32[0x000045be, 0x00007af0, 0x0000fa7d, 0x000084fd, 0x00012e44, 0x00009ee8, 0x00008507, 0x00005f8f, 0x0000a821, 0x0000e8bb]\n=== 14 -- distances:Float32[7.146419, 7.6548395, 7.6628113, 7.7666984, 8.21031, 8.259998, 8.2795315, 8.29027, 8.521764, 8.537868]\nUInt32[0x0000cc52, 0x00003555, 0x00012d38, 0x0001530e, 0x0000f314, 0x00012521, 0x00007ca5, 0x0000b459, 0x00000e1f, 0x0000270f]\n=== 28 -- distances:Float32[2.3141243, 3.7611763, 4.263225, 4.462967, 4.561663, 4.723583, 4.8436794, 4.932152, 4.9954405, 5.0165505]\nFloat32[3.8189826, 4.861901, 5.2630305, 5.529071, 5.73982, 5.851315, 5.885683, 6.0396266, 6.221147, 6.2740703]\nFloat32[3.4117002, 4.9005895, 5.4857664, 5.571561, 5.8690004, 6.0611997, 6.1128445, 6.301587, 6.67636, 6.7609825]\nFloat32[2.573769, 2.7496862, 2.9666526, 2.9732895, 3.5768433, 3.6061654, 3.6454985, 3.6685057, 3.806617, 3.8794928]\nFloat32[8.899307, 9.490221, 9.776374, 9.888553, 10.09094, 11.118255, 11.204079, 11.3221035, 11.578979, 11.599606]\nFloat32[4.4726005, 4.785658, 4.9192986, 4.934017, 4.9390864, 5.2061806, 5.334557, 5.581282, 5.709755, 5.716966]\nFloat32[3.147786, 3.8929074, 3.9253385, 4.091182, 4.1683755, 4.2477016, 4.304034, 4.316153, 4.3633614, 4.44652]\nFloat32[1.965283, 3.1877782, 3.249923, 3.628541, 3.7055597, 3.825026, 3.8452713, 3.8862011, 3.9847722, 4.0222106]\nFloat32[5.2745876, 5.8291106, 6.4070086, 6.795627, 6.9853, 7.147513, 7.184842, 7.1906123, 7.2757754, 7.331565]\nFloat32[6.4164953, 6.776382, 7.134707, 8.10099, 8.182668, 8.228857, 8.349739, 8.477403, 8.622601, 8.879154]\nFloat32[4.274204, 5.2577176, 5.5245667, 5.666194, 5.9326954, 6.423924, 6.459067, 6.669644, 6.8179555, 6.8334846]\nFloat32[3.0218663, 3.4218574, 3.9089339, 4.108682, 4.128976, 4.132928, 4.3134365, 4.497098, 4.561669, 4.636936]\nFloat32[4.4203563, 4.6113424, 5.004443, 5.0229335, 5.2730675, 5.3338995, 5.357499, 5.410845, 5.579874, 5.610617]\nFloat32[4.03551, 5.223899, 5.6033916, 5.848182, 5.8650727, 5.8921704, 6.045236, 6.055215, 6.064277, 6.1185017]\nFloat32[6.152143, 6.3324933, 7.0652313, 7.072897, 7.1499515, 7.312863, 7.3377275, 7.443193, 7.5871773, 7.606157]\nFloat32[5.726545, 6.347835, 7.8558307, 7.9286184, 8.059452, 8.47074, 9.214812, 9.29467, 9.351808, 9.368945]\nFloat32[3.4980834, 6.7795095, 6.959316, 7.244296, 7.2853017, 7.8786387, 7.9160266, 7.983876, 8.027033, 8.440343]\nFloat32[5.0267553, 5.943399, 6.225438, 6.6744537, 6.7110944, 6.73041, 6.7516375, 6.796702, 6.9638524, 7.0452642]\nUInt32[0x00008c42, 0x0000d290, 0x0001852b, 0x00014835, 0x00001f44, 0x0001244a, 0x000037a0, 0x0000da2a, 0x00004252, 0x00006ebc]\n=== 11 -- distances:Float32[6.0533586, 6.298763, 6.97188, 7.1849685, 7.2015147, 7.3086305, 7.4306865, 7.9000106, 8.029214, 8.058967]\nFloat32[2.4382908, 3.1227078, 3.8674657, 4.3323894, 4.82807, 4.8599615, 4.863696, 4.9403586, 5.116307, 5.262404]\nFloat32[3.9603493, 4.075366, 4.349281, 4.542161, 4.568691, 4.762635, 4.8440332, 4.878849, 4.920123, 5.074725]\nFloat32[5.2145047, 5.333848, 5.9869747, 6.042752, 6.0887012, 6.1249385, 6.3808045, 6.4381137, 6.4861426, 6.5507874]\nFloat32[4.0888176, 5.198706, 5.2775083, 5.346553, 5.5973034, 5.8229513, 5.866308, 5.952819, 6.023663, 6.0717235]\nFloat32[5.390626, 7.403925, 7.4913073, 7.5654616, 8.156989, 8.321898, 8.891943, 9.014965, 9.17036, 9.404676]\nFloat32[9.193828, 10.864647, 11.26052, 11.285156, 11.50055, 11.775035, 12.119754, 12.143553, 12.352108, 12.460969]\nFloat32[5.0722613, 5.463666, 5.9964733, 6.0189514, 6.035078, 6.17049, 6.3066783, 6.3714485, 6.4586406, 6.4766154]\nFloat32[4.7959347, 5.6685944, 6.2683506, 6.2745705, 6.390696, 6.768043, 7.0031466, 7.0897584, 7.268764, 7.3031964]\nFloat32[7.2126055, 7.359127, 7.4707, 7.5330343, 7.6445327, 7.768216, 7.852289, 8.215154, 8.352378, 8.544362]\nFloat32[3.73225, 3.8267496, 3.8798156, 3.896295, 4.2590437, 4.3881903, 4.4591255, 4.4796567, 4.479895, 4.492508]"
  },
  {
    "objectID": "tutorials/parallel-construction-and-search.html#environment-and-dependencies",
    "href": "tutorials/parallel-construction-and-search.html#environment-and-dependencies",
    "title": "Parallel construction and parallel search",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.9\nCommit 5595d20a287 (2025-03-10 12:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 Ã Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_PROJECT = .\n  JULIA_NUM_THREADS = auto\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/sites/SimilaritySearchDemos/Project.toml`\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.7.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.0 `~/.julia/dev/InvertedFiles`\n  [682c06a0] JSON v0.21.4\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\nâ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.11\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.0 `~/.julia/dev/SimSearchManifoldLearning`\n  [053f045d] SimilaritySearch v0.12.0 `~/.julia/dev/SimilaritySearch`\nâ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.0 `~/.julia/dev/TextSearch`\nInfo Packages marked with â and â have new versions available. Those with â may be upgradable, but those with â are restricted by compatibility constraints from upgrading. To see why use `status --outdated`\nWarning The project dependencies or compat requirements have changed since the manifest was last resolved. It is recommended to `Pkg.resolve()` or consider `Pkg.update()` if necessary."
  },
  {
    "objectID": "tutorials/basic-usage.html",
    "href": "tutorials/basic-usage.html",
    "title": "Using the SimilaritySearch package",
    "section": "",
    "text": "by: Eric S. TÃ©llez\nusing SimilaritySearch, Markdown\nThis is a small tutorial showing a minimum example for working with SimilaritySearch it accepts several options that are let to defaults. While this should be enough for many purposes, you are invited to see the rest of the tutorials to take advantage of other features.\nMatrixDatabase is a required wrapper that tells SimilaritySearch how to access underlying objects since it can support different kinds of objects. In this setup, each column is an object and will be accessed through views using the MatrixDatabase. Since the backend doesnât support appends or pushes, the index can be seen as an static index.\nfunction synthetic_benchmark(n, m, dim)\n    db = MatrixDatabase(randn(Float32, dim, n))\n    queries = MatrixDatabase(randn(Float32, dim, m))\n    dist = SqL2Distance()\n    (; db, queries, dist)\nend\nit can use any distance function described in SimilaritySearch and Distances.jl, and in fact any SemiMetric as described in the later package. The index construction is made as follows\nB = synthetic_benchmark(3000, 50, 2)\nG = SearchGraph(; B.dist, B.db)\nctx = SearchGraphContext()\nindex!(G, ctx)\nthis will display a lot of information in the console, since as construction advances the hyperparameters of the index are adjusted. The default optimization try to get a recall of 0.9 which is a typical tradeoff between quality and speed. Once the index is created, the index can solve nearest neighbor queries\nk = 16\n1I, D = searchbatch(G, ctx, B.queries, k)\n\n\n1\n\nThe searchbatch functions takes a set of queries and solve them using the given index. I is a matrix of identifiers in db and D their corresponding distances."
  },
  {
    "objectID": "tutorials/basic-usage.html#visualizing-what-we-just-did",
    "href": "tutorials/basic-usage.html#visualizing-what-we-just-did",
    "title": "Using the SimilaritySearch package",
    "section": "Visualizing what we just did",
    "text": "Visualizing what we just did\n\nusing Plots\n\nscatter(B.db.matrix[1, :], B.db.matrix[2, :], size=(600, 600), color=:cyan, ma=0.3, a=0.3, ms=1, msw=0, label=\"\")\nfor c in eachcol(I)\n    R = B.db.matrix[:, c]\n    @views scatter!(R[1, :], R[2, :], m=:diamond, ma=0.3, a=0.3, color=:auto, ms=2, msw=0, label=\"\")\nend\n\n@views scatter!(B.queries.matrix[1, :], B.queries.matrix[2, :], color=:black, m=:star, ma=0.5, a=0.5, ms=4, msw=0, label=\"\")\n\nplot!()\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCyan points identify the dataset while starts are query points. The nearest neighbor points are colored automatically and can repeat, but they come quite close to query points, in dense areas they are even hidding them."
  },
  {
    "objectID": "tutorials/basic-usage.html#environment-and-dependencies",
    "href": "tutorials/basic-usage.html#environment-and-dependencies",
    "title": "Using the SimilaritySearch package",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.9\nCommit 5595d20a287 (2025-03-10 12:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 Ã Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_PROJECT = .\n  JULIA_NUM_THREADS = auto\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/sites/SimilaritySearchDemos/Project.toml`\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.7.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.0 `~/.julia/dev/InvertedFiles`\n  [682c06a0] JSON v0.21.4\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\nâ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.11\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.0 `~/.julia/dev/SimSearchManifoldLearning`\n  [053f045d] SimilaritySearch v0.12.0 `~/.julia/dev/SimilaritySearch`\nâ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.0 `~/.julia/dev/TextSearch`\nInfo Packages marked with â and â have new versions available. Those with â may be upgradable, but those with â are restricted by compatibility constraints from upgrading. To see why use `status --outdated`\nWarning The project dependencies or compat requirements have changed since the manifest was last resolved. It is recommended to `Pkg.resolve()` or consider `Pkg.update()` if necessary."
  },
  {
    "objectID": "tutorials/allknn.html",
    "href": "tutorials/allknn.html",
    "title": "Computing all \\(k\\) nearest neighbors",
    "section": "",
    "text": "by: Eric S. TÃ©llez"
  },
  {
    "objectID": "tutorials/allknn.html#introduction",
    "href": "tutorials/allknn.html#introduction",
    "title": "Computing all \\(k\\) nearest neighbors",
    "section": "Introduction",
    "text": "Introduction\nComputing the \\(k\\) nearest neighbors of a dataset (a.k.a. allknn) is a useful task to take knowledge of a given dataset. This is a fundamental problem for some clustering algorithms and non-linear dimensional reduction algorithms.\nGiven a metric database \\((X, dist)\\) and a relatively small \\(k\\) value, the goal is to compute \\(\\{ knn(x) \\mid x \\in X \\}\\) taking into account that each \\(x_i \\in X\\), and therefore, \\(x_i\\) should be removed from the \\(i\\)-th \\(knn\\) result set.\nSolving allknn fast and accuratelly is the goal of this example."
  },
  {
    "objectID": "tutorials/allknn.html#initializing-our-notebook",
    "href": "tutorials/allknn.html#initializing-our-notebook",
    "title": "Computing all \\(k\\) nearest neighbors",
    "section": "Initializing our notebook",
    "text": "Initializing our notebook\nThe first step is to load our basic packages\n\nusing SimilaritySearch, Markdown\n\nwe will use a synthetic dataset\n\nfunction synthetic_benchmark(n, dim)\n1    db = MatrixDatabase(randn(Float32, dim, n))\n2    dist = SqL2Distance()\n3    (; db, dist)\nend\n\n\n1\n\nGenerate \\(n\\) random vectors, of \\(dim\\) dimension. Note that we wrap the matrix as MatrixDatabase to let our index that this is a database; this is necessary since we typically can change the type of objects and distance functions to work.\n\n2\n\nThe squared Euclidean distance; it preserves the order than plain Euclidean distance, but it is faster.\n\n3\n\nReturns a named tuple with the dataset and the distance.\n\n\n\n\n\n1B = synthetic_benchmark(10^5, 16)\n2k = 8\n3etime = @elapsed eknns, edists = allknn(ExhaustiveSearch(; B.db, B.dist),  GenericContext(), k)\n\n\n1\n\nCreates a synthetic dataset of dimension \\(16\\) and \\(10^5\\) points.\n\n2\n\nDefines we will be fetching this number of neighbors.\n\n3\n\nCreates a gold standard for test and compare.\n\n\n\n\n\nG = SearchGraph(; B.dist, B.db)\n2ctx = SearchGraphContext()\n3itime = @elapsed index!(G, ctx)\n4atime = @elapsed knns, dists = allknn(G, ctx, k)\n\n\n2\n\nDefines the SearchGraph index; it does not indexes anything yet!\n\n3\n\nDefines a search context, it contains several hyperparameters that will be applied for the indexing process, default values just work for now.\n\n4\n\nThe actual indexing."
  },
  {
    "objectID": "tutorials/allknn.html#differences-between-allknng-k-and-searchbatchg-x-k",
    "href": "tutorials/allknn.html#differences-between-allknng-k-and-searchbatchg-x-k",
    "title": "Computing all \\(k\\) nearest neighbors",
    "section": "Differences between allknn(G, k) and searchbatch(G, X, k)",
    "text": "Differences between allknn(G, k) and searchbatch(G, X, k)\nWe can solve similarly with searchbatch but self-references should be removed later, and more important, allknn use special pivoting/boosting strategies that yields to faster searches.\n\nstime = @elapsed sknns, sdists = searchbatch(G, ctx, B.db, k)"
  },
  {
    "objectID": "tutorials/allknn.html#comparing-solutions",
    "href": "tutorials/allknn.html#comparing-solutions",
    "title": "Computing all \\(k\\) nearest neighbors",
    "section": "Comparing solutions",
    "text": "Comparing solutions\nWe can measure the quality of SearchGraph in its different modalities against the exhaustive search (exact) solution.\n\nallknn_recall = macrorecall(eknns, knns)\nsearch_recall = macrorecall(eknns, sknns)\n\n\n\nTimes:\n\nindexing: 5.571040759\n\nallknn with SearchGraph: 0.330264035\n\nsearchbatch with SearchGraph: 0.412170289\n\nallknn with Exhaustivesearch: 6.987462306\n\n\nThe search and recall tradeoff:\n\nallknn (SearchGraph): 0.8859225\n\nsearchbatch (SearchGraph): 0.89476875"
  },
  {
    "objectID": "tutorials/allknn.html#final-notes",
    "href": "tutorials/allknn.html#final-notes",
    "title": "Computing all \\(k\\) nearest neighbors",
    "section": "Final notes",
    "text": "Final notes\nExhaustive search will fetch the exact solution but it has a higher cost and this could be more notorious as datasetâs size increases."
  },
  {
    "objectID": "tutorials/allknn.html#environment-and-dependencies",
    "href": "tutorials/allknn.html#environment-and-dependencies",
    "title": "Computing all \\(k\\) nearest neighbors",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.9\nCommit 5595d20a287 (2025-03-10 12:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 Ã Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_PROJECT = .\n  JULIA_NUM_THREADS = auto\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/sites/SimilaritySearchDemos/Project.toml`\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.7.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.0 `~/.julia/dev/InvertedFiles`\n  [682c06a0] JSON v0.21.4\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\nâ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.11\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.0 `~/.julia/dev/SimSearchManifoldLearning`\n  [053f045d] SimilaritySearch v0.12.0 `~/.julia/dev/SimilaritySearch`\nâ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.0 `~/.julia/dev/TextSearch`\nInfo Packages marked with â and â have new versions available. Those with â may be upgradable, but those with â are restricted by compatibility constraints from upgrading. To see why use `status --outdated`\nWarning The project dependencies or compat requirements have changed since the manifest was last resolved. It is recommended to `Pkg.resolve()` or consider `Pkg.update()` if necessary."
  },
  {
    "objectID": "demos/using-manifoldlearning.html",
    "href": "demos/using-manifoldlearning.html",
    "title": "Using with ManifoldLearning",
    "section": "",
    "text": "by: Eric S. TÃ©llez\nThis demonstration is about using SimilaritySearch and ManifoldLearning methods through SimSearchManifoldLearning.\nusing SimilaritySearch, SimSearchManifoldLearning, ManifoldLearning, Primes, Plots, StatsPlots, StatsBase, LinearAlgebra, Markdown, Random"
  },
  {
    "objectID": "demos/using-manifoldlearning.html#scurve-example",
    "href": "demos/using-manifoldlearning.html#scurve-example",
    "title": "Using with ManifoldLearning",
    "section": "SCurve example",
    "text": "SCurve example\n\nX, L = ManifoldLearning.scurve(segments=5)\n\nscatter(X[1, :], X[2, :], X[3, :], color=L, alpha=0.5)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimilaritySearch support exact and approximate algorithms to solve k nearest neighbors. Also, it supports different metrics. For instance, let see how the selection of the distance function modifies the projection.\n\nManhattan distance (\\(L_1\\))\n\nlet Y = predict(fit(Isomap, X, nntype=ApproxManhattan))\n    scatter(Y[1,:], Y[2,:], color=L, alpha=0.5)\nend\n\ncomputing farthest point 1, dmax: Inf, imax: 96, n: 151\ncomputing farthest point 2, dmax: 6.4815764, imax: 59, n: 151\ncomputing farthest point 3, dmax: 3.7775562, imax: 42, n: 151\ncomputing farthest point 4, dmax: 3.6876507, imax: 134, n: 151\ncomputing farthest point 5, dmax: 2.8788354, imax: 1, n: 151\ncomputing farthest point 6, dmax: 2.827672, imax: 118, n: 151\ncomputing farthest point 7, dmax: 2.2148476, imax: 138, n: 151\ncomputing farthest point 8, dmax: 2.1992762, imax: 76, n: 151\ncomputing farthest point 9, dmax: 1.8798082, imax: 70, n: 151\ncomputing farthest point 10, dmax: 1.8291274, imax: 77, n: 151\ncomputing farthest point 11, dmax: 1.821475, imax: 142, n: 151\ncomputing farthest point 12, dmax: 1.8130635, imax: 54, n: 151\ncomputing farthest point 13, dmax: 1.6884601, imax: 146, n: 151\ncomputing farthest point 14, dmax: 1.5665245, imax: 64, n: 151\ncomputing farthest point 15, dmax: 1.5657225, imax: 62, n: 151\ncomputing farthest point 16, dmax: 1.4981971, imax: 120, n: 151\ncomputing farthest point 17, dmax: 1.298184, imax: 14, n: 151\ncomputing farthest point 18, dmax: 1.1735748, imax: 139, n: 151\ncomputing farthest point 19, dmax: 1.1516896, imax: 31, n: 151\ncomputing farthest point 20, dmax: 1.1513287, imax: 74, n: 151\ncomputing farthest point 21, dmax: 1.1139009, imax: 20, n: 151\ncomputing farthest point 22, dmax: 1.0868317, imax: 71, n: 151\ncomputing farthest point 23, dmax: 1.0529543, imax: 109, n: 151\ncomputing farthest point 24, dmax: 1.0007396, imax: 8, n: 151\ncomputing farthest point 25, dmax: 0.9856829, imax: 133, n: 151\ncomputing farthest point 26, dmax: 0.9292389, imax: 56, n: 151\ncomputing farthest point 27, dmax: 0.91858214, imax: 121, n: 151\ncomputing farthest point 28, dmax: 0.9137236, imax: 131, n: 151\ncomputing farthest point 29, dmax: 0.91299933, imax: 67, n: 151\ncomputing farthest point 30, dmax: 0.8915813, imax: 60, n: 151\ncomputing farthest point 31, dmax: 0.87109905, imax: 100, n: 151\ncomputing farthest point 32, dmax: 0.8609946, imax: 47, n: 151\ncomputing farthest point 33, dmax: 0.8479115, imax: 123, n: 151\ncomputing farthest point 34, dmax: 0.7896146, imax: 126, n: 151\ncomputing farthest point 35, dmax: 0.77026474, imax: 44, n: 151\ncomputing farthest point 36, dmax: 0.7690527, imax: 130, n: 151\n(n, m, k, length(A.centers), length(C)) = (513, 216, 36, 36, 35)\n[ Info: using 32 random queries from the dataset\ncomputing farthest point 1, dmax: Inf, imax: 16, n: 171\ncomputing farthest point 2, dmax: 6.6357927, imax: 157, n: 171\ncomputing farthest point 3, dmax: 3.5149958, imax: 145, n: 171\ncomputing farthest point 4, dmax: 3.4506536, imax: 35, n: 171\ncomputing farthest point 5, dmax: 3.0280118, imax: 19, n: 171\ncomputing farthest point 6, dmax: 2.764099, imax: 118, n: 171\ncomputing farthest point 7, dmax: 2.2019768, imax: 80, n: 171\ncomputing farthest point 8, dmax: 2.1902308, imax: 64, n: 171\ncomputing farthest point 9, dmax: 2.0294576, imax: 166, n: 171\ncomputing farthest point 10, dmax: 1.8646044, imax: 74, n: 171\ncomputing farthest point 11, dmax: 1.7397182, imax: 161, n: 171\ncomputing farthest point 12, dmax: 1.6922809, imax: 119, n: 171\ncomputing farthest point 13, dmax: 1.6456871, imax: 121, n: 171\ncomputing farthest point 14, dmax: 1.5794612, imax: 140, n: 171\ncomputing farthest point 15, dmax: 1.5725561, imax: 87, n: 171\ncomputing farthest point 16, dmax: 1.554947, imax: 133, n: 171\ncomputing farthest point 17, dmax: 1.5049617, imax: 135, n: 171\ncomputing farthest point 18, dmax: 1.4182429, imax: 127, n: 171\ncomputing farthest point 19, dmax: 1.1817534, imax: 125, n: 171\ncomputing farthest point 20, dmax: 1.1351885, imax: 24, n: 171\ncomputing farthest point 21, dmax: 1.0831147, imax: 26, n: 171\ncomputing farthest point 22, dmax: 1.060078, imax: 55, n: 171\ncomputing farthest point 23, dmax: 1.0029254, imax: 107, n: 171\ncomputing farthest point 24, dmax: 0.97840285, imax: 59, n: 171\ncomputing farthest point 25, dmax: 0.92496115, imax: 132, n: 171\ncomputing farthest point 26, dmax: 0.9096818, imax: 41, n: 171\ncomputing farthest point 27, dmax: 0.8986021, imax: 15, n: 171\ncomputing farthest point 28, dmax: 0.87275606, imax: 130, n: 171\ncomputing farthest point 29, dmax: 0.86477983, imax: 143, n: 171\ncomputing farthest point 30, dmax: 0.85448694, imax: 29, n: 171\ncomputing farthest point 31, dmax: 0.85155773, imax: 11, n: 171\ncomputing farthest point 32, dmax: 0.83031183, imax: 17, n: 171\ncomputing farthest point 33, dmax: 0.82695156, imax: 21, n: 171\ncomputing farthest point 34, dmax: 0.79188377, imax: 169, n: 171\ncomputing farthest point 35, dmax: 0.7839273, imax: 72, n: 171\ncomputing farthest point 36, dmax: 0.7634769, imax: 23, n: 171\ncomputing farthest point 37, dmax: 0.7541419, imax: 5, n: 171\ncomputing farthest point 38, dmax: 0.7516426, imax: 126, n: 171\n(n, m, k, length(A.centers), length(C)) = (770, 235, 38, 38, 35)\n[ Info: using 32 random queries from the dataset\ncomputing farthest point 1, dmax: Inf, imax: 71, n: 190\ncomputing farthest point 2, dmax: 5.9516253, imax: 190, n: 190\ncomputing farthest point 3, dmax: 3.8602846, imax: 89, n: 190\ncomputing farthest point 4, dmax: 3.189239, imax: 105, n: 190\ncomputing farthest point 5, dmax: 2.9530873, imax: 130, n: 190\ncomputing farthest point 6, dmax: 2.6075056, imax: 114, n: 190\ncomputing farthest point 7, dmax: 2.5113564, imax: 90, n: 190\ncomputing farthest point 8, dmax: 2.1342013, imax: 19, n: 190\ncomputing farthest point 9, dmax: 1.9597938, imax: 119, n: 190\ncomputing farthest point 10, dmax: 1.9294549, imax: 188, n: 190\ncomputing farthest point 11, dmax: 1.9261228, imax: 53, n: 190\ncomputing farthest point 12, dmax: 1.7190639, imax: 46, n: 190\ncomputing farthest point 13, dmax: 1.7091347, imax: 27, n: 190\ncomputing farthest point 14, dmax: 1.5771431, imax: 150, n: 190\ncomputing farthest point 15, dmax: 1.520996, imax: 126, n: 190\ncomputing farthest point 16, dmax: 1.5202605, imax: 152, n: 190\ncomputing farthest point 17, dmax: 1.3958374, imax: 148, n: 190\ncomputing farthest point 18, dmax: 1.3738395, imax: 142, n: 190\ncomputing farthest point 19, dmax: 1.329449, imax: 180, n: 190\ncomputing farthest point 20, dmax: 1.2969466, imax: 34, n: 190\ncomputing farthest point 21, dmax: 1.2365568, imax: 155, n: 190\ncomputing farthest point 22, dmax: 1.2278334, imax: 151, n: 190\ncomputing farthest point 23, dmax: 1.035477, imax: 78, n: 190\ncomputing farthest point 24, dmax: 1.035152, imax: 70, n: 190\ncomputing farthest point 25, dmax: 1.0262656, imax: 5, n: 190\ncomputing farthest point 26, dmax: 1.0194812, imax: 26, n: 190\ncomputing farthest point 27, dmax: 0.9963111, imax: 137, n: 190\ncomputing farthest point 28, dmax: 0.94353044, imax: 85, n: 190\ncomputing farthest point 29, dmax: 0.9319989, imax: 2, n: 190\ncomputing farthest point 30, dmax: 0.91654325, imax: 176, n: 190\ncomputing farthest point 31, dmax: 0.9005539, imax: 121, n: 190\ncomputing farthest point 32, dmax: 0.87736833, imax: 40, n: 190\ncomputing farthest point 33, dmax: 0.8668168, imax: 24, n: 190\ncomputing farthest point 34, dmax: 0.8614975, imax: 108, n: 190\ncomputing farthest point 35, dmax: 0.8532078, imax: 10, n: 190\ncomputing farthest point 36, dmax: 0.84512824, imax: 98, n: 190\ncomputing farthest point 37, dmax: 0.8420819, imax: 83, n: 190\ncomputing farthest point 38, dmax: 0.8304248, imax: 96, n: 190\ncomputing farthest point 39, dmax: 0.8107647, imax: 79, n: 190\n(n, m, k, length(A.centers), length(C)) = (1000, 244, 39, 39, 39)\n[ Info: using 32 random queries from the dataset\n[ Info: using 64 random queries from the dataset\n  0.169362 seconds (184.08 k allocations: 11.860 MiB, 99.74% compilation time)\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEuclidean distance (\\(L_2\\))\n\nlet\n    E = predict(fit(Isomap, X, nntype=ApproxEuclidean))\n    scatter(E[1,:], E[2,:], color=L, alpha=0.5)\nend\n\ncomputing farthest point 1, dmax: Inf, imax: 117, n: 138\ncomputing farthest point 2, dmax: 4.1425896, imax: 90, n: 138\ncomputing farthest point 3, dmax: 2.5274546, imax: 135, n: 138\ncomputing farthest point 4, dmax: 2.239619, imax: 4, n: 138\ncomputing farthest point 5, dmax: 2.035317, imax: 26, n: 138\ncomputing farthest point 6, dmax: 1.6278336, imax: 46, n: 138\ncomputing farthest point 7, dmax: 1.5676655, imax: 119, n: 138\ncomputing farthest point 8, dmax: 1.5228775, imax: 9, n: 138\ncomputing farthest point 9, dmax: 1.3680493, imax: 71, n: 138\ncomputing farthest point 10, dmax: 1.3396664, imax: 130, n: 138\ncomputing farthest point 11, dmax: 1.337497, imax: 40, n: 138\ncomputing farthest point 12, dmax: 1.1789955, imax: 122, n: 138\ncomputing farthest point 13, dmax: 1.1518054, imax: 54, n: 138\ncomputing farthest point 14, dmax: 1.0295967, imax: 31, n: 138\ncomputing farthest point 15, dmax: 1.0153332, imax: 105, n: 138\ncomputing farthest point 16, dmax: 0.9574775, imax: 2, n: 138\ncomputing farthest point 17, dmax: 0.8520343, imax: 59, n: 138\ncomputing farthest point 18, dmax: 0.83734083, imax: 56, n: 138\ncomputing farthest point 19, dmax: 0.7960204, imax: 44, n: 138\ncomputing farthest point 20, dmax: 0.7637263, imax: 138, n: 138\ncomputing farthest point 21, dmax: 0.74767727, imax: 10, n: 138\ncomputing farthest point 22, dmax: 0.74421304, imax: 97, n: 138\ncomputing farthest point 23, dmax: 0.7369598, imax: 126, n: 138\ncomputing farthest point 24, dmax: 0.70262325, imax: 78, n: 138\ncomputing farthest point 25, dmax: 0.7011923, imax: 16, n: 138\ncomputing farthest point 26, dmax: 0.68937325, imax: 72, n: 138\ncomputing farthest point 27, dmax: 0.6436881, imax: 43, n: 138\ncomputing farthest point 28, dmax: 0.6429, imax: 32, n: 138\ncomputing farthest point 29, dmax: 0.62799585, imax: 67, n: 138\ncomputing farthest point 30, dmax: 0.58220327, imax: 37, n: 138\ncomputing farthest point 31, dmax: 0.5617429, imax: 3, n: 138\ncomputing farthest point 32, dmax: 0.55807287, imax: 1, n: 138\ncomputing farthest point 33, dmax: 0.53651124, imax: 82, n: 138\ncomputing farthest point 34, dmax: 0.5317145, imax: 134, n: 138\ncomputing farthest point 35, dmax: 0.527738, imax: 12, n: 138\ncomputing farthest point 36, dmax: 0.52656966, imax: 27, n: 138\n(n, m, k, length(A.centers), length(C)) = (513, 216, 36, 36, 34)\n[ Info: using 32 random queries from the dataset\ncomputing farthest point 1, dmax: Inf, imax: 121, n: 176\ncomputing farthest point 2, dmax: 3.8449655, imax: 169, n: 176\ncomputing farthest point 3, dmax: 2.3766565, imax: 93, n: 176\ncomputing farthest point 4, dmax: 2.3454819, imax: 94, n: 176\ncomputing farthest point 5, dmax: 2.0097914, imax: 126, n: 176\ncomputing farthest point 6, dmax: 1.890813, imax: 3, n: 176\ncomputing farthest point 7, dmax: 1.7368457, imax: 174, n: 176\ncomputing farthest point 8, dmax: 1.547874, imax: 76, n: 176\ncomputing farthest point 9, dmax: 1.4191817, imax: 74, n: 176\ncomputing farthest point 10, dmax: 1.3250549, imax: 50, n: 176\ncomputing farthest point 11, dmax: 1.3219174, imax: 120, n: 176\ncomputing farthest point 12, dmax: 1.3098271, imax: 138, n: 176\ncomputing farthest point 13, dmax: 1.1843822, imax: 28, n: 176\ncomputing farthest point 14, dmax: 1.084917, imax: 1, n: 176\ncomputing farthest point 15, dmax: 0.9687573, imax: 82, n: 176\ncomputing farthest point 16, dmax: 0.92400616, imax: 37, n: 176\ncomputing farthest point 17, dmax: 0.9118212, imax: 18, n: 176\ncomputing farthest point 18, dmax: 0.91006786, imax: 153, n: 176\ncomputing farthest point 19, dmax: 0.8907045, imax: 92, n: 176\ncomputing farthest point 20, dmax: 0.83341306, imax: 69, n: 176\ncomputing farthest point 21, dmax: 0.8202981, imax: 39, n: 176\ncomputing farthest point 22, dmax: 0.7895275, imax: 53, n: 176\ncomputing farthest point 23, dmax: 0.7403018, imax: 150, n: 176\ncomputing farthest point 24, dmax: 0.69786656, imax: 149, n: 176\ncomputing farthest point 25, dmax: 0.69100857, imax: 141, n: 176\ncomputing farthest point 26, dmax: 0.66545665, imax: 162, n: 176\ncomputing farthest point 27, dmax: 0.64106596, imax: 104, n: 176\ncomputing farthest point 28, dmax: 0.63428867, imax: 32, n: 176\ncomputing farthest point 29, dmax: 0.63163686, imax: 75, n: 176\ncomputing farthest point 30, dmax: 0.6169325, imax: 81, n: 176\ncomputing farthest point 31, dmax: 0.6033342, imax: 85, n: 176\ncomputing farthest point 32, dmax: 0.6015613, imax: 36, n: 176\ncomputing farthest point 33, dmax: 0.5932891, imax: 163, n: 176\ncomputing farthest point 34, dmax: 0.57040304, imax: 156, n: 176\ncomputing farthest point 35, dmax: 0.55089587, imax: 103, n: 176\ncomputing farthest point 36, dmax: 0.54709905, imax: 90, n: 176\ncomputing farthest point 37, dmax: 0.5306709, imax: 68, n: 176\ncomputing farthest point 38, dmax: 0.51280135, imax: 61, n: 176\n(n, m, k, length(A.centers), length(C)) = (770, 235, 38, 38, 34)\n[ Info: using 32 random queries from the dataset\ncomputing farthest point 1, dmax: Inf, imax: 99, n: 177\ncomputing farthest point 2, dmax: 3.7977564, imax: 92, n: 177\ncomputing farthest point 3, dmax: 2.4443223, imax: 157, n: 177\ncomputing farthest point 4, dmax: 2.0950882, imax: 1, n: 177\ncomputing farthest point 5, dmax: 1.9893839, imax: 42, n: 177\ncomputing farthest point 6, dmax: 1.896083, imax: 48, n: 177\ncomputing farthest point 7, dmax: 1.679585, imax: 10, n: 177\ncomputing farthest point 8, dmax: 1.606552, imax: 155, n: 177\ncomputing farthest point 9, dmax: 1.4612445, imax: 80, n: 177\ncomputing farthest point 10, dmax: 1.388588, imax: 56, n: 177\ncomputing farthest point 11, dmax: 1.32155, imax: 46, n: 177\ncomputing farthest point 12, dmax: 1.2887776, imax: 31, n: 177\ncomputing farthest point 13, dmax: 1.0957654, imax: 149, n: 177\ncomputing farthest point 14, dmax: 1.0392711, imax: 101, n: 177\ncomputing farthest point 15, dmax: 0.94109523, imax: 51, n: 177\ncomputing farthest point 16, dmax: 0.9397371, imax: 166, n: 177\ncomputing farthest point 17, dmax: 0.938444, imax: 13, n: 177\ncomputing farthest point 18, dmax: 0.9064559, imax: 62, n: 177\ncomputing farthest point 19, dmax: 0.8884273, imax: 172, n: 177\ncomputing farthest point 20, dmax: 0.8750033, imax: 134, n: 177\ncomputing farthest point 21, dmax: 0.8709786, imax: 144, n: 177\ncomputing farthest point 22, dmax: 0.7474438, imax: 60, n: 177\ncomputing farthest point 23, dmax: 0.74179775, imax: 41, n: 177\ncomputing farthest point 24, dmax: 0.694397, imax: 8, n: 177\ncomputing farthest point 25, dmax: 0.6777665, imax: 49, n: 177\ncomputing farthest point 26, dmax: 0.657751, imax: 93, n: 177\ncomputing farthest point 27, dmax: 0.6513499, imax: 28, n: 177\ncomputing farthest point 28, dmax: 0.6434744, imax: 140, n: 177\ncomputing farthest point 29, dmax: 0.6352616, imax: 15, n: 177\ncomputing farthest point 30, dmax: 0.62252784, imax: 159, n: 177\ncomputing farthest point 31, dmax: 0.59175026, imax: 126, n: 177\ncomputing farthest point 32, dmax: 0.5835448, imax: 63, n: 177\ncomputing farthest point 33, dmax: 0.577759, imax: 85, n: 177\ncomputing farthest point 34, dmax: 0.5522087, imax: 163, n: 177\ncomputing farthest point 35, dmax: 0.5495788, imax: 77, n: 177\ncomputing farthest point 36, dmax: 0.53022146, imax: 164, n: 177\ncomputing farthest point 37, dmax: 0.5224308, imax: 88, n: 177\ncomputing farthest point 38, dmax: 0.52156776, imax: 127, n: 177\ncomputing farthest point 39, dmax: 0.52063847, imax: 118, n: 177\n(n, m, k, length(A.centers), length(C)) = (1000, 244, 39, 39, 37)\n[ Info: using 32 random queries from the dataset\n[ Info: using 64 random queries from the dataset\n  0.146248 seconds (176.19 k allocations: 11.329 MiB, 99.66% compilation time)\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChebyshev distance (\\(L_\\infty\\))\n\nlet\n    Ch = predict(fit(Isomap, X, nntype=ApproxChebyshev))\n    scatter(Ch[1,:], Ch[2,:], color=L, alpha=0.5)\nend\n\ncomputing farthest point 1, dmax: Inf, imax: 109, n: 147\ncomputing farthest point 2, dmax: 2.0592954, imax: 86, n: 147\ncomputing farthest point 3, dmax: 2.0267496, imax: 32, n: 147\ncomputing farthest point 4, dmax: 1.8228779, imax: 119, n: 147\ncomputing farthest point 5, dmax: 1.6579559, imax: 78, n: 147\ncomputing farthest point 6, dmax: 1.242166, imax: 75, n: 147\ncomputing farthest point 7, dmax: 1.2040324, imax: 144, n: 147\ncomputing farthest point 8, dmax: 1.1887678, imax: 116, n: 147\ncomputing farthest point 9, dmax: 1.0686975, imax: 23, n: 147\ncomputing farthest point 10, dmax: 1.0490083, imax: 22, n: 147\ncomputing farthest point 11, dmax: 0.990714, imax: 77, n: 147\ncomputing farthest point 12, dmax: 0.94364536, imax: 46, n: 147\ncomputing farthest point 13, dmax: 0.9334425, imax: 103, n: 147\ncomputing farthest point 14, dmax: 0.87672466, imax: 35, n: 147\ncomputing farthest point 15, dmax: 0.85096467, imax: 76, n: 147\ncomputing farthest point 16, dmax: 0.810649, imax: 14, n: 147\ncomputing farthest point 17, dmax: 0.8022182, imax: 2, n: 147\ncomputing farthest point 18, dmax: 0.7974361, imax: 72, n: 147\ncomputing farthest point 19, dmax: 0.78190833, imax: 108, n: 147\ncomputing farthest point 20, dmax: 0.6514583, imax: 97, n: 147\ncomputing farthest point 21, dmax: 0.6378781, imax: 36, n: 147\ncomputing farthest point 22, dmax: 0.6164605, imax: 20, n: 147\ncomputing farthest point 23, dmax: 0.5920692, imax: 50, n: 147\ncomputing farthest point 24, dmax: 0.5864584, imax: 122, n: 147\ncomputing farthest point 25, dmax: 0.5807377, imax: 66, n: 147\ncomputing farthest point 26, dmax: 0.57479703, imax: 37, n: 147\ncomputing farthest point 27, dmax: 0.56674296, imax: 49, n: 147\ncomputing farthest point 28, dmax: 0.5630297, imax: 91, n: 147\ncomputing farthest point 29, dmax: 0.56120694, imax: 95, n: 147\ncomputing farthest point 30, dmax: 0.533759, imax: 131, n: 147\ncomputing farthest point 31, dmax: 0.5309487, imax: 146, n: 147\ncomputing farthest point 32, dmax: 0.50763273, imax: 94, n: 147\ncomputing farthest point 33, dmax: 0.5060431, imax: 29, n: 147\ncomputing farthest point 34, dmax: 0.5027335, imax: 124, n: 147\ncomputing farthest point 35, dmax: 0.49866754, imax: 145, n: 147\ncomputing farthest point 36, dmax: 0.47019696, imax: 89, n: 147\n(n, m, k, length(A.centers), length(C)) = (513, 216, 36, 36, 33)\n[ Info: using 32 random queries from the dataset\ncomputing farthest point 1, dmax: Inf, imax: 124, n: 182\ncomputing farthest point 2, dmax: 2.6320806, imax: 24, n: 182\ncomputing farthest point 3, dmax: 1.9669185, imax: 107, n: 182\ncomputing farthest point 4, dmax: 1.8882048, imax: 12, n: 182\ncomputing farthest point 5, dmax: 1.7510226, imax: 129, n: 182\ncomputing farthest point 6, dmax: 1.7408992, imax: 28, n: 182\ncomputing farthest point 7, dmax: 1.5173838, imax: 36, n: 182\ncomputing farthest point 8, dmax: 1.417304, imax: 122, n: 182\ncomputing farthest point 9, dmax: 1.2035195, imax: 35, n: 182\ncomputing farthest point 10, dmax: 1.1324997, imax: 176, n: 182\ncomputing farthest point 11, dmax: 1.011772, imax: 37, n: 182\ncomputing farthest point 12, dmax: 1.0057926, imax: 59, n: 182\ncomputing farthest point 13, dmax: 0.9691602, imax: 71, n: 182\ncomputing farthest point 14, dmax: 0.8691029, imax: 44, n: 182\ncomputing farthest point 15, dmax: 0.85914814, imax: 178, n: 182\ncomputing farthest point 16, dmax: 0.83548206, imax: 150, n: 182\ncomputing farthest point 17, dmax: 0.80270517, imax: 27, n: 182\ncomputing farthest point 18, dmax: 0.7984557, imax: 8, n: 182\ncomputing farthest point 19, dmax: 0.79420024, imax: 3, n: 182\ncomputing farthest point 20, dmax: 0.7545633, imax: 162, n: 182\ncomputing farthest point 21, dmax: 0.7181568, imax: 47, n: 182\ncomputing farthest point 22, dmax: 0.70810777, imax: 38, n: 182\ncomputing farthest point 23, dmax: 0.70375633, imax: 105, n: 182\ncomputing farthest point 24, dmax: 0.6457773, imax: 174, n: 182\ncomputing farthest point 25, dmax: 0.6396458, imax: 110, n: 182\ncomputing farthest point 26, dmax: 0.5982415, imax: 1, n: 182\ncomputing farthest point 27, dmax: 0.59306324, imax: 19, n: 182\ncomputing farthest point 28, dmax: 0.5705263, imax: 159, n: 182\ncomputing farthest point 29, dmax: 0.5619547, imax: 167, n: 182\ncomputing farthest point 30, dmax: 0.5384188, imax: 125, n: 182\ncomputing farthest point 31, dmax: 0.535576, imax: 103, n: 182\ncomputing farthest point 32, dmax: 0.5354215, imax: 78, n: 182\ncomputing farthest point 33, dmax: 0.51772684, imax: 84, n: 182\ncomputing farthest point 34, dmax: 0.5082254, imax: 40, n: 182\ncomputing farthest point 35, dmax: 0.5001392, imax: 79, n: 182\ncomputing farthest point 36, dmax: 0.47708392, imax: 21, n: 182\ncomputing farthest point 37, dmax: 0.47685316, imax: 170, n: 182\ncomputing farthest point 38, dmax: 0.47213078, imax: 113, n: 182\n(n, m, k, length(A.centers), length(C)) = (770, 235, 38, 38, 36)\n[ Info: using 32 random queries from the dataset\ncomputing farthest point 1, dmax: Inf, imax: 55, n: 178\ncomputing farthest point 2, dmax: 3.8017182, imax: 107, n: 178\ncomputing farthest point 3, dmax: 1.8827873, imax: 154, n: 178\ncomputing farthest point 4, dmax: 1.6836039, imax: 127, n: 178\ncomputing farthest point 5, dmax: 1.5347333, imax: 175, n: 178\ncomputing farthest point 6, dmax: 1.3791317, imax: 118, n: 178\ncomputing farthest point 7, dmax: 1.3059524, imax: 25, n: 178\ncomputing farthest point 8, dmax: 1.1442869, imax: 83, n: 178\ncomputing farthest point 9, dmax: 1.1108489, imax: 14, n: 178\ncomputing farthest point 10, dmax: 1.0559151, imax: 39, n: 178\ncomputing farthest point 11, dmax: 0.9808544, imax: 27, n: 178\ncomputing farthest point 12, dmax: 0.93980765, imax: 16, n: 178\ncomputing farthest point 13, dmax: 0.9120856, imax: 51, n: 178\ncomputing farthest point 14, dmax: 0.89796114, imax: 20, n: 178\ncomputing farthest point 15, dmax: 0.8954327, imax: 67, n: 178\ncomputing farthest point 16, dmax: 0.8116172, imax: 146, n: 178\ncomputing farthest point 17, dmax: 0.80299973, imax: 141, n: 178\ncomputing farthest point 18, dmax: 0.7782076, imax: 142, n: 178\ncomputing farthest point 19, dmax: 0.7219002, imax: 4, n: 178\ncomputing farthest point 20, dmax: 0.72039366, imax: 78, n: 178\ncomputing farthest point 21, dmax: 0.6826009, imax: 97, n: 178\ncomputing farthest point 22, dmax: 0.6755668, imax: 131, n: 178\ncomputing farthest point 23, dmax: 0.6506037, imax: 30, n: 178\ncomputing farthest point 24, dmax: 0.62571114, imax: 2, n: 178\ncomputing farthest point 25, dmax: 0.59119534, imax: 82, n: 178\ncomputing farthest point 26, dmax: 0.57215273, imax: 161, n: 178\ncomputing farthest point 27, dmax: 0.5603994, imax: 133, n: 178\ncomputing farthest point 28, dmax: 0.5331801, imax: 36, n: 178\ncomputing farthest point 29, dmax: 0.4808414, imax: 43, n: 178\ncomputing farthest point 30, dmax: 0.47145605, imax: 81, n: 178\ncomputing farthest point 31, dmax: 0.471171, imax: 130, n: 178\ncomputing farthest point 32, dmax: 0.47098243, imax: 28, n: 178\ncomputing farthest point 33, dmax: 0.46978936, imax: 145, n: 178\ncomputing farthest point 34, dmax: 0.46924174, imax: 114, n: 178\ncomputing farthest point 35, dmax: 0.46536797, imax: 7, n: 178\ncomputing farthest point 36, dmax: 0.45560244, imax: 177, n: 178\ncomputing farthest point 37, dmax: 0.4534478, imax: 87, n: 178\ncomputing farthest point 38, dmax: 0.45277053, imax: 33, n: 178\ncomputing farthest point 39, dmax: 0.43939415, imax: 134, n: 178\n(n, m, k, length(A.centers), length(C)) = (1000, 244, 39, 39, 36)\n[ Info: using 32 random queries from the dataset\n[ Info: using 64 random queries from the dataset\n  0.145455 seconds (176.20 k allocations: 11.331 MiB, 99.64% compilation time)"
  },
  {
    "objectID": "demos/using-manifoldlearning.html#visualizing-prime-gaps",
    "href": "demos/using-manifoldlearning.html#visualizing-prime-gaps",
    "title": "Using with ManifoldLearning",
    "section": "Visualizing prime gaps",
    "text": "Visualizing prime gaps\nThe difference between contiguous prime numbers is called a Prime gap. We use this series of values as a time series example due to its interesting behavior and since it can be computed without downloading more than the necessary packages.\nThis example shows how to generate the dataset and index it. We will use the ManifoldLearning for generating the 2d visualization.\n\nGeneration of the dataset\nThe time series is represented with windows of size w, we also take log of gaps to reduce variance in gap values. We create a matrix to avoid redefinition of the knn interface for ManifoldLearning.\n\nfunction create_database_primes_diff(n, w)\n    T = log2.(diff(primes(n)))\n    M = Matrix{Float32}(undef, w, length(T) - w)\n    @info size(M)\n    for i in 1:size(M, 2)\n        M[:, i] .= view(T, i:(i+w-1))\n    end\n\n    M\nend\n\n\nx, y = let\n    P = create_database_primes_diff(3 * 10^4, 5)\n    # or LLE\n    primesgap = fit(Isomap, P; k=16, maxoutdim=2, nntype=ApproxEuclidean)\n    \n    p = predict(primesgap)\n    p[1, :], p[2, :]\nend\n\nA 2D histogram\n\nhistogram2d(x, y; nbins=100)"
  },
  {
    "objectID": "demos/using-manifoldlearning.html#environment-and-dependencies",
    "href": "demos/using-manifoldlearning.html#environment-and-dependencies",
    "title": "Using with ManifoldLearning",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.9\nCommit 5595d20a287 (2025-03-10 12:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 Ã Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_PROJECT = .\n  JULIA_NUM_THREADS = auto\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/sites/SimilaritySearchDemos/Project.toml`\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.7.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.0 `~/.julia/dev/InvertedFiles`\n  [682c06a0] JSON v0.21.4\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\nâ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.11\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.0 `~/.julia/dev/SimSearchManifoldLearning`\n  [053f045d] SimilaritySearch v0.12.0 `~/.julia/dev/SimilaritySearch`\nâ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.0 `~/.julia/dev/TextSearch`\nInfo Packages marked with â and â have new versions available. Those with â may be upgradable, but those with â are restricted by compatibility constraints from upgrading. To see why use `status --outdated`\nWarning The project dependencies or compat requirements have changed since the manifest was last resolved. It is recommended to `Pkg.resolve()` or consider `Pkg.update()` if necessary."
  },
  {
    "objectID": "demos/index.html",
    "href": "demos/index.html",
    "title": "Tutorials",
    "section": "",
    "text": "We separate the examples by the kind of data, since some of the datasets are quite large and will require a lot of computer power. We also list how to connect SimilaritySearch with other packages that require solving k nearest neighbor queries.\n\n\n\n2d example\n\n\n\n\n\nPrime factors\nManifoldLearning â scurve and prime gaps\n\n\n\n\n\nGlove embeddings\nEmoji space\n\n\n\n\n\nMNIST"
  },
  {
    "objectID": "demos/index.html#list-of-examples",
    "href": "demos/index.html#list-of-examples",
    "title": "Tutorials",
    "section": "",
    "text": "We separate the examples by the kind of data, since some of the datasets are quite large and will require a lot of computer power. We also list how to connect SimilaritySearch with other packages that require solving k nearest neighbor queries.\n\n\n\n2d example\n\n\n\n\n\nPrime factors\nManifoldLearning â scurve and prime gaps\n\n\n\n\n\nGlove embeddings\nEmoji space\n\n\n\n\n\nMNIST"
  },
  {
    "objectID": "demos/mnist.html",
    "href": "demos/mnist.html",
    "title": "Visualizing MNIST database",
    "section": "",
    "text": "by: Eric S. TÃ©llez\nThis example creates a visualization of the MNIST images (hand written digits) using MLDatasets.jl to retrieve it.\nNote: This example needs a lot of computing power; therefore you may want to set the environment variable JULIA_NUM_THREADS=auto before running julia.\nusing SimilaritySearch, SimSearchManifoldLearning, Plots, StatsBase, LinearAlgebra, Markdown, MLDatasets, Random\ndb, y, dist = let data = MNIST(split=:train)\n    T, y = data.features, data.targets\n    n = size(T, 3)\n    MatrixDatabase(Float32.(reshape(T, (28*28, n)))), y, SqL2_asf32()\nend\nNow we can create the index\n1index = SearchGraph(; dist, db)\nctx = SearchGraphContext(hyperparameters_callback=OptimizeParameters(MinRecall(0.99)))\n2index!(index, ctx)\n3optimize_index!(index, ctx, MinRecall(0.95))\n\n\n1\n\nDefines the index and the search context (caches and hyperparameters); particularly, we use a very high quality build MinRecall(0.99); high quality constructions yield to faster queries due to the underlying graph structure.\n\n2\n\nActual indexing procedure using the given search context.\n\n3\n\nOptimizing the index to trade quality and speed."
  },
  {
    "objectID": "demos/mnist.html#umap-visualization",
    "href": "demos/mnist.html#umap-visualization",
    "title": "Visualizing MNIST database",
    "section": "UMAP Visualization",
    "text": "UMAP Visualization\n\nfunction normcolors(V)\n    min_, max_ = extrema(V)\n    V .= (V .- min_) ./ (max_ - min_)\n    V .= clamp.(V, 0, 1)\nend\n\nnormcolors(@view e3[1, :])\nnormcolors(@view e3[2, :])\nnormcolors(@view e3[3, :])\n\nlet C = [RGB(c[1], c[2], c[3]) for c in eachcol(e3)],\n    X = view(e2, 1, :),\n    Y = view(e2, 2, :)\n    scatter(X, Y, color=C, fmt=:png, alpha=0.2, size=(600, 600), ma=0.3, ms=2, msw=0, label=\"\", yticks=nothing, xticks=nothing, xaxis=false, yaxis=false)\n    for i in 1:100\n        j = rand(1:length(y))\n        annotate!(X[j], Y[j], text(y[j], :black, :right, 8, \"noto\"))\n    end\nend\n\nplot!()\n\n\n\n\n\ne2, e3 = let min_dist=0.5f0,\n             k=7,\n             n_epochs=75,\n             neg_sample_rate=3,\n             tol=1e-3,\n             layout=SpectralLayout()\n\n    @time \"Compute 2D UMAP model\" U2 = fit(UMAP, index; k, neg_sample_rate, layout, n_epochs, tol, min_dist)\n    @time \"Compute 3D UMAP model\" U3 = fit(U2, 3; neg_sample_rate, n_epochs, tol)\n    @time \"predicting 2D embeddings\" e2 = clamp.(predict(U2), -10f0, 10f0)\n    @time \"predicting 3D embeddings\" e3 = clamp.(predict(U3), -10f0, 10f0)\n    e2, e3\nend"
  },
  {
    "objectID": "demos/mnist.html#final-notes",
    "href": "demos/mnist.html#final-notes",
    "title": "Visualizing MNIST database",
    "section": "Final notes",
    "text": "Final notes\nThis example shows how to index and visualize the MNIST dataset using UMAP low dimensional projections. Low dimensional projections are made with SimSearchManifoldLearning, note that SimilaritySearch is also used for computing the all \\(k\\) nearest neighbors needed by the UMAP model. Note that this notebook should be ran with several threads to reduce time costs."
  },
  {
    "objectID": "demos/mnist.html#environment-and-dependencies",
    "href": "demos/mnist.html#environment-and-dependencies",
    "title": "Visualizing MNIST database",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.9\nCommit 5595d20a287 (2025-03-10 12:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 Ã Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_PROJECT = .\n  JULIA_NUM_THREADS = auto\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/sites/SimilaritySearchDemos/Project.toml`\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.7.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.0 `~/.julia/dev/InvertedFiles`\n  [682c06a0] JSON v0.21.4\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\nâ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.11\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.0 `~/.julia/dev/SimSearchManifoldLearning`\n  [053f045d] SimilaritySearch v0.12.0 `~/.julia/dev/SimilaritySearch`\nâ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.0 `~/.julia/dev/TextSearch`\nInfo Packages marked with â and â have new versions available. Those with â may be upgradable, but those with â are restricted by compatibility constraints from upgrading. To see why use `status --outdated`\nWarning The project dependencies or compat requirements have changed since the manifest was last resolved. It is recommended to `Pkg.resolve()` or consider `Pkg.update()` if necessary."
  },
  {
    "objectID": "demos/emojispace.html",
    "href": "demos/emojispace.html",
    "title": "Visualizing Twitter Messages with Emojis",
    "section": "",
    "text": "This example creates a vector space model for classify emojis in Twitter messages, then process and create vectors from messages and project them using a UMAP model. The projection uses the SimilaritySearch allknn operation.\nusing SimilaritySearch, SimSearchManifoldLearning, TextSearch, CodecZlib, JSON, DataFrames, Plots, StatsBase\nusing Downloads: download\ndownloading the dataset, parsing and vectorizing functions\nmkpath(\"tmp\")\ndbfile = \"tmp/emo50k.json.gz\"\nbaseurl = \"https://github.com/sadit/TextClassificationTutorial/raw/refs/heads/main/data/emo50k.json.gz\"\n!isfile(dbfile) && download(baseurl, dbfile)\n\nfalse\nNow, we load the dataset\nD = DataFrame(open(GzipDecompressorStream, dbfile) do f\n    JSON.parse.(eachline(f))\nend)\n\ncollect(countmap(D.klass))\n\n64-element Vector{Pair{String, Int64}}:\n \"â¨\" =&gt; 801\n \"ð¤¤\" =&gt; 771\n \"ð\" =&gt; 794\n \"ð¡\" =&gt; 776\n \"ð\" =&gt; 757\n \"ð¤£\" =&gt; 780\n \"ð\" =&gt; 779\n \"ð­\" =&gt; 785\n \"ð¤\" =&gt; 732\n \"ð\" =&gt; 774\n      â®\n \"ð\" =&gt; 748\n \"ð\" =&gt; 770\n \"ð\" =&gt; 786\n \"ð\" =&gt; 815\n \"ð\" =&gt; 772\n \"ð\" =&gt; 747\n \"ð\" =&gt; 812\n \"ð\" =&gt; 782\n \"ð³\" =&gt; 839\nD = filter(D) do r\n    r.klass in (\"ð­\", \"ð¤£\", \"ð\", \"ð¤\")\nend\n\ncollect(countmap(D.klass))\n#H = sort!(collect(countmap(D.klass)), by=first)\n#bar(first.(H), last.(H))\n\n4-element Vector{Pair{String, Int64}}:\n \"ð¤£\" =&gt; 780\n \"ð¤\" =&gt; 808\n \"ð­\" =&gt; 785\n \"ð\" =&gt; 816\nFunctions create to encode texto into bag-of-word vectors\ntextconfig = TextConfig(\n    group_usr=true,\n    group_url=true,\n    del_diac=true,\n    lc=true,\n    group_num=true,\n    nlist=[1],\n    qlist=[3])\n\n# corpus here can be a sample to avoid double parsing\nvoc = Vocabulary(textconfig, D.text) \n# model = VectorModel(IdfWeighting(), TfWeighting(), voc)\nmodel = VectorModel(EntropyWeighting(), BinaryLocalWeighting(), voc, D.text, D.klass; smooth=1.0)\n#model = VectorModel(IdfWeighting(), TfWeighting(), voc)\nmodel = filter_tokens(model) do t\n    t.weight &gt;= 0.075\nend\nvectors = vectorize_corpus(model, D.text)"
  },
  {
    "objectID": "demos/emojispace.html#umap-projections",
    "href": "demos/emojispace.html#umap-projections",
    "title": "Visualizing Twitter Messages with Emojis",
    "section": "UMAP projections",
    "text": "UMAP projections\nUMAP projection can take a while, even on multithreading systems. Note that we are creating 2d and 3d projections.\n\n1e2, e3 = let min_dist=0.5f0,\n             k=16,\n             n_epochs=75,\n             neg_sample_rate=3,\n             tol=1e-3,\n             layout=SpectralLayout(),\n             indexsize=768,\n             dist=NormalizedCosineDistance()\n\n    index = ExhaustiveSearch(; db=rand(vectors, indexsize), dist)\n    @time U2 = fit(UMAP, index; k, neg_sample_rate, layout, n_epochs, tol, min_dist)\n    @time U3 = fit(U2, 3; neg_sample_rate, n_epochs, tol)\n    @time e2 = clamp.(predict(U2, vectors), -10f0, 10f0)\n    @time e3 = clamp.(predict(U3, vectors), -10f0, 10f0)\n    e2, e3\nend\n\n\n1\n\nThe UMAP algorithm has a lot of hyperparameters; min_dist controls the distance between projected points, k is the number of neighbors to be used in the underlying \\(k\\)nn graph, n_epochs the number of epochs used to optimize the projection, neg_sample_rate means for the number of negative examples used in the optimization process, tol the tolerance to converge, layout"
  },
  {
    "objectID": "demos/emojispace.html#visualizations",
    "href": "demos/emojispace.html#visualizations",
    "title": "Visualizing Twitter Messages with Emojis",
    "section": "Visualizations",
    "text": "Visualizations\n\nfunction normcolors(V)\n    min_, max_ = extrema(V)\n    V .= (V .- min_) ./ (max_ - min_)\n    V .= clamp.(V, 0, 1)\nend\n\nnormcolors(@view e3[1, :])\nnormcolors(@view e3[2, :])\nnormcolors(@view e3[3, :])\n\nC = [RGB(c[1], c[2], c[3]) for c in eachcol(e3)]\n\nX = @view e2[1, :]\nY = @view e2[2, :]\nscatter(X, Y, color=C, markersize=4, alpha=0.5)\n\nfor i in 1:100\n    j = rand(1:length(D.klass))\n    annotate!(X[j], Y[j], text(D.klass[j], :blue, :right, 8, \"noto\"))\nend\n\nplot!()\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nð­\n\n\nð¤£\n\n\nð¤£\n\n\nð¤\n\n\nð¤\n\n\nð\n\n\nð\n\n\nð\n\n\nð¤\n\n\nð¤£\n\n\nð\n\n\nð\n\n\nð¤£\n\n\nð­\n\n\nð¤\n\n\nð­\n\n\nð¤\n\n\nð¤£\n\n\nð\n\n\nð¤\n\n\nð¤\n\n\nð¤\n\n\nð¤\n\n\nð\n\n\nð­\n\n\nð¤£\n\n\nð¤£\n\n\nð­\n\n\nð¤£\n\n\nð¤\n\n\nð¤£\n\n\nð¤£\n\n\nð¤\n\n\nð¤\n\n\nð­\n\n\nð­\n\n\nð\n\n\nð­\n\n\nð¤\n\n\nð¤£\n\n\nð\n\n\nð­\n\n\nð\n\n\nð¤£\n\n\nð¤\n\n\nð­\n\n\nð¤£\n\n\nð¤£\n\n\nð\n\n\nð­\n\n\nð¤£\n\n\nð\n\n\nð¤\n\n\nð¤£\n\n\nð¤\n\n\nð¤\n\n\nð¤\n\n\nð­\n\n\nð­\n\n\nð¤\n\n\nð­\n\n\nð¤\n\n\nð­\n\n\nð­\n\n\nð¤£\n\n\nð¤£\n\n\nð¤£\n\n\nð\n\n\nð\n\n\nð¤\n\n\nð¤\n\n\nð\n\n\nð¤£\n\n\nð¤\n\n\nð­\n\n\nð\n\n\nð¤£\n\n\nð¤\n\n\nð­\n\n\nð¤£\n\n\nð\n\n\nð¤\n\n\nð¤£\n\n\nð¤£\n\n\nð­\n\n\nð\n\n\nð¤\n\n\nð­\n\n\nð\n\n\nð­\n\n\nð­\n\n\nð¤£\n\n\nð\n\n\nð¤£\n\n\nð­\n\n\nð¤\n\n\nð¤\n\n\nð¤\n\n\nð­\n\n\nð¤"
  },
  {
    "objectID": "demos/emojispace.html#environment-and-dependencies",
    "href": "demos/emojispace.html#environment-and-dependencies",
    "title": "Visualizing Twitter Messages with Emojis",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.9\nCommit 5595d20a287 (2025-03-10 12:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 Ã Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_PROJECT = .\n  JULIA_NUM_THREADS = auto\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/sites/SimilaritySearchDemos/Project.toml`\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.7.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.0 `~/.julia/dev/InvertedFiles`\n  [682c06a0] JSON v0.21.4\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\nâ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.11\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.0 `~/.julia/dev/SimSearchManifoldLearning`\n  [053f045d] SimilaritySearch v0.12.0 `~/.julia/dev/SimilaritySearch`\nâ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.0 `~/.julia/dev/TextSearch`\nInfo Packages marked with â and â have new versions available. Those with â may be upgradable, but those with â are restricted by compatibility constraints from upgrading. To see why use `status --outdated`\nWarning The project dependencies or compat requirements have changed since the manifest was last resolved. It is recommended to `Pkg.resolve()` or consider `Pkg.update()` if necessary."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This site is an effort to document and give comprehensive resources to use the SimilaritySearch.jl Julia package. The contributors are:\n\nEric S. TÃ©llez https://sadit.github.io/, SECIHTI-INFOTEC, Aguascalientes, MÃ©xico.\nGuillermo Ruiz, INFOTEC, Aguascalientes, MÃ©xico."
  },
  {
    "objectID": "datasets.html",
    "href": "datasets.html",
    "title": "Datasets for Nearest Neighbor Search",
    "section": "",
    "text": "MNIST. Very used in vision tasks, pretty old and not very challenging. However it is very easy to use. From MNIST site, it corresponds to 60k 28x28 handwritten numbers. We use the MLDatasets.jl package to simplify downloading and loading it.\nWiktionary. Took from Wiktionary site, we select English terms from the english wiktionary.\nWIT-300K. From Clip and WIT, we downloaded the first 300K annotated images for the Spanish Wikipedia and take the Clip embeddings of them. Available from the demo subfolder.\nGlove. Very used as dataset in papers but not yet vigent with respect to state of the art methods in different Natural Language Processing tasks. From Glove site, it corresponds to the 100d, 6B tokens. We use the Embeddings.jl package to simplify downloading and loading it.\n\n\n\nThe versions used in the demonstrations are not splitted in train and test, but those used in the paper are splitted. If you want to reproduce the same results, please use the datasets by ann-benchmarks and its repo.\nFor WIT and Twitter-2M, please use the following HDF5 files, they follow a similar structure than those found in the ann-benchmarks.\n\nWIT-300K\nTwitter-2M. These word embeddings corresponds to that model labeled as ALL-2M in the Regional Spanish Models site, yet partitioned for using as similarity search benchmark."
  },
  {
    "objectID": "datasets.html#real-world",
    "href": "datasets.html#real-world",
    "title": "Datasets for Nearest Neighbor Search",
    "section": "",
    "text": "MNIST. Very used in vision tasks, pretty old and not very challenging. However it is very easy to use. From MNIST site, it corresponds to 60k 28x28 handwritten numbers. We use the MLDatasets.jl package to simplify downloading and loading it.\nWiktionary. Took from Wiktionary site, we select English terms from the english wiktionary.\nWIT-300K. From Clip and WIT, we downloaded the first 300K annotated images for the Spanish Wikipedia and take the Clip embeddings of them. Available from the demo subfolder.\nGlove. Very used as dataset in papers but not yet vigent with respect to state of the art methods in different Natural Language Processing tasks. From Glove site, it corresponds to the 100d, 6B tokens. We use the Embeddings.jl package to simplify downloading and loading it.\n\n\n\nThe versions used in the demonstrations are not splitted in train and test, but those used in the paper are splitted. If you want to reproduce the same results, please use the datasets by ann-benchmarks and its repo.\nFor WIT and Twitter-2M, please use the following HDF5 files, they follow a similar structure than those found in the ann-benchmarks.\n\nWIT-300K\nTwitter-2M. These word embeddings corresponds to that model labeled as ALL-2M in the Regional Spanish Models site, yet partitioned for using as similarity search benchmark."
  },
  {
    "objectID": "demos/glove.html",
    "href": "demos/glove.html",
    "title": "Visualizing Twitter Messages with Emojis",
    "section": "",
    "text": "by: Eric S. TÃ©llez\nThis example creates a visualization of Glove word embeddings using Embeddings.jl package to fetch them.\nNote: This example needs a lot of computing power; therefore you may want to set the environment variable JULIA_NUM_THREADS=auto before running julia.\nusing SimilaritySearch, SimSearchManifoldLearning, TextSearch, CodecZlib, JSON, DataFrames, Plots, StatsBase, LinearAlgebra, Markdown, Embeddings, Random\nusing Downloads: download\nemb, vocab = let emb = load_embeddings(GloVe{:en}, 2)  # you can change with any of the available embeddings in `Embeddings`\n    for c in eachcol(emb.embeddings)\n1        normalize!(c)\n    end\n\n2    Float16.(emb.embeddings), emb.vocab\nend\n\n3dist = NormalizedCosine_asf32()\n4vocab2id = Dict(w =&gt; i for (i, w) in enumerate(vocab))\n\n\n1\n\nNormalizes all vectors to have a unitary norm; this allow us to use the dot product as similarity (see point 3)\n\n2\n\nThe speed can be improved through memoryâs bandwidth using less memory per vector; using Float16 as memory representation is a good idea even if your computer doesnât support 16-bit floating point arithmetic natively.\n\n3\n\nSince we have unitary norm vectors we can simplify the cosine distance (i.e., \\(1 - dot(\\cdot, \\cdot)\\)); note that we are using Float16 and the suffix _asf32 will select a distance function that converts numbers to Float32 just before performing arithmetic operations.\n\n4\n\nInverse map from words to identifiers in vocab.\nNow we can create the index\n1index = SearchGraph(; dist, db=MatrixDatabase(emb))\nctx = SearchGraphContext(hyperparameters_callback=OptimizeParameters(MinRecall(0.99)))\n2index!(index, ctx)\n3optimize_index!(index, ctx, MinRecall(0.9))\n\n\n1\n\nDefines the index and the search context (caches and hyperparameters); particularly, we use a very high quality build MinRecall(0.99); high quality constructions yield to faster queries due to the underlying graph structure.\n\n2\n\nActual indexing procedure using the given search context.\n\n3\n\nOptimizing the index to trade quality and speed."
  },
  {
    "objectID": "demos/glove.html#umap-visualization",
    "href": "demos/glove.html#umap-visualization",
    "title": "Visualizing Twitter Messages with Emojis",
    "section": "UMAP Visualization",
    "text": "UMAP Visualization\n\nfunction normcolors(V)\n    min_, max_ = extrema(V)\n    V .= (V .- min_) ./ (max_ - min_)\n    V .= clamp.(V, 0, 1)\nend\n\nnormcolors(@view e3[1, :])\nnormcolors(@view e3[2, :])\nnormcolors(@view e3[3, :])\n\nlet C = [RGB(c[1], c[2], c[3]) for c in eachcol(e3)],\n    X = view(e2, 1, :),\n    Y = view(e2, 2, :)\n    scatter(X, Y, color=C, fmt=:png, alpha=0.2, size=(600, 600), ma=0.3, ms=2, msw=0, label=\"\", yticks=nothing, xticks=nothing, xaxis=false, yaxis=false)\nend\n\nplot!()\n\n\n\n\n\ne2, e3 = let min_dist=0.5f0,\n             k=12,\n             n_epochs=75,\n             neg_sample_rate=3,\n             tol=1e-3,\n             layout=RandomLayout()\n\n    @time \"Compute 2D UMAP model\" U2 = fit(UMAP, index; k, neg_sample_rate, layout, n_epochs, tol, min_dist)\n    @time \"Compute 3D UMAP model\" U3 = fit(U2, 3; neg_sample_rate, n_epochs, tol)\n    @time \"predicting 2D embeddings\" e2 = clamp.(predict(U2), -10f0, 10f0)\n    @time \"predicting 3D embeddings\" e3 = clamp.(predict(U3), -10f0, 10f0)\n    e2, e3\nend"
  },
  {
    "objectID": "demos/glove.html#final-notes",
    "href": "demos/glove.html#final-notes",
    "title": "Visualizing Twitter Messages with Emojis",
    "section": "Final notes",
    "text": "Final notes\nThis example shows how to index and search dense vector databases, in particular GloVe word embeddings using the cosine distance. Low dimensional projections are made with SimSearchManifoldLearning, note that SimilaritySearch is also used for computing the all \\(k\\) nearest neighbors needed by the UMAP model. Note that this notebook should be ran with several threads to reduce time costs."
  },
  {
    "objectID": "demos/glove.html#environment-and-dependencies",
    "href": "demos/glove.html#environment-and-dependencies",
    "title": "Visualizing Twitter Messages with Emojis",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.9\nCommit 5595d20a287 (2025-03-10 12:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 Ã Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_PROJECT = .\n  JULIA_NUM_THREADS = auto\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/sites/SimilaritySearchDemos/Project.toml`\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.7.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.0 `~/.julia/dev/InvertedFiles`\n  [682c06a0] JSON v0.21.4\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\nâ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.11\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.0 `~/.julia/dev/SimSearchManifoldLearning`\n  [053f045d] SimilaritySearch v0.12.0 `~/.julia/dev/SimilaritySearch`\nâ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.0 `~/.julia/dev/TextSearch`\nInfo Packages marked with â and â have new versions available. Those with â may be upgradable, but those with â are restricted by compatibility constraints from upgrading. To see why use `status --outdated`\nWarning The project dependencies or compat requirements have changed since the manifest was last resolved. It is recommended to `Pkg.resolve()` or consider `Pkg.update()` if necessary."
  },
  {
    "objectID": "demos/syn2d.html",
    "href": "demos/syn2d.html",
    "title": "Visualizing MNIST database",
    "section": "",
    "text": "by: Eric S. TÃ©llez\nThis demonstration shows in a 2D example the functionality of SearchGraph.\nusing SimilaritySearch, SimSearchManifoldLearning, Plots, StatsBase, LinearAlgebra, Markdown, Random\nn = 100_000\n\nM = randn(Float16, 2, n)\ndb = MatrixDatabase(M)\ndist = SqL2_asf32()\nsize(M)\nNow we can create the index\n1G = SearchGraph(; dist, db)\nctx = SearchGraphContext(hyperparameters_callback=OptimizeParameters(MinRecall(0.99)))\n2index!(G, ctx)\n3optimize_index!(G, ctx, MinRecall(0.9))\n\n\n1\n\nDefines the index and the search context (caches and hyperparameters); particularly, we use a very high quality build MinRecall(0.99); high quality constructions yield to faster queries due to the underlying graph structure.\n\n2\n\nActual indexing procedure using the given search context.\n\n3\n\nOptimizing the index to trade quality and speed."
  },
  {
    "objectID": "demos/syn2d.html#the-set-of-queries",
    "href": "demos/syn2d.html#the-set-of-queries",
    "title": "Visualizing MNIST database",
    "section": "The set of queries",
    "text": "The set of queries\nWe define a small set of queries being close to the border of the dataset and also in the most dense regions of the dataset.\n\nQ = [Float32[-2, -2], Float32[2, -2], Float32[-2, 0], Float32[-0, 2], Float32[0, 0],   Float32[-3, 3],  Float32[4, 4], Float32[1, 0.5]]\nI, D = searchbatch(G, ctx, VectorDatabase(Q), 30)\n\nPlease note how queries in low and high dense regions are located.\n\nscatter(view(M, 1, :), view(M, 2, :), fmt=:png, c=:cyan, ma=0.3, a=0.3, ms=1, msw=0)\n\nscatter!(getindex.(Q, 1), getindex.(Q, 2), c=:red, ma=0.7, a=0.7, ms=6, msw=0)\n\nfor c in eachcol(I)\n    X = M[:, c]\n    scatter!(view(X, 1, :), view(X, 2, :), c=:blue, ma=0.5, a=0.5, ms=2, msw=0)\n    #scatter!( c=:auto, ms=2)\nend\n\nplot!(legend=nothing)\n\nSince points are distributed in several regions with disparate density, their radii are also quite diverse. The next figure illustrates this effect."
  },
  {
    "objectID": "demos/syn2d.html#distribution-of-distances-for-the-set-of-queries",
    "href": "demos/syn2d.html#distribution-of-distances-for-the-set-of-queries",
    "title": "Visualizing MNIST database",
    "section": "Distribution of distances for the set of queries",
    "text": "Distribution of distances for the set of queries\n\nplot(D, m=:auto, yscale=:log10, title=\"knn distances for elements in Q\", fmt=:png)"
  },
  {
    "objectID": "demos/syn2d.html#environment-and-dependencies",
    "href": "demos/syn2d.html#environment-and-dependencies",
    "title": "Visualizing MNIST database",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.9\nCommit 5595d20a287 (2025-03-10 12:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 Ã Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_PROJECT = .\n  JULIA_NUM_THREADS = auto\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/sites/SimilaritySearchDemos/Project.toml`\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.7.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.0 `~/.julia/dev/InvertedFiles`\n  [682c06a0] JSON v0.21.4\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\nâ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.11\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.0 `~/.julia/dev/SimSearchManifoldLearning`\n  [053f045d] SimilaritySearch v0.12.0 `~/.julia/dev/SimilaritySearch`\nâ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.0 `~/.julia/dev/TextSearch`\nInfo Packages marked with â and â have new versions available. Those with â may be upgradable, but those with â are restricted by compatibility constraints from upgrading. To see why use `status --outdated`\nWarning The project dependencies or compat requirements have changed since the manifest was last resolved. It is recommended to `Pkg.resolve()` or consider `Pkg.update()` if necessary."
  },
  {
    "objectID": "demos/primes.html",
    "href": "demos/primes.html",
    "title": "Prime numbers",
    "section": "",
    "text": "by: Eric S. TÃ©llez\nThis demonstration is about prime numbers and its similarity based on its factors. This is a well-known demonstration of SimSearchManifoldLearning.jl. This notebook does not requires to download any dataset.\nNote: This example needs a lot of computing power; therefore you may want to set the environment variable JULIA_NUM_THREADS=auto before running julia.\nusing SimilaritySearch, SimSearchManifoldLearning, Primes, Plots, StatsBase, LinearAlgebra, Markdown, Random\nNow, we can define our dataset. The set of factors are found using the Primes package. Note that we use VectorDatabase to represent the dataset.\nn = 100_000\nF = Vector{Vector{Int32}}(undef, n+1)\n\nfunction encode_factors(num)\n    sort!(Int32[convert(Int32, f) for f in factor(Set, num)])\nend\n\nF[1] = Int32[1]\n\nfor i in 2:n+1\n    s = encode_factors(i)\n    F[i] = s\nend\n\ndb = VectorDatabase(F)\n#dist = JaccardDistance()  # Other distances from SimilaritySearch\n#dist = IntersectionDissimilarity()\n#dist = CosineDistanceSet()\ndist = DiceDistance()\nWe use Int32 ordered arrays to store prime factors to represent each integer. In the following cell define the cosine distance equivalent for this representation. While other representations may perform faster, this is quite straighforward and demonstrates the use of userâs defined distance functions."
  },
  {
    "objectID": "demos/primes.html#index-construction",
    "href": "demos/primes.html#index-construction",
    "title": "Prime numbers",
    "section": "Index construction",
    "text": "Index construction\nNote that the primes factors are pretty large for some large \\(n\\) and this imply challengues for metric indexes (since it is related with the intrinsic dimension of the dataset). We used a kernel that starts 64 threads, it solves \\(100000\\) in a few seconds but it can take pretty large time using single threads and larger \\(n\\) values. The construction of the index is used by the visualization algorithm (UMAP) to construct an all-knn graph, which can be a quite costly procedure.\n\nG = SearchGraph(; db, dist)\n1ctx = SearchGraphContext(hyperparameters_callback=OptimizeParameters(MinRecall(0.95)))\n2index!(G, ctx)\n3optimize_index!(G, ctx, MinRecall(0.9))\n\n\n1\n\nDefines the index and the search context (caches and hyperparameters); particularly, we use a very high quality build MinRecall(0.95); high quality constructions yield to faster queries due to the underlying graph structure.\n\n2\n\nActual indexing procedure using the given search context.\n\n3\n\nOptimizing the index to trade quality and speed."
  },
  {
    "objectID": "demos/primes.html#visualizing-with-umap-projection",
    "href": "demos/primes.html#visualizing-with-umap-projection",
    "title": "Prime numbers",
    "section": "Visualizing with UMAP projection",
    "text": "Visualizing with UMAP projection\nWe select to initialize the embedding randomly, this could yield to low quality embeddings, but it is much faster than other techniques like spectral layout. Note that we pass the Search graph G. We also use a second call to compute a 3D embedding for computing a kind of colour embedding, here we pass U2 to avoid recomputing several of the involved structures.\n\nfunction normcolors(V)\n    min_, max_ = extrema(V)\n    V .= (V .- min_) ./ (max_ - min_)\n    V .= clamp.(V, 0, 1)\nend\n\nnormcolors(@view e3[1, :])\nnormcolors(@view e3[2, :])\nnormcolors(@view e3[3, :])\n\nlet C = [RGB(c[1], c[2], c[3]) for c in eachcol(e3)],\n    X = view(e2, 1, :),\n    Y = view(e2, 2, :)\n    scatter(X, Y, color=C, fmt=:png, alpha=0.2, size=(600, 600), ma=0.3, ms=2, msw=0, label=\"\", yticks=nothing, xticks=nothing, xaxis=false, yaxis=false)\nend\n\nplot!()\n\n\n\n\n\ne2, e3 = let min_dist=0.5f0,\n             k=20,\n             n_epochs=75,\n             neg_sample_rate=3,\n             tol=1e-3,\n             layout=SpectralLayout()\n\n    @time \"Compute 2D UMAP model\" U2 = fit(UMAP, G; k, neg_sample_rate, layout, n_epochs, tol, min_dist)\n    @time \"Compute 3D UMAP model\" U3 = fit(U2, 3; neg_sample_rate, n_epochs, tol)\n    @time \"predicting 2D embeddings\" e2 = clamp.(predict(U2), -10f0, 10f0)\n    @time \"predicting 3D embeddings\" e3 = clamp.(predict(U3), -10f0, 10f0)\n    e2, e3\nend"
  },
  {
    "objectID": "demos/primes.html#environment-and-dependencies",
    "href": "demos/primes.html#environment-and-dependencies",
    "title": "Prime numbers",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.9\nCommit 5595d20a287 (2025-03-10 12:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 Ã Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_PROJECT = .\n  JULIA_NUM_THREADS = auto\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/sites/SimilaritySearchDemos/Project.toml`\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.7.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.0 `~/.julia/dev/InvertedFiles`\n  [682c06a0] JSON v0.21.4\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\nâ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.11\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.0 `~/.julia/dev/SimSearchManifoldLearning`\n  [053f045d] SimilaritySearch v0.12.0 `~/.julia/dev/SimilaritySearch`\nâ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.0 `~/.julia/dev/TextSearch`\nInfo Packages marked with â and â have new versions available. Those with â may be upgradable, but those with â are restricted by compatibility constraints from upgrading. To see why use `status --outdated`\nWarning The project dependencies or compat requirements have changed since the manifest was last resolved. It is recommended to `Pkg.resolve()` or consider `Pkg.update()` if necessary."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tutorials and Examples for the SimilaritySearch.jl package",
    "section": "",
    "text": "Here you will find several examples for the SimilaritySearch.jl package."
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "Tutorials and Examples for the SimilaritySearch.jl package",
    "section": "Installation",
    "text": "Installation\nYou need a Julia installation https://julialang.org/downloads/, in particular, we recommend to use Julia \\(v1.10\\) since \\(v1.11\\) has several performance regressions with respect to SimilaritySearch.\nWe present our examples just to copy and paste on the REPL but also provide some in Jupyter and Pluto notebooks; you must install IJulia and Pluto packages, just run the following commands in the REPL\nusing Pkg; Pkg.add([\"IJulia\", \"Pluto\"])\nPlease check their documentation:\n\nIJulia.\nJupyter.\nPluto\n\nThis website was made with Quarto with the Julia engine."
  },
  {
    "objectID": "index.html#notes-about-multithreading",
    "href": "index.html#notes-about-multithreading",
    "title": "Tutorials and Examples for the SimilaritySearch.jl package",
    "section": "Notes about multithreading",
    "text": "Notes about multithreading\nNearest neighbor search can be computationally expensive, therefore SimilaritySearch has multithreading support. You should want to run jupyter or julia using all available threads, that is\nJULIA_NUM_THREADS=auto jupyter-lab .\nor\nJULIA_NUM_THREADS=auto julia\nPerhaps all your threads may become your computer useless for a while, so you can replace auto by some other more conservative number that allow you to work on the same computer."
  },
  {
    "objectID": "index.html#news",
    "href": "index.html#news",
    "title": "Tutorials and Examples for the SimilaritySearch.jl package",
    "section": "News",
    "text": "News\n\nmarch 20th, 2025: the site is behind the SimilaritySearch API; I will be working on updating examples and moving the site to Quarto.\njune 5th, 2023: adds news section, some installation requirements, Jupyter notebookes were updated to work with the v0.10 and with the current julia release v1.9. I also moved most plots to Makie."
  },
  {
    "objectID": "index.html#problem-statement",
    "href": "index.html#problem-statement",
    "title": "Tutorials and Examples for the SimilaritySearch.jl package",
    "section": "Problem statement",
    "text": "Problem statement\nGiven a finite dataset, \\(S \\subseteq U\\) where \\(n = |S|\\), and a metric distance function \\(d\\) working with any pair of elements in \\(U\\), the similarity search problem consists on retrieving similar items to a given query \\(q\\), for example, the \\(k\\) most similar items to \\(q\\) in \\(S\\) (\\(k\\) nearest neighbors).\nAt first glance, the problem is simple since it can be solved using an exhaustive evaluation of all possible results \\(d(u_1, q), \\cdots, d(u_n, q)\\) (that is, for all \\(u_i \\in S\\)) and select those \\(k\\) items \\(\\{u_i\\}\\) having the least distance to \\(q\\). This solution is impractical when \\(n\\) is large or when the number of expected queries is high. In these cases, it is necessary to create a data structure that preprocess the dataset and reduce the cost of solving queries, it is often called a metric index. When the dataset is pretty large or the metric space is quite complex, sometimes we can loose the ability of retrieving the exact solution to gain speed, clearly, the approximation quality becomes a major concern and these approximate methods require a lot of knowledge to trade speed retrieval process also kept high the solutionâs quality. Additionally, the amount of memory used by the index and the construction time are also concerns whenever \\(n\\) is big.\nThe SearchGraph index in the SimilaritySearch.jl package is a competitive alternative for solving search queries that automatically tune search speed and quality and also remains very competitive in memory and construction costs. Here we show some demostrations of how using SimilaritySearch.jl in several synthetic and real problems."
  },
  {
    "objectID": "tutorials/automatic-hyperparameter-opt.html",
    "href": "tutorials/automatic-hyperparameter-opt.html",
    "title": "Automatic Hyperparameter Optimization",
    "section": "",
    "text": "by: Eric S. TÃ©llez\nThis example optimizes different kinds of optimizations that allow different tradeoffs\n\nusing SimilaritySearch, Markdown\n\n1dim = 16\n2db = MatrixDatabase(rand(Float32, dim, 10^5))\n3queries = MatrixDatabase(rand(Float32, dim, 10^3))\n4dist = SqL2Distance()\n5k = 12\n\n\n1\n\nThe dimension to use in the synthetic data\n\n2\n\nThe synthetic database\n\n3\n\nThe synthetic queries\n\n4\n\nThe distance function; we will use the squared L2, which preserves the order of L2 but is faster to compute.\n\n5\n\nThe number of neighbors to retrieve"
  },
  {
    "objectID": "tutorials/automatic-hyperparameter-opt.html#automatic-hyperparameter-optimization",
    "href": "tutorials/automatic-hyperparameter-opt.html#automatic-hyperparameter-optimization",
    "title": "Automatic Hyperparameter Optimization",
    "section": "",
    "text": "by: Eric S. TÃ©llez\nThis example optimizes different kinds of optimizations that allow different tradeoffs\n\nusing SimilaritySearch, Markdown\n\n1dim = 16\n2db = MatrixDatabase(rand(Float32, dim, 10^5))\n3queries = MatrixDatabase(rand(Float32, dim, 10^3))\n4dist = SqL2Distance()\n5k = 12\n\n\n1\n\nThe dimension to use in the synthetic data\n\n2\n\nThe synthetic database\n\n3\n\nThe synthetic queries\n\n4\n\nThe distance function; we will use the squared L2, which preserves the order of L2 but is faster to compute.\n\n5\n\nThe number of neighbors to retrieve"
  },
  {
    "objectID": "tutorials/automatic-hyperparameter-opt.html#computing-ground-truth",
    "href": "tutorials/automatic-hyperparameter-opt.html#computing-ground-truth",
    "title": "Automatic Hyperparameter Optimization",
    "section": "Computing ground truth",
    "text": "Computing ground truth\nWe will generate a ground truth with an exhaustive method.\n\ngoldI, goldD = searchbatch(ExhaustiveSearch(; db, dist), GenericContext(), queries, k)"
  },
  {
    "objectID": "tutorials/automatic-hyperparameter-opt.html#different-hyperparameter-optimization-strategies",
    "href": "tutorials/automatic-hyperparameter-opt.html#different-hyperparameter-optimization-strategies",
    "title": "Automatic Hyperparameter Optimization",
    "section": "Different hyperparameter optimization strategies",
    "text": "Different hyperparameter optimization strategies\nThe way of specifying the hyperparameter optimization strategy and objective is with a SearchGraphContext object, as follows:\n\nG1 = SearchGraph(; dist, db)\nC1 = SearchGraphContext(hyperparameters_callback=OptimizeParameters(MinRecall(0.99)))\nbuildtime1 = @elapsed index!(G1, C1)\n\nThe previous construction optimizes the construction to have a very high recall, which can be very costly but also produces a high quality index.\n\nG2 = SearchGraph(; dist, db)\nC2 = SearchGraphContext(hyperparameters_callback=OptimizeParameters(MinRecall(0.9)))\nbuildtime2 = @elapsed index!(G2, C2)\n\nsearch, searchbatch, index!, append_items!, and push_item! accept context arguments."
  },
  {
    "objectID": "tutorials/automatic-hyperparameter-opt.html#performances",
    "href": "tutorials/automatic-hyperparameter-opt.html#performances",
    "title": "Automatic Hyperparameter Optimization",
    "section": "Performances",
    "text": "Performances\nsearching times\n\ntime1 = @elapsed I1, D1 = searchbatch(G1, C1, queries, k)\ntime2 = @elapsed I2, D2 = searchbatch(G2, C2, queries, k)\nrecall1 = macrorecall(goldI, I1)\nrecall2 = macrorecall(goldI, I2)\n\nthe recall is an score value between 0 to 1 where values close to 1 indicate better qualities.\n\n\nbuild time:\n\nbuildtime1: 5.628086565\n\nbuildtime2: 0.571731296\n\n\nsearch time:\n\ntime1: 0.002756634\n\ntime2: 0.001616155\n\n\nrecall values:\n\nrecall1: 0.975916666666664\n\nrecall2: 0.8739166666666656\n\n\n\n\n\nhere we can see smaller recalls than expected, and this is an effect of the difference between indexed elements (that are those objects used to perform the hyperparameter optimization). In any case, we 1can appreciate the differences among them, showing that high quality constructions may produce faster indexes; this is a consequence of the quality of the underlying structure. Contrary to this example, in higher dimensions or large datasets, we will obtain much higher construction times for high quality constructions."
  },
  {
    "objectID": "tutorials/automatic-hyperparameter-opt.html#optimizing-an-already-created-searchgraph-for-achieving-a-desired-quality",
    "href": "tutorials/automatic-hyperparameter-opt.html#optimizing-an-already-created-searchgraph-for-achieving-a-desired-quality",
    "title": "Automatic Hyperparameter Optimization",
    "section": "Optimizing an already created SearchGraph for achieving a desired quality",
    "text": "Optimizing an already created SearchGraph for achieving a desired quality\nThe hyperparameter optimization is performed in exponential stages while the SearchGraph is created; and therefore, the current hyperparameters could need an update. To optimize an already created SearchGraph we use optimize instead of index\nContext objects are special for construction since they encapsulate several hyperparameters; for searching it contains also caches but it can be shared among indexes; however, if the indexes have different sizes or you expect very different queries, it is better to maintain different context.\n\noptimize_index!(G1, C1, MinRecall(0.9))\noptimize_index!(G2, C1, MinRecall(0.9))\n\nafter optimizing the index its quality and speed are changed\n\ntime1 = @elapsed I1, D1 = searchbatch(G1, C1, queries, k)\ntime2 = @elapsed I2, D2 = searchbatch(G2, C1, queries, k)\n\nrecall1 = macrorecall(goldI, I1)\nrecall2 = macrorecall(goldI, I2)\n\nThese results on the following performances:\n\n\nbuild time:\n\nbuildtime1: 5.628086565\n\nbuildtime2: 0.571731296\n\n\nsearch time:\n\ntime1: 0.022819288\n\ntime2: 0.013949292\n\n\nrecall values:\n\nrecall1: 0.5897499999999993\n\nrecall2: 0.6759999999999998\n\n\n\n\n\nPlease note that faster searches are expected for indexes created for higher qualities; but the construction must be paid. Note that recall values are lower than expected, as we explained, due to differences in the distributions (more precisely between points already seen and not seen points)."
  },
  {
    "objectID": "tutorials/automatic-hyperparameter-opt.html#giving-more-realistic-queries-for-optimization",
    "href": "tutorials/automatic-hyperparameter-opt.html#giving-more-realistic-queries-for-optimization",
    "title": "Automatic Hyperparameter Optimization",
    "section": "Giving more realistic queries for optimization",
    "text": "Giving more realistic queries for optimization\nThe default optimization parameters use objects already indexed to tune the hyperparameters, which is too optimistic in real applications, since already indexed objects are particularly easy for this use. We can get a better optimization using external data:\n\noptqueries = MatrixDatabase(rand(Float32, dim, 64))\n\noptimize_index!(G1, C1, MinRecall(0.9); queries=optqueries)\noptimize_index!(G2, C1, MinRecall(0.9); queries=optqueries)\n\nafter optimizing the index its quality and speed are changed\n\ntime1 = @elapsed I1, D1 = searchbatch(G1, C1, queries, k)\ntime2 = @elapsed I2, D2 = searchbatch(G2, C1, queries, k)\n\nrecall1 = macrorecall(goldI, I1)\nrecall2 = macrorecall(goldI, I2)\n\nThese results on the following performances:\n\n\nbuild time:\n\nbuildtime1: 5.628086565\n\nbuildtime2: 0.571731296\n\n\nsearch time:\n\ntime1: 0.001570915\n\ntime2: 0.001412304\n\n\nrecall values:\n\nrecall1: 0.8935833333333316\n\nrecall2: 0.9081666666666651\n\n\n\n\n\nThese scores are much closer to those we are looking for.\nBe careful on doing optimize_index!(..., queries=queries) since this can yield to overfitting on your query set."
  },
  {
    "objectID": "tutorials/automatic-hyperparameter-opt.html#environment-and-dependencies",
    "href": "tutorials/automatic-hyperparameter-opt.html#environment-and-dependencies",
    "title": "Automatic Hyperparameter Optimization",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.9\nCommit 5595d20a287 (2025-03-10 12:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 Ã Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_PROJECT = .\n  JULIA_NUM_THREADS = auto\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/sites/SimilaritySearchDemos/Project.toml`\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.7.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.0 `~/.julia/dev/InvertedFiles`\n  [682c06a0] JSON v0.21.4\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\nâ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.11\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.0 `~/.julia/dev/SimSearchManifoldLearning`\n  [053f045d] SimilaritySearch v0.12.0 `~/.julia/dev/SimilaritySearch`\nâ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.0 `~/.julia/dev/TextSearch`\nInfo Packages marked with â and â have new versions available. Those with â may be upgradable, but those with â are restricted by compatibility constraints from upgrading. To see why use `status --outdated`\nWarning The project dependencies or compat requirements have changed since the manifest was last resolved. It is recommended to `Pkg.resolve()` or consider `Pkg.update()` if necessary."
  },
  {
    "objectID": "tutorials/incremental-construction.html",
    "href": "tutorials/incremental-construction.html",
    "title": "Incremental construction with SearchGraph",
    "section": "",
    "text": "by: Eric S. TÃ©llez\nusing SimilaritySearch\nFor incremental construction we need a database backend that supports incremental insertions. Currently, there are two backends for this: DynamicMatrixDatabase and VectorDatabase:\ndim = 8\ndb = DynamicMatrixDatabase(Float32, dim) # or VectorDatabase(Vector{Float32})\ndist = L1Distance()\nit can use any distance function described in SimilaritySearch and Distances.jl, and in fact any SemiMetric as described in the later package. The index construction is made as follows:\nG = SearchGraph(; dist, db)\nctx = SearchGraphContext()\ninstead of index! we can use push_item! and append_items! functions\nfor _ in 1:10^4\n    push_item!(G, ctx, rand(Float32, dim))  # push_item! inserts one item at a time\nend\nwe can also use append_items! if we have a batch of items\nappend_items!(G, ctx, MatrixDatabase(rand(Float32, dim, 10^4))) # append_items! inserts many items at once\nNote that we used a MatrixDatabase to wrap the matrix to be inserted since it will be copied into the index. Now we have a populated index.\n@assert length(G) == 20_000\nthis will display a lot of information in the console, since as construction advances the hyperparameters of the index are adjusted.\nOnce the index is created, the index can solve nearest neighbor queries\n1Q = MatrixDatabase(rand(dim, 30))\n2k = 5\n3I, D = searchbatch(G, ctx, Q, k)\ndisplay((typeof(I), typeof(D)))\ndisplay((size(I), size(D)))\n\n\n1\n\nCreates the query\n\n2\n\nThe number of nearest neighbors to retrieve\n\n3\n\nSolve queries, returns neighbor identifiers and distances.\n\n\n\n\n(Matrix{Int32}, Matrix{Float32})\n\n\n((5, 30), (5, 30))"
  },
  {
    "objectID": "tutorials/incremental-construction.html#environment-and-dependencies",
    "href": "tutorials/incremental-construction.html#environment-and-dependencies",
    "title": "Incremental construction with SearchGraph",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.9\nCommit 5595d20a287 (2025-03-10 12:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 Ã Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_PROJECT = .\n  JULIA_NUM_THREADS = auto\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/sites/SimilaritySearchDemos/Project.toml`\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.7.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.0 `~/.julia/dev/InvertedFiles`\n  [682c06a0] JSON v0.21.4\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\nâ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.11\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.0 `~/.julia/dev/SimSearchManifoldLearning`\n  [053f045d] SimilaritySearch v0.12.0 `~/.julia/dev/SimilaritySearch`\nâ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.0 `~/.julia/dev/TextSearch`\nInfo Packages marked with â and â have new versions available. Those with â may be upgradable, but those with â are restricted by compatibility constraints from upgrading. To see why use `status --outdated`\nWarning The project dependencies or compat requirements have changed since the manifest was last resolved. It is recommended to `Pkg.resolve()` or consider `Pkg.update()` if necessary."
  },
  {
    "objectID": "tutorials/solving-single-queries.html",
    "href": "tutorials/solving-single-queries.html",
    "title": "Solving single queries",
    "section": "",
    "text": "by: Eric S. TÃ©llez\nusing SimilaritySearch\nThis example shows how to perform single queries instead of solving a batch of them. This is particularly useful for some applications, and we also show how they are solved, which could be used to avoid some memory allocations.\ndim = 8\ndb = MatrixDatabase(randn(Float32, dim, 10^4))\nqueries = db = MatrixDatabase(randn(Float32, dim, 100))\ndist = SqL2Distance()\nG = SearchGraph(; dist, db)\nctx = SearchGraphContext()\nindex!(G, ctx)\nSuppose you want to compute some \\(k\\) nearest neighbors, for this we use the structure KnnResult which is a priority queue of maximum size \\(k\\).\nfor _ in 1:10\n    res = KnnResult(3)\n\n    @time search(G, ctx, randn(Float32, dim), res)\n    @show minimum(res), maximum(res), argmin(res), argmax(res)\n    @show collect(IdView(res))\n    @show collect(DistView(res))\nend\n\n  0.181569 seconds (118.20 k allocations: 7.439 MiB, 99.96% compilation time)\n(minimum(res), maximum(res), argmin(res), argmax(res)) = (5.809701f0, 5.942638f0, 0x00000016, 0x0000000c)\ncollect(IdView(res)) = UInt32[0x00000016, 0x00000043, 0x0000000c]\ncollect(DistView(res)) = Float32[5.809701, 5.835182, 5.942638]\n  0.000016 seconds (3 allocations: 160 bytes)\n(minimum(res), maximum(res), argmin(res), argmax(res)) = (3.823287f0, 5.02922f0, 0x00000012, 0x00000010)\ncollect(IdView(res)) = UInt32[0x00000012, 0x00000020, 0x00000010]\ncollect(DistView(res)) = Float32[3.823287, 4.3830223, 5.02922]\n  0.000005 seconds (3 allocations: 160 bytes)\n(minimum(res), maximum(res), argmin(res), argmax(res)) = (2.145288f0, 2.7880228f0, 0x00000006, 0x00000017)\ncollect(IdView(res)) = UInt32[0x00000006, 0x00000054, 0x00000017]\ncollect(DistView(res)) = Float32[2.145288, 2.73, 2.7880228]\n  0.000005 seconds (3 allocations: 160 bytes)\n(minimum(res), maximum(res), argmin(res), argmax(res)) = (2.0310807f0, 3.5405772f0, 0x0000005f, 0x00000016)\ncollect(IdView(res)) = UInt32[0x0000005f, 0x0000000c, 0x00000016]\ncollect(DistView(res)) = Float32[2.0310807, 3.4354124, 3.5405772]\n  0.000004 seconds (3 allocations: 160 bytes)\n(minimum(res), maximum(res), argmin(res), argmax(res)) = (0.8641082f0, 2.2749689f0, 0x00000012, 0x00000010)\ncollect(IdView(res)) = UInt32[0x00000012, 0x00000026, 0x00000010]\ncollect(DistView(res)) = Float32[0.8641082, 1.4668975, 2.2749689]\n  0.000004 seconds (3 allocations: 160 bytes)\n(minimum(res), maximum(res), argmin(res), argmax(res)) = (2.9604142f0, 4.2328644f0, 0x00000033, 0x0000000c)\ncollect(IdView(res)) = UInt32[0x00000033, 0x00000004, 0x0000000c]\ncollect(DistView(res)) = Float32[2.9604142, 4.0192075, 4.2328644]\n  0.000005 seconds (3 allocations: 160 bytes)\n(minimum(res), maximum(res), argmin(res), argmax(res)) = (2.8505664f0, 6.0536327f0, 0x0000003b, 0x00000011)\ncollect(IdView(res)) = UInt32[0x0000003b, 0x00000063, 0x00000011]\ncollect(DistView(res)) = Float32[2.8505664, 3.903384, 6.0536327]\n  0.000003 seconds (3 allocations: 160 bytes)\n(minimum(res), maximum(res), argmin(res), argmax(res)) = (4.8982854f0, 6.959735f0, 0x0000004a, 0x00000023)\ncollect(IdView(res)) = UInt32[0x0000004a, 0x0000004b, 0x00000023]\ncollect(DistView(res)) = Float32[4.8982854, 5.5592337, 6.959735]\n  0.000004 seconds (3 allocations: 160 bytes)\n(minimum(res), maximum(res), argmin(res), argmax(res)) = (1.3950515f0, 2.9594204f0, 0x0000005f, 0x00000013)\ncollect(IdView(res)) = UInt32[0x0000005f, 0x0000000c, 0x00000013]\ncollect(DistView(res)) = Float32[1.3950515, 2.454435, 2.9594204]\n  0.000003 seconds (3 allocations: 160 bytes)\n(minimum(res), maximum(res), argmin(res), argmax(res)) = (2.1621277f0, 3.9601092f0, 0x0000001c, 0x0000000c)\ncollect(IdView(res)) = UInt32[0x0000001c, 0x00000016, 0x0000000c]\ncollect(DistView(res)) = Float32[2.1621277, 3.524062, 3.9601092]"
  },
  {
    "objectID": "tutorials/solving-single-queries.html#knnresult",
    "href": "tutorials/solving-single-queries.html#knnresult",
    "title": "Solving single queries",
    "section": "KnnResult",
    "text": "KnnResult\nThis structure is the container for the result and it is also used to specify the number of elements to retrieve. As mentioned before, it is a priority queue\n\n\nres = KnnResult(4)\npush_item!(res, 1, 10)\npush_item!(res, 2, 9)\npush_item!(res, 3, 8)\npush_item!(res, 4, 7)\npush_item!(res, 6, 5)\n@show res\n\n# it also supports removals\n@show :popfirst! =&gt; popfirst!(res)\npush_item!(res, 7, 0.1)\n@show :push_item! =&gt; res\n@show :pop! =&gt; pop!(res)\nres\n# It can be iterated\n\n@show collect(res)\n\nres = SimilaritySearch.KnnResult(SimilaritySearch.AdjacencyLists.IdWeight[SimilaritySearch.AdjacencyLists.IdWeight(0x00000006, 5.0f0), SimilaritySearch.AdjacencyLists.IdWeight(0x00000004, 7.0f0), SimilaritySearch.AdjacencyLists.IdWeight(0x00000003, 8.0f0), SimilaritySearch.AdjacencyLists.IdWeight(0x00000002, 9.0f0)], 4)\n:popfirst! =&gt; popfirst!(res) = :popfirst! =&gt; SimilaritySearch.AdjacencyLists.IdWeight(0x00000006, 5.0f0)\n:push_item! =&gt; res = :push_item! =&gt; SimilaritySearch.KnnResult(SimilaritySearch.AdjacencyLists.IdWeight[SimilaritySearch.AdjacencyLists.IdWeight(0x00000007, 0.1f0), SimilaritySearch.AdjacencyLists.IdWeight(0x00000004, 7.0f0), SimilaritySearch.AdjacencyLists.IdWeight(0x00000003, 8.0f0), SimilaritySearch.AdjacencyLists.IdWeight(0x00000002, 9.0f0)], 4)\n:pop! =&gt; pop!(res) = :pop! =&gt; SimilaritySearch.AdjacencyLists.IdWeight(0x00000002, 9.0f0)\ncollect(res) = SimilaritySearch.AdjacencyLists.IdWeight[SimilaritySearch.AdjacencyLists.IdWeight(0x00000007, 0.1f0), SimilaritySearch.AdjacencyLists.IdWeight(0x00000004, 7.0f0), SimilaritySearch.AdjacencyLists.IdWeight(0x00000003, 8.0f0)]\n\n\n3-element Vector{IdWeight}:\n IdWeight(0x00000007, 0.1f0)\n IdWeight(0x00000004, 7.0f0)\n IdWeight(0x00000003, 8.0f0)"
  },
  {
    "objectID": "tutorials/solving-single-queries.html#environment-and-dependencies",
    "href": "tutorials/solving-single-queries.html#environment-and-dependencies",
    "title": "Solving single queries",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.9\nCommit 5595d20a287 (2025-03-10 12:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 Ã Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_PROJECT = .\n  JULIA_NUM_THREADS = auto\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/sites/SimilaritySearchDemos/Project.toml`\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.7.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.0 `~/.julia/dev/InvertedFiles`\n  [682c06a0] JSON v0.21.4\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\nâ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.11\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.0 `~/.julia/dev/SimSearchManifoldLearning`\n  [053f045d] SimilaritySearch v0.12.0 `~/.julia/dev/SimilaritySearch`\nâ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.0 `~/.julia/dev/TextSearch`\nInfo Packages marked with â and â have new versions available. Those with â may be upgradable, but those with â are restricted by compatibility constraints from upgrading. To see why use `status --outdated`\nWarning The project dependencies or compat requirements have changed since the manifest was last resolved. It is recommended to `Pkg.resolve()` or consider `Pkg.update()` if necessary."
  }
]