[
  {
    "objectID": "demos/using-manifoldlearning.html",
    "href": "demos/using-manifoldlearning.html",
    "title": "Using with ManifoldLearning",
    "section": "",
    "text": "by: Eric S. Téllez\nThis demonstration is about using SimilaritySearch and ManifoldLearning methods through SimSearchManifoldLearning.\nusing SimilaritySearch, SimSearchManifoldLearning, ManifoldLearning, Primes, Plots, StatsPlots, StatsBase, LinearAlgebra, Markdown, Random"
  },
  {
    "objectID": "demos/using-manifoldlearning.html#scurve-example",
    "href": "demos/using-manifoldlearning.html#scurve-example",
    "title": "Using with ManifoldLearning",
    "section": "SCurve example",
    "text": "SCurve example\n\nX, L = ManifoldLearning.scurve(segments=5)\n\nscatter(X[1, :], X[2, :], X[3, :], color=L, alpha=0.5)\n\n\n\n\nSimilaritySearch support exact and approximate algorithms to solve k nearest neighbors. Also, it supports different metrics. For instance, let see how the selection of the distance function modifies the projection.\n\nManhattan distance (\\(L_1\\))\n\nlet Y = predict(fit(Isomap, X, nntype=ApproxManhattan))\n    scatter(Y[1,:], Y[2,:], color=L, alpha=0.5)\nend\n\nLOG add_vertex! sp=1 ep=1 n=1 BeamSearch(bsize=4, Δ=1.0, maxvisits=1000000) 2025-09-22T09:33:10.480\nLOG n.size quantiles:[0.0, 0.0, 0.0, 0.0, 0.0]\nLOG add_vertex! sp=514 ep=770 n=513 BeamSearch(bsize=2, Δ=0.8638376, maxvisits=154) 2025-09-22T09:33:13.600\nLOG n.size quantiles:[2.0, 3.0, 3.0, 4.0, 5.0]\n  0.151662 seconds (175.80 k allocations: 11.259 MiB, 99.52% compilation time)\n\n\n\n\n\n\n\nEuclidean distance (\\(L_2\\))\n\nlet\n    E = predict(fit(Isomap, X, nntype=ApproxEuclidean))\n    scatter(E[1,:], E[2,:], color=L, alpha=0.5)\nend\n\nLOG add_vertex! sp=1 ep=1 n=1 BeamSearch(bsize=4, Δ=1.0, maxvisits=1000000) 2025-09-22T09:33:17.135\nLOG n.size quantiles:[0.0, 0.0, 0.0, 0.0, 0.0]\nLOG add_vertex! sp=514 ep=770 n=513 BeamSearch(bsize=4, Δ=0.84224164, maxvisits=130) 2025-09-22T09:33:18.230\nLOG n.size quantiles:[2.0, 3.0, 3.0, 3.0, 4.0]\n  0.129605 seconds (167.92 k allocations: 10.729 MiB, 99.69% compilation time)\n\n\n\n\n\n\n\nChebyshev distance (\\(L_\\infty\\))\n\nlet\n    Ch = predict(fit(Isomap, X, nntype=ApproxChebyshev))\n    scatter(Ch[1,:], Ch[2,:], color=L, alpha=0.5)\nend\n\nLOG add_vertex! sp=1 ep=1 n=1 BeamSearch(bsize=4, Δ=1.0, maxvisits=1000000) 2025-09-22T09:33:21.299\nLOG n.size quantiles:[0.0, 0.0, 0.0, 0.0, 0.0]\nLOG add_vertex! sp=514 ep=770 n=513 BeamSearch(bsize=2, Δ=1.05, maxvisits=180) 2025-09-22T09:33:22.509\nLOG n.size quantiles:[1.0, 3.0, 3.0, 4.0, 5.0]\n  0.129050 seconds (167.93 k allocations: 10.730 MiB, 99.52% compilation time)"
  },
  {
    "objectID": "demos/using-manifoldlearning.html#visualizing-prime-gaps",
    "href": "demos/using-manifoldlearning.html#visualizing-prime-gaps",
    "title": "Using with ManifoldLearning",
    "section": "Visualizing prime gaps",
    "text": "Visualizing prime gaps\nThe difference between contiguous prime numbers is called a Prime gap. We use this series of values as a time series example due to its interesting behavior and since it can be computed without downloading more than the necessary packages.\nThis example shows how to generate the dataset and index it. We will use the ManifoldLearning for generating the 2d visualization.\n\nGeneration of the dataset\nThe time series is represented with windows of size w, we also take log of gaps to reduce variance in gap values. We create a matrix to avoid redefinition of the knn interface for ManifoldLearning.\n\nfunction create_database_primes_diff(n, w)\n    T = log2.(diff(primes(n)))\n    M = Matrix{Float32}(undef, w, length(T) - w)\n    @info size(M)\n    for i in 1:size(M, 2)\n        M[:, i] .= view(T, i:(i+w-1))\n    end\n\n    M\nend\n\n\nx, y = let\n    P = create_database_primes_diff(3 * 10^4, 5)\n    # or LLE\n    primesgap = fit(Isomap, P; k=16, maxoutdim=2, nntype=ApproxEuclidean)\n    \n    p = predict(primesgap)\n    p[1, :], p[2, :]\nend\n\nA 2D histogram\n\nhistogram2d(x, y; nbins=100)"
  },
  {
    "objectID": "demos/using-manifoldlearning.html#environment-and-dependencies",
    "href": "demos/using-manifoldlearning.html#environment-and-dependencies",
    "title": "Using with ManifoldLearning",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.10\nCommit 95f30e51f41 (2025-06-27 09:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 × Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_NUM_THREADS = auto\n  JULIA_PROJECT = .\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/Research/SimilaritySearchDemos/Project.toml`\n  [aaaa29a8] Clustering v0.15.8\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.8.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.1\n  [682c06a0] JSON v0.21.4\n  [23fbe1c1] Latexify v0.16.10\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\n⌃ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.20\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.1\n  [053f045d] SimilaritySearch v0.13.0\n⌅ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.6\nInfo Packages marked with ⌃ and ⌅ have new versions available. Those with ⌃ may be upgradable, but those with ⌅ are restricted by compatibility constraints from upgrading. To see why use `status --outdated`"
  },
  {
    "objectID": "demos/primes.html",
    "href": "demos/primes.html",
    "title": "Prime numbers",
    "section": "",
    "text": "by: Eric S. Téllez\nThis demonstration is about prime numbers and its similarity based on its factors. This is a well-known demonstration of SimSearchManifoldLearning.jl. This notebook does not requires to download any dataset.\nNote: This example needs a lot of computing power; therefore you may want to set the environment variable JULIA_NUM_THREADS=auto before running julia.\nusing SimilaritySearch, SimSearchManifoldLearning, Primes, Plots, StatsBase, LinearAlgebra, Markdown, Random\nNow, we can define our dataset. The set of factors are found using the Primes package. Note that we use VectorDatabase to represent the dataset.\nn = 100_000\nF = Vector{Vector{Int32}}(undef, n+1)\n\nfunction encode_factors(num)\n    sort!(Int32[convert(Int32, f) for f in factor(Set, num)])\nend\n\nF[1] = Int32[1]\n\nfor i in 2:n+1\n    s = encode_factors(i)\n    F[i] = s\nend\n\ndb = VectorDatabase(F)\n#dist = JaccardDistance()  # Other distances from SimilaritySearch\n#dist = IntersectionDissimilarity()\n#dist = CosineDistanceSet()\ndist = DiceDistance()\nWe use Int32 ordered arrays to store prime factors to represent each integer. In the following cell define the cosine distance equivalent for this representation. While other representations may perform faster, this is quite straighforward and demonstrates the use of user’s defined distance functions."
  },
  {
    "objectID": "demos/primes.html#index-construction",
    "href": "demos/primes.html#index-construction",
    "title": "Prime numbers",
    "section": "Index construction",
    "text": "Index construction\nNote that the primes factors are pretty large for some large \\(n\\) and this imply challengues for metric indexes (since it is related with the intrinsic dimension of the dataset). We used a kernel that starts 64 threads, it solves \\(100000\\) in a few seconds but it can take pretty large time using single threads and larger \\(n\\) values. The construction of the index is used by the visualization algorithm (UMAP) to construct an all-knn graph, which can be a quite costly procedure.\n\nG = SearchGraph(; db, dist)\n1ctx = SearchGraphContext(hyperparameters_callback=OptimizeParameters(MinRecall(0.95)))\n2index!(G, ctx)\n3optimize_index!(G, ctx, MinRecall(0.9))\n\n\n1\n\nDefines the index and the search context (caches and hyperparameters); particularly, we use a very high quality build MinRecall(0.95); high quality constructions yield to faster queries due to the underlying graph structure.\n\n2\n\nActual indexing procedure using the given search context.\n\n3\n\nOptimizing the index to trade quality and speed."
  },
  {
    "objectID": "demos/primes.html#visualizing-with-umap-projection",
    "href": "demos/primes.html#visualizing-with-umap-projection",
    "title": "Prime numbers",
    "section": "Visualizing with UMAP projection",
    "text": "Visualizing with UMAP projection\nWe select to initialize the embedding randomly, this could yield to low quality embeddings, but it is much faster than other techniques like spectral layout. Note that we pass the Search graph G. We also use a second call to compute a 3D embedding for computing a kind of colour embedding, here we pass U2 to avoid recomputing several of the involved structures.\n\nfunction normcolors(V)\n    min_, max_ = extrema(V)\n    V .= (V .- min_) ./ (max_ - min_)\n    V .= clamp.(V, 0, 1)\nend\n\nnormcolors(@view e3[1, :])\nnormcolors(@view e3[2, :])\nnormcolors(@view e3[3, :])\n\nlet C = [RGB(c[1], c[2], c[3]) for c in eachcol(e3)],\n    X = view(e2, 1, :),\n    Y = view(e2, 2, :)\n    scatter(X, Y, color=C, fmt=:png, alpha=0.2, size=(600, 600), ma=0.3, ms=2, msw=0, label=\"\", yticks=nothing, xticks=nothing, xaxis=false, yaxis=false)\nend\n\nplot!()\n\n\n\n\n\ne2, e3 = let min_dist=0.5f0,\n             k=20,\n             n_epochs=75,\n             neg_sample_rate=3,\n             tol=1e-3,\n             layout=SpectralLayout()\n\n    @time \"Compute 2D UMAP model\" U2 = fit(UMAP, G; k, neg_sample_rate, layout, n_epochs, tol, min_dist)\n    @time \"Compute 3D UMAP model\" U3 = fit(U2, 3; neg_sample_rate, n_epochs, tol)\n    @time \"predicting 2D embeddings\" e2 = clamp.(predict(U2), -10f0, 10f0)\n    @time \"predicting 3D embeddings\" e3 = clamp.(predict(U3), -10f0, 10f0)\n    e2, e3\nend"
  },
  {
    "objectID": "demos/primes.html#environment-and-dependencies",
    "href": "demos/primes.html#environment-and-dependencies",
    "title": "Prime numbers",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.10\nCommit 95f30e51f41 (2025-06-27 09:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 × Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_NUM_THREADS = auto\n  JULIA_PROJECT = .\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/Research/SimilaritySearchDemos/Project.toml`\n  [aaaa29a8] Clustering v0.15.8\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.8.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.1\n  [682c06a0] JSON v0.21.4\n  [23fbe1c1] Latexify v0.16.10\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\n⌃ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.20\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.1\n  [053f045d] SimilaritySearch v0.13.0\n⌅ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.6\nInfo Packages marked with ⌃ and ⌅ have new versions available. Those with ⌃ may be upgradable, but those with ⌅ are restricted by compatibility constraints from upgrading. To see why use `status --outdated`"
  },
  {
    "objectID": "demos/mnist.html",
    "href": "demos/mnist.html",
    "title": "Visualizing MNIST database",
    "section": "",
    "text": "by: Eric S. Téllez\nThis example creates a visualization of the MNIST images (hand written digits) using MLDatasets.jl to retrieve it.\nNote: This example needs a lot of computing power; therefore you may want to set the environment variable JULIA_NUM_THREADS=auto before running julia.\nusing SimilaritySearch, SimSearchManifoldLearning, Plots, StatsBase, LinearAlgebra, Markdown, MLDatasets, Random\ndb, y, dist = let data = MNIST(split=:train)\n    T, y = data.features, data.targets\n    n = size(T, 3)\n    MatrixDatabase(Float32.(reshape(T, (28*28, n)))), y, SqL2_asf32()\nend\nNow we can create the index\n1index = SearchGraph(; dist, db)\nctx = SearchGraphContext(hyperparameters_callback=OptimizeParameters(MinRecall(0.99)))\n2index!(index, ctx)\n3optimize_index!(index, ctx, MinRecall(0.95))\n\n\n1\n\nDefines the index and the search context (caches and hyperparameters); particularly, we use a very high quality build MinRecall(0.99); high quality constructions yield to faster queries due to the underlying graph structure.\n\n2\n\nActual indexing procedure using the given search context.\n\n3\n\nOptimizing the index to trade quality and speed."
  },
  {
    "objectID": "demos/mnist.html#umap-visualization",
    "href": "demos/mnist.html#umap-visualization",
    "title": "Visualizing MNIST database",
    "section": "UMAP Visualization",
    "text": "UMAP Visualization\n\nfunction normcolors(V)\n    min_, max_ = extrema(V)\n    V .= (V .- min_) ./ (max_ - min_)\n    V .= clamp.(V, 0, 1)\nend\n\nnormcolors(@view e3[1, :])\nnormcolors(@view e3[2, :])\nnormcolors(@view e3[3, :])\n\nlet C = [RGB(c[1], c[2], c[3]) for c in eachcol(e3)],\n    X = view(e2, 1, :),\n    Y = view(e2, 2, :)\n    scatter(X, Y, color=C, fmt=:png, alpha=0.2, size=(600, 600), ma=0.3, ms=2, msw=0, label=\"\", yticks=nothing, xticks=nothing, xaxis=false, yaxis=false)\n    for i in 1:100\n        j = rand(1:length(y))\n        annotate!(X[j], Y[j], text(y[j], :black, :right, 8, \"noto\"))\n    end\nend\n\nplot!()\n\n\n\n\n\ne2, e3 = let min_dist=0.5f0,\n             k=7,\n             n_epochs=75,\n             neg_sample_rate=3,\n             tol=1e-3,\n             layout=SpectralLayout()\n\n    @time \"Compute 2D UMAP model\" U2 = fit(UMAP, index; k, neg_sample_rate, layout, n_epochs, tol, min_dist)\n    @time \"Compute 3D UMAP model\" U3 = fit(U2, 3; neg_sample_rate, n_epochs, tol)\n    @time \"predicting 2D embeddings\" e2 = clamp.(predict(U2), -10f0, 10f0)\n    @time \"predicting 3D embeddings\" e3 = clamp.(predict(U3), -10f0, 10f0)\n    e2, e3\nend"
  },
  {
    "objectID": "demos/mnist.html#final-notes",
    "href": "demos/mnist.html#final-notes",
    "title": "Visualizing MNIST database",
    "section": "Final notes",
    "text": "Final notes\nThis example shows how to index and visualize the MNIST dataset using UMAP low dimensional projections. Low dimensional projections are made with SimSearchManifoldLearning, note that SimilaritySearch is also used for computing the all \\(k\\) nearest neighbors needed by the UMAP model. Note that this notebook should be ran with several threads to reduce time costs."
  },
  {
    "objectID": "demos/mnist.html#environment-and-dependencies",
    "href": "demos/mnist.html#environment-and-dependencies",
    "title": "Visualizing MNIST database",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.10\nCommit 95f30e51f41 (2025-06-27 09:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 × Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_NUM_THREADS = auto\n  JULIA_PROJECT = .\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/Research/SimilaritySearchDemos/Project.toml`\n  [aaaa29a8] Clustering v0.15.8\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.8.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.1\n  [682c06a0] JSON v0.21.4\n  [23fbe1c1] Latexify v0.16.10\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\n⌃ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.20\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.1\n  [053f045d] SimilaritySearch v0.13.0\n⌅ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.6\nInfo Packages marked with ⌃ and ⌅ have new versions available. Those with ⌃ may be upgradable, but those with ⌅ are restricted by compatibility constraints from upgrading. To see why use `status --outdated`"
  },
  {
    "objectID": "demos/glove.html",
    "href": "demos/glove.html",
    "title": "Visualizing Twitter Messages with Emojis",
    "section": "",
    "text": "by: Eric S. Téllez\nThis example creates a visualization of Glove word embeddings using Embeddings.jl package to fetch them.\nNote: This example needs a lot of computing power; therefore you may want to set the environment variable JULIA_NUM_THREADS=auto before running julia.\nusing SimilaritySearch, SimSearchManifoldLearning, TextSearch, CodecZlib, JSON, DataFrames, Plots, StatsBase, LinearAlgebra, Markdown, Embeddings, Random\nusing Downloads: download\nemb, vocab = let emb = load_embeddings(GloVe{:en}, 2)  # you can change with any of the available embeddings in `Embeddings`\n    for c in eachcol(emb.embeddings)\n1        normalize!(c)\n    end\n\n2    Float16.(emb.embeddings), emb.vocab\nend\n\n3dist = NormalizedCosine_asf32()\n4vocab2id = Dict(w =&gt; i for (i, w) in enumerate(vocab))\n\n\n1\n\nNormalizes all vectors to have a unitary norm; this allow us to use the dot product as similarity (see point 3)\n\n2\n\nThe speed can be improved through memory’s bandwidth using less memory per vector; using Float16 as memory representation is a good idea even if your computer doesn’t support 16-bit floating point arithmetic natively.\n\n3\n\nSince we have unitary norm vectors we can simplify the cosine distance (i.e., \\(1 - dot(\\cdot, \\cdot)\\)); note that we are using Float16 and the suffix _asf32 will select a distance function that converts numbers to Float32 just before performing arithmetic operations.\n\n4\n\nInverse map from words to identifiers in vocab.\nNow we can create the index\n1index = SearchGraph(; dist, db=MatrixDatabase(emb))\nctx = SearchGraphContext(hyperparameters_callback=OptimizeParameters(MinRecall(0.99)))\n2index!(index, ctx)\n3optimize_index!(index, ctx, MinRecall(0.9))\n\n\n1\n\nDefines the index and the search context (caches and hyperparameters); particularly, we use a very high quality build MinRecall(0.99); high quality constructions yield to faster queries due to the underlying graph structure.\n\n2\n\nActual indexing procedure using the given search context.\n\n3\n\nOptimizing the index to trade quality and speed."
  },
  {
    "objectID": "demos/glove.html#umap-visualization",
    "href": "demos/glove.html#umap-visualization",
    "title": "Visualizing Twitter Messages with Emojis",
    "section": "UMAP Visualization",
    "text": "UMAP Visualization\n\nfunction normcolors(V)\n    min_, max_ = extrema(V)\n    V .= (V .- min_) ./ (max_ - min_)\n    V .= clamp.(V, 0, 1)\nend\n\nnormcolors(@view e3[1, :])\nnormcolors(@view e3[2, :])\nnormcolors(@view e3[3, :])\n\nlet C = [RGB(c[1], c[2], c[3]) for c in eachcol(e3)],\n    X = view(e2, 1, :),\n    Y = view(e2, 2, :)\n    scatter(X, Y, color=C, fmt=:png, alpha=0.2, size=(600, 600), ma=0.3, ms=2, msw=0, label=\"\", yticks=nothing, xticks=nothing, xaxis=false, yaxis=false)\nend\n\nplot!()\n\n\n\n\n\ne2, e3 = let min_dist=0.5f0,\n             k=12,\n             n_epochs=75,\n             neg_sample_rate=3,\n             tol=1e-3,\n             layout=RandomLayout()\n\n    @time \"Compute 2D UMAP model\" U2 = fit(UMAP, index; k, neg_sample_rate, layout, n_epochs, tol, min_dist)\n    @time \"Compute 3D UMAP model\" U3 = fit(U2, 3; neg_sample_rate, n_epochs, tol)\n    @time \"predicting 2D embeddings\" e2 = clamp.(predict(U2), -10f0, 10f0)\n    @time \"predicting 3D embeddings\" e3 = clamp.(predict(U3), -10f0, 10f0)\n    e2, e3\nend"
  },
  {
    "objectID": "demos/glove.html#final-notes",
    "href": "demos/glove.html#final-notes",
    "title": "Visualizing Twitter Messages with Emojis",
    "section": "Final notes",
    "text": "Final notes\nThis example shows how to index and search dense vector databases, in particular GloVe word embeddings using the cosine distance. Low dimensional projections are made with SimSearchManifoldLearning, note that SimilaritySearch is also used for computing the all \\(k\\) nearest neighbors needed by the UMAP model. Note that this notebook should be ran with several threads to reduce time costs."
  },
  {
    "objectID": "demos/glove.html#environment-and-dependencies",
    "href": "demos/glove.html#environment-and-dependencies",
    "title": "Visualizing Twitter Messages with Emojis",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.10\nCommit 95f30e51f41 (2025-06-27 09:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 × Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_NUM_THREADS = auto\n  JULIA_PROJECT = .\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/Research/SimilaritySearchDemos/Project.toml`\n  [aaaa29a8] Clustering v0.15.8\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.8.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.1\n  [682c06a0] JSON v0.21.4\n  [23fbe1c1] Latexify v0.16.10\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\n⌃ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.20\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.1\n  [053f045d] SimilaritySearch v0.13.0\n⌅ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.6\nInfo Packages marked with ⌃ and ⌅ have new versions available. Those with ⌃ may be upgradable, but those with ⌅ are restricted by compatibility constraints from upgrading. To see why use `status --outdated`"
  },
  {
    "objectID": "tutorials/solving-single-queries.html",
    "href": "tutorials/solving-single-queries.html",
    "title": "Solving single queries",
    "section": "",
    "text": "by: Eric S. Téllez\nusing SimilaritySearch\nThis example shows how to perform single queries instead of solving a batch of them. This is particularly useful for some applications, and we also show how they are solved, which could be used to avoid some memory allocations.\ndim = 8\ndb = MatrixDatabase(randn(Float32, dim, 10^4))\nqueries = db = MatrixDatabase(randn(Float32, dim, 100))\ndist = SqL2Distance()\nG = SearchGraph(; dist, db)\nctx = SearchGraphContext()\nindex!(G, ctx)\nSuppose you want to compute some \\(k\\) nearest neighbors, for this we use the structure KnnResult which is a priority queue of maximum size \\(k\\).\nfor _ in 1:10\n    res = knnqueue(ctx, 3)\n\n    @time search(G, ctx, randn(Float32, dim), res)\n    @show minimum(res), maximum(res), argmin(res), argmax(res)\n    @show collect(IdView(res))\n    @show collect(DistView(res))\nend\n\n  0.302833 seconds (154.11 k allocations: 10.185 MiB, 99.98% compilation time)\n(minimum(res), maximum(res), argmin(res), argmax(res)) = (5.73508f0, 8.136073f0, 0x00000047, 0x00000049)\ncollect(IdView(res)) = UInt32[0x00000047, 0x0000000c, 0x00000049]\ncollect(DistView(res)) = Float32[5.73508, 8.045934, 8.136073]\n  0.000016 seconds (2 allocations: 128 bytes)\n(minimum(res), maximum(res), argmin(res), argmax(res)) = (2.4517207f0, 4.1300344f0, 0x00000054, 0x0000001a)\ncollect(IdView(res)) = UInt32[0x00000054, 0x0000002d, 0x0000001a]\ncollect(DistView(res)) = Float32[2.4517207, 3.6453025, 4.1300344]\n  0.000007 seconds (2 allocations: 128 bytes)\n(minimum(res), maximum(res), argmin(res), argmax(res)) = (5.665649f0, 6.3988633f0, 0x00000019, 0x0000003d)\ncollect(IdView(res)) = UInt32[0x00000019, 0x00000022, 0x0000003d]\ncollect(DistView(res)) = Float32[5.665649, 6.12617, 6.3988633]\n  0.000006 seconds (2 allocations: 128 bytes)\n(minimum(res), maximum(res), argmin(res), argmax(res)) = (4.363997f0, 6.268838f0, 0x0000000c, 0x00000029)\ncollect(IdView(res)) = UInt32[0x0000000c, 0x00000025, 0x00000029]\ncollect(DistView(res)) = Float32[4.363997, 4.8510885, 6.268838]\n  0.000005 seconds (2 allocations: 128 bytes)\n(minimum(res), maximum(res), argmin(res), argmax(res)) = (1.9081182f0, 3.2303193f0, 0x00000061, 0x00000054)\ncollect(IdView(res)) = UInt32[0x00000061, 0x0000000d, 0x00000054]\ncollect(DistView(res)) = Float32[1.9081182, 2.8516128, 3.2303193]\n  0.000004 seconds (2 allocations: 128 bytes)\n(minimum(res), maximum(res), argmin(res), argmax(res)) = (3.5657682f0, 7.0970955f0, 0x0000002a, 0x0000003e)\ncollect(IdView(res)) = UInt32[0x0000002a, 0x00000056, 0x0000003e]\ncollect(DistView(res)) = Float32[3.5657682, 6.842711, 7.0970955]\n  0.000004 seconds (2 allocations: 128 bytes)\n(minimum(res), maximum(res), argmin(res), argmax(res)) = (1.0025893f0, 2.340893f0, 0x00000017, 0x0000000d)\ncollect(IdView(res)) = UInt32[0x00000017, 0x0000000c, 0x0000000d]\ncollect(DistView(res)) = Float32[1.0025893, 1.2908223, 2.340893]\n  0.000005 seconds (2 allocations: 128 bytes)\n(minimum(res), maximum(res), argmin(res), argmax(res)) = (2.1722112f0, 5.5402813f0, 0x00000027, 0x00000002)\ncollect(IdView(res)) = UInt32[0x00000027, 0x00000021, 0x00000002]\ncollect(DistView(res)) = Float32[2.1722112, 4.0453386, 5.5402813]\n  0.000004 seconds (2 allocations: 128 bytes)\n(minimum(res), maximum(res), argmin(res), argmax(res)) = (1.3056961f0, 3.5194216f0, 0x00000060, 0x00000062)\ncollect(IdView(res)) = UInt32[0x00000060, 0x00000023, 0x00000062]\ncollect(DistView(res)) = Float32[1.3056961, 3.0779376, 3.5194216]\n  0.000003 seconds (2 allocations: 128 bytes)\n(minimum(res), maximum(res), argmin(res), argmax(res)) = (2.4991374f0, 4.457182f0, 0x0000000d, 0x00000034)\ncollect(IdView(res)) = UInt32[0x0000000d, 0x0000001c, 0x00000034]\ncollect(DistView(res)) = Float32[2.4991374, 3.6591063, 4.457182]"
  },
  {
    "objectID": "tutorials/solving-single-queries.html#knn-queue",
    "href": "tutorials/solving-single-queries.html#knn-queue",
    "title": "Solving single queries",
    "section": "Knn queue",
    "text": "Knn queue\nThis structure is the container for the result and it is also used to specify the number of elements to retrieve. As mentioned before, it is a priority queue\n\n\nres = knnqueue(ctx, 4)\npush_item!(res, 1, 10)\npush_item!(res, 2, 9)\npush_item!(res, 3, 8)\npush_item!(res, 4, 7)\npush_item!(res, 6, 5)\n@show collect(viewitems(res))\n\n# it also supports removals; yet `pop_min!` is not exported since currently is available only for `KnnSorted` queue backend.\n@show :pop_min! =&gt; SimilaritySearch.pop_min!(res) \npush_item!(res, 7, 0.1)\n@show :push_item! =&gt; res\n@show :pop_max! =&gt; pop_max!(res)\nres\n# It can be iterated\n\n@show collect(viewitems(res))\n\ncollect(viewitems(res)) = SimilaritySearch.AdjacencyLists.IdWeight[SimilaritySearch.AdjacencyLists.IdWeight(0x00000006, 5.0f0), SimilaritySearch.AdjacencyLists.IdWeight(0x00000004, 7.0f0), SimilaritySearch.AdjacencyLists.IdWeight(0x00000003, 8.0f0), SimilaritySearch.AdjacencyLists.IdWeight(0x00000002, 9.0f0)]\n:pop_min! =&gt; SimilaritySearch.pop_min!(res) = :pop_min! =&gt; SimilaritySearch.AdjacencyLists.IdWeight(0x00000006, 5.0f0)\n:push_item! =&gt; res = :push_item! =&gt; SimilaritySearch.KnnSorted{Vector{SimilaritySearch.AdjacencyLists.IdWeight}}(SimilaritySearch.AdjacencyLists.IdWeight[SimilaritySearch.AdjacencyLists.IdWeight(0x00000007, 0.1f0), SimilaritySearch.AdjacencyLists.IdWeight(0x00000004, 7.0f0), SimilaritySearch.AdjacencyLists.IdWeight(0x00000003, 8.0f0), SimilaritySearch.AdjacencyLists.IdWeight(0x00000002, 9.0f0)], 1, 4, 4, 0, 0)\n:pop_max! =&gt; pop_max!(res) = :pop_max! =&gt; SimilaritySearch.AdjacencyLists.IdWeight(0x00000002, 9.0f0)\ncollect(viewitems(res)) = SimilaritySearch.AdjacencyLists.IdWeight[SimilaritySearch.AdjacencyLists.IdWeight(0x00000007, 0.1f0), SimilaritySearch.AdjacencyLists.IdWeight(0x00000004, 7.0f0), SimilaritySearch.AdjacencyLists.IdWeight(0x00000003, 8.0f0)]\n\n\n3-element Vector{IdWeight}:\n IdWeight(0x00000007, 0.1f0)\n IdWeight(0x00000004, 7.0f0)\n IdWeight(0x00000003, 8.0f0)"
  },
  {
    "objectID": "tutorials/solving-single-queries.html#environment-and-dependencies",
    "href": "tutorials/solving-single-queries.html#environment-and-dependencies",
    "title": "Solving single queries",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.10\nCommit 95f30e51f41 (2025-06-27 09:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 × Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_NUM_THREADS = auto\n  JULIA_PROJECT = .\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/Research/SimilaritySearchDemos/Project.toml`\n  [aaaa29a8] Clustering v0.15.8\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.8.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.1\n  [682c06a0] JSON v0.21.4\n  [23fbe1c1] Latexify v0.16.10\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\n⌃ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.20\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.1\n  [053f045d] SimilaritySearch v0.13.0\n⌅ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.6\nInfo Packages marked with ⌃ and ⌅ have new versions available. Those with ⌃ may be upgradable, but those with ⌅ are restricted by compatibility constraints from upgrading. To see why use `status --outdated`"
  },
  {
    "objectID": "tutorials/index.html",
    "href": "tutorials/index.html",
    "title": "Tutorials",
    "section": "",
    "text": "Basic usage - Euclidean distance, Random 2D points.\nIncremental construction - Manhattan distance, Random 8D points.\nAutomatic hyperparameter optimization - Squared Euclidean distance Random 16D points.\nSolving single queries - Euclidean distance, Random points.\nParallel construction and search - Euclidean distance, Random 2D points."
  },
  {
    "objectID": "tutorials/basic-usage.html",
    "href": "tutorials/basic-usage.html",
    "title": "Using the SimilaritySearch package",
    "section": "",
    "text": "by: Eric S. Téllez\nusing SimilaritySearch, Markdown\nThis is a small tutorial showing a minimum example for working with SimilaritySearch it accepts several options that are let to defaults. While this should be enough for many purposes, you are invited to see the rest of the tutorials to take advantage of other features.\nMatrixDatabase is a required wrapper that tells SimilaritySearch how to access underlying objects since it can support different kinds of objects. In this setup, each column is an object and will be accessed through views using the MatrixDatabase. Since the backend doesn’t support appends or pushes, the index can be seen as an static index.\nfunction synthetic_benchmark(n, m, dim)\n    db = MatrixDatabase(randn(Float32, dim, n))\n    queries = MatrixDatabase(randn(Float32, dim, m))\n    dist = SqL2Distance()\n    (; db, queries, dist)\nend\nit can use any distance function described in SimilaritySearch and Distances.jl, and in fact any SemiMetric as described in the later package. The index construction is made as follows\nB = synthetic_benchmark(3000, 50, 2)\nG = SearchGraph(; B.dist, B.db)\nctx = SearchGraphContext()\nindex!(G, ctx)\nthis will display a lot of information in the console, since as construction advances the hyperparameters of the index are adjusted. The default optimization try to get a recall of 0.9 which is a typical tradeoff between quality and speed. Once the index is created, the index can solve nearest neighbor queries\nk = 16\n1knns = searchbatch(G, ctx, B.queries, k)\n\n\n1\n\nThe searchbatch functions takes a set of queries and solve them using the given index. knns is a matrix with identifiers and their corresponding distances packed into a special structure IdWeight."
  },
  {
    "objectID": "tutorials/basic-usage.html#visualizing-what-we-just-did",
    "href": "tutorials/basic-usage.html#visualizing-what-we-just-did",
    "title": "Using the SimilaritySearch package",
    "section": "Visualizing what we just did",
    "text": "Visualizing what we just did\n\nusing Plots\n\nscatter(B.db.matrix[1, :], B.db.matrix[2, :], size=(600, 600), color=:cyan, ma=0.3, a=0.3, ms=1, msw=0, label=\"\")\nfor c in eachcol(knns)\n    R = B.db.matrix[:, sort!(collect(IdView(c)))]\n    @views scatter!(R[1, :], R[2, :], m=:diamond, ma=0.3, a=0.3, color=:auto, ms=2, msw=0, label=\"\")\nend\n\n@views scatter!(B.queries.matrix[1, :], B.queries.matrix[2, :], color=:black, m=:star, ma=0.5, a=0.5, ms=4, msw=0, label=\"\")\n\nplot!()\n\n\n\n\nCyan points identify the dataset while starts are query points. The nearest neighbor points are colored automatically and can repeat, but they come quite close to query points, in dense areas they are even hidding them."
  },
  {
    "objectID": "tutorials/basic-usage.html#environment-and-dependencies",
    "href": "tutorials/basic-usage.html#environment-and-dependencies",
    "title": "Using the SimilaritySearch package",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.10\nCommit 95f30e51f41 (2025-06-27 09:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 × Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_NUM_THREADS = auto\n  JULIA_PROJECT = .\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/Research/SimilaritySearchDemos/Project.toml`\n  [aaaa29a8] Clustering v0.15.8\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.8.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.1\n  [682c06a0] JSON v0.21.4\n  [23fbe1c1] Latexify v0.16.10\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\n⌃ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.20\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.1\n  [053f045d] SimilaritySearch v0.13.0\n⌅ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.6\nInfo Packages marked with ⌃ and ⌅ have new versions available. Those with ⌃ may be upgradable, but those with ⌅ are restricted by compatibility constraints from upgrading. To see why use `status --outdated`"
  },
  {
    "objectID": "tutorials/allknn.html",
    "href": "tutorials/allknn.html",
    "title": "Computing all \\(k\\) nearest neighbors",
    "section": "",
    "text": "by: Eric S. Téllez"
  },
  {
    "objectID": "tutorials/allknn.html#introduction",
    "href": "tutorials/allknn.html#introduction",
    "title": "Computing all \\(k\\) nearest neighbors",
    "section": "Introduction",
    "text": "Introduction\nComputing the \\(k\\) nearest neighbors of a dataset (a.k.a. allknn) is a useful task to take knowledge of a given dataset. This is a fundamental problem for some clustering algorithms and non-linear dimensional reduction algorithms.\nGiven a metric database \\((X, dist)\\) and a relatively small \\(k\\) value, the goal is to compute \\(\\{ knn(x) \\mid x \\in X \\}\\) taking into account that each \\(x_i \\in X\\), and therefore, \\(x_i\\) should be removed from the \\(i\\)-th \\(knn\\) result set.\nSolving allknn fast and accuratelly is the goal of this example."
  },
  {
    "objectID": "tutorials/allknn.html#initializing-our-notebook",
    "href": "tutorials/allknn.html#initializing-our-notebook",
    "title": "Computing all \\(k\\) nearest neighbors",
    "section": "Initializing our notebook",
    "text": "Initializing our notebook\nThe first step is to load our basic packages\n\nusing SimilaritySearch, Markdown\n\nwe will use a synthetic dataset\n\nfunction synthetic_benchmark(n, dim)\n1    db = MatrixDatabase(randn(Float32, dim, n))\n2    dist = SqL2Distance()\n3    (; db, dist)\nend\n\n\n1\n\nGenerate \\(n\\) random vectors, of \\(dim\\) dimension. Note that we wrap the matrix as MatrixDatabase to let our index that this is a database; this is necessary since we typically can change the type of objects and distance functions to work.\n\n2\n\nThe squared Euclidean distance; it preserves the order than plain Euclidean distance, but it is faster.\n\n3\n\nReturns a named tuple with the dataset and the distance.\n\n\n\n\n\n1B = synthetic_benchmark(10^5, 16)\n2k = 8\n3etime = @elapsed gold_knns = allknn(ExhaustiveSearch(; B.db, B.dist),  GenericContext(), k)\n\n\n1\n\nCreates a synthetic dataset of dimension \\(16\\) and \\(10^5\\) points.\n\n2\n\nThe number of neighbors to be fetched.\n\n3\n\nCreates a gold standard for testing and comparing.\n\n\n\n\n\nG = SearchGraph(; B.dist, B.db)\n2ctx = SearchGraphContext()\n3itime = @elapsed index!(G, ctx)\n4atime = @elapsed knns = allknn(G, ctx, k)\n\n\n2\n\nDefines the SearchGraph index; it does not indexes anything yet!\n\n3\n\nDefines a search context, it contains several hyperparameters that will be applied for the indexing process, default values just work for now.\n\n4\n\nThe actual indexing."
  },
  {
    "objectID": "tutorials/allknn.html#differences-between-allknng-k-and-searchbatchg-x-k",
    "href": "tutorials/allknn.html#differences-between-allknng-k-and-searchbatchg-x-k",
    "title": "Computing all \\(k\\) nearest neighbors",
    "section": "Differences between allknn(G, k) and searchbatch(G, X, k)",
    "text": "Differences between allknn(G, k) and searchbatch(G, X, k)\nWe can solve similarly with searchbatch but self-references should be removed later, and more important, allknn use special pivoting/boosting strategies that yields to faster searches.\n\nstime = @elapsed sknns = searchbatch(G, ctx, B.db, k)"
  },
  {
    "objectID": "tutorials/allknn.html#comparing-solutions",
    "href": "tutorials/allknn.html#comparing-solutions",
    "title": "Computing all \\(k\\) nearest neighbors",
    "section": "Comparing solutions",
    "text": "Comparing solutions\nWe can measure the quality of SearchGraph in its different modalities against the exhaustive search (exact) solution.\n\nallknn_recall = macrorecall(gold_knns, knns)\nsearch_recall = macrorecall(gold_knns, sknns)\n\n\n\nTimes:\n\nindexing: 18.166401396\n\nallknn with SearchGraph: 0.515946127\n\nsearchbatch with SearchGraph: 1.013383502\n\nallknn with Exhaustivesearch: 9.123408697\n\n\nThe search and recall tradeoff:\n\nallknn (SearchGraph): 0.93061875\n\nsearchbatch (SearchGraph): 0.9358525"
  },
  {
    "objectID": "tutorials/allknn.html#final-notes",
    "href": "tutorials/allknn.html#final-notes",
    "title": "Computing all \\(k\\) nearest neighbors",
    "section": "Final notes",
    "text": "Final notes\nExhaustive search will fetch the exact solution but it has a higher cost and this could be more notorious as dataset’s size increases."
  },
  {
    "objectID": "tutorials/allknn.html#environment-and-dependencies",
    "href": "tutorials/allknn.html#environment-and-dependencies",
    "title": "Computing all \\(k\\) nearest neighbors",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.10\nCommit 95f30e51f41 (2025-06-27 09:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 × Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_NUM_THREADS = auto\n  JULIA_PROJECT = .\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/Research/SimilaritySearchDemos/Project.toml`\n  [aaaa29a8] Clustering v0.15.8\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.8.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.1\n  [682c06a0] JSON v0.21.4\n  [23fbe1c1] Latexify v0.16.10\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\n⌃ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.20\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.1\n  [053f045d] SimilaritySearch v0.13.0\n⌅ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.6\nInfo Packages marked with ⌃ and ⌅ have new versions available. Those with ⌃ may be upgradable, but those with ⌅ are restricted by compatibility constraints from upgrading. To see why use `status --outdated`"
  },
  {
    "objectID": "datasets.html",
    "href": "datasets.html",
    "title": "Datasets for Nearest Neighbor Search",
    "section": "",
    "text": "MNIST. Very used in vision tasks, pretty old and not very challenging. However it is very easy to use. From MNIST site, it corresponds to 60k 28x28 handwritten numbers. We use the MLDatasets.jl package to simplify downloading and loading it.\nWiktionary. Took from Wiktionary site, we select English terms from the english wiktionary.\nWIT-300K. From Clip and WIT, we downloaded the first 300K annotated images for the Spanish Wikipedia and take the Clip embeddings of them. Available from the demo subfolder.\nGlove. Very used as dataset in papers but not yet vigent with respect to state of the art methods in different Natural Language Processing tasks. From Glove site, it corresponds to the 100d, 6B tokens. We use the Embeddings.jl package to simplify downloading and loading it.\n\n\n\nThe versions used in the demonstrations are not splitted in train and test, but those used in the paper are splitted. If you want to reproduce the same results, please use the datasets by ann-benchmarks and its repo.\nFor WIT and Twitter-2M, please use the following HDF5 files, they follow a similar structure than those found in the ann-benchmarks.\n\nWIT-300K\nTwitter-2M. These word embeddings corresponds to that model labeled as ALL-2M in the Regional Spanish Models site, yet partitioned for using as similarity search benchmark."
  },
  {
    "objectID": "datasets.html#real-world",
    "href": "datasets.html#real-world",
    "title": "Datasets for Nearest Neighbor Search",
    "section": "",
    "text": "MNIST. Very used in vision tasks, pretty old and not very challenging. However it is very easy to use. From MNIST site, it corresponds to 60k 28x28 handwritten numbers. We use the MLDatasets.jl package to simplify downloading and loading it.\nWiktionary. Took from Wiktionary site, we select English terms from the english wiktionary.\nWIT-300K. From Clip and WIT, we downloaded the first 300K annotated images for the Spanish Wikipedia and take the Clip embeddings of them. Available from the demo subfolder.\nGlove. Very used as dataset in papers but not yet vigent with respect to state of the art methods in different Natural Language Processing tasks. From Glove site, it corresponds to the 100d, 6B tokens. We use the Embeddings.jl package to simplify downloading and loading it.\n\n\n\nThe versions used in the demonstrations are not splitted in train and test, but those used in the paper are splitted. If you want to reproduce the same results, please use the datasets by ann-benchmarks and its repo.\nFor WIT and Twitter-2M, please use the following HDF5 files, they follow a similar structure than those found in the ann-benchmarks.\n\nWIT-300K\nTwitter-2M. These word embeddings corresponds to that model labeled as ALL-2M in the Regional Spanish Models site, yet partitioned for using as similarity search benchmark."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This site is an effort to document and give comprehensive resources to use the SimilaritySearch.jl Julia package. The contributors are:\n\nEric S. Téllez https://sadit.github.io/, SECIHTI-INFOTEC, Aguascalientes, México.\nGuillermo Ruiz, INFOTEC, Aguascalientes, México."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tutorials and Examples for the SimilaritySearch.jl package",
    "section": "",
    "text": "Here you will find several examples for the SimilaritySearch.jl package."
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "Tutorials and Examples for the SimilaritySearch.jl package",
    "section": "Installation",
    "text": "Installation\nYou need a Julia installation https://julialang.org/downloads/, in particular, we recommend to use Julia \\(v1.10\\) since \\(v1.11\\) has several performance regressions with respect to SimilaritySearch.\nWe present our examples just to copy and paste on the REPL but also provide some in Jupyter and Pluto notebooks; you must install IJulia and Pluto packages, just run the following commands in the REPL\nusing Pkg; Pkg.add([\"IJulia\", \"Pluto\"])\nPlease check their documentation:\n\nIJulia.\nJupyter.\nPluto\n\nThis website was made with Quarto with the Julia engine."
  },
  {
    "objectID": "index.html#notes-about-multithreading",
    "href": "index.html#notes-about-multithreading",
    "title": "Tutorials and Examples for the SimilaritySearch.jl package",
    "section": "Notes about multithreading",
    "text": "Notes about multithreading\nNearest neighbor search can be computationally expensive, therefore SimilaritySearch has multithreading support. You should want to run jupyter or julia using all available threads, that is\nJULIA_NUM_THREADS=auto jupyter-lab .\nor\nJULIA_NUM_THREADS=auto julia\nPerhaps all your threads may become your computer useless for a while, so you can replace auto by some other more conservative number that allow you to work on the same computer."
  },
  {
    "objectID": "index.html#news",
    "href": "index.html#news",
    "title": "Tutorials and Examples for the SimilaritySearch.jl package",
    "section": "News",
    "text": "News\n\nmarch 20th, 2025: the site is behind the SimilaritySearch API; I will be working on updating examples and moving the site to Quarto.\njune 5th, 2023: adds news section, some installation requirements, Jupyter notebookes were updated to work with the v0.10 and with the current julia release v1.9. I also moved most plots to Makie."
  },
  {
    "objectID": "index.html#problem-statement",
    "href": "index.html#problem-statement",
    "title": "Tutorials and Examples for the SimilaritySearch.jl package",
    "section": "Problem statement",
    "text": "Problem statement\nGiven a finite dataset, \\(S \\subseteq U\\) where \\(n = |S|\\), and a metric distance function \\(d\\) working with any pair of elements in \\(U\\), the similarity search problem consists on retrieving similar items to a given query \\(q\\), for example, the \\(k\\) most similar items to \\(q\\) in \\(S\\) (\\(k\\) nearest neighbors).\nAt first glance, the problem is simple since it can be solved using an exhaustive evaluation of all possible results \\(d(u_1, q), \\cdots, d(u_n, q)\\) (that is, for all \\(u_i \\in S\\)) and select those \\(k\\) items \\(\\{u_i\\}\\) having the least distance to \\(q\\). This solution is impractical when \\(n\\) is large or when the number of expected queries is high. In these cases, it is necessary to create a data structure that preprocess the dataset and reduce the cost of solving queries, it is often called a metric index. When the dataset is pretty large or the metric space is quite complex, sometimes we can loose the ability of retrieving the exact solution to gain speed, clearly, the approximation quality becomes a major concern and these approximate methods require a lot of knowledge to trade speed retrieval process also kept high the solution’s quality. Additionally, the amount of memory used by the index and the construction time are also concerns whenever \\(n\\) is big.\nThe SearchGraph index in the SimilaritySearch.jl package is a competitive alternative for solving search queries that automatically tune search speed and quality and also remains very competitive in memory and construction costs. Here we show some demostrations of how using SimilaritySearch.jl in several synthetic and real problems."
  },
  {
    "objectID": "tutorials/automatic-hyperparameter-opt.html",
    "href": "tutorials/automatic-hyperparameter-opt.html",
    "title": "Automatic Hyperparameter Optimization",
    "section": "",
    "text": "by: Eric S. Téllez\nThis example optimizes different kinds of optimizations that allow different tradeoffs\n\nusing SimilaritySearch, Markdown\n\n1dim = 16\n2db = MatrixDatabase(rand(Float32, dim, 10^5))\n3queries = MatrixDatabase(rand(Float32, dim, 10^3))\n4dist = SqL2Distance()\n5k = 12\n\n\n1\n\nThe dimension to use in the synthetic data\n\n2\n\nThe synthetic database\n\n3\n\nThe synthetic queries\n\n4\n\nThe distance function; we will use the squared L2, which preserves the order of L2 but is faster to compute.\n\n5\n\nThe number of neighbors to retrieve"
  },
  {
    "objectID": "tutorials/automatic-hyperparameter-opt.html#automatic-hyperparameter-optimization",
    "href": "tutorials/automatic-hyperparameter-opt.html#automatic-hyperparameter-optimization",
    "title": "Automatic Hyperparameter Optimization",
    "section": "",
    "text": "by: Eric S. Téllez\nThis example optimizes different kinds of optimizations that allow different tradeoffs\n\nusing SimilaritySearch, Markdown\n\n1dim = 16\n2db = MatrixDatabase(rand(Float32, dim, 10^5))\n3queries = MatrixDatabase(rand(Float32, dim, 10^3))\n4dist = SqL2Distance()\n5k = 12\n\n\n1\n\nThe dimension to use in the synthetic data\n\n2\n\nThe synthetic database\n\n3\n\nThe synthetic queries\n\n4\n\nThe distance function; we will use the squared L2, which preserves the order of L2 but is faster to compute.\n\n5\n\nThe number of neighbors to retrieve"
  },
  {
    "objectID": "tutorials/automatic-hyperparameter-opt.html#computing-ground-truth",
    "href": "tutorials/automatic-hyperparameter-opt.html#computing-ground-truth",
    "title": "Automatic Hyperparameter Optimization",
    "section": "Computing ground truth",
    "text": "Computing ground truth\nWe will generate a ground truth with an exhaustive method.\n\ngold_knns = searchbatch(ExhaustiveSearch(; db, dist), GenericContext(), queries, k)"
  },
  {
    "objectID": "tutorials/automatic-hyperparameter-opt.html#different-hyperparameter-optimization-strategies",
    "href": "tutorials/automatic-hyperparameter-opt.html#different-hyperparameter-optimization-strategies",
    "title": "Automatic Hyperparameter Optimization",
    "section": "Different hyperparameter optimization strategies",
    "text": "Different hyperparameter optimization strategies\nThe way of specifying the hyperparameter optimization strategy and objective is with a SearchGraphContext object, as follows:\n\nG1 = SearchGraph(; dist, db)\nC1 = SearchGraphContext(hyperparameters_callback=OptimizeParameters(MinRecall(0.99)))\nbuildtime1 = @elapsed index!(G1, C1)\n\nThe previous construction optimizes the construction to have a very high recall, which can be very costly but also produces a high quality index.\n\nG2 = SearchGraph(; dist, db)\nC2 = SearchGraphContext(hyperparameters_callback=OptimizeParameters(MinRecall(0.9)))\nbuildtime2 = @elapsed index!(G2, C2)\n\nsearch, searchbatch, index!, append_items!, and push_item! accept context arguments."
  },
  {
    "objectID": "tutorials/automatic-hyperparameter-opt.html#performances",
    "href": "tutorials/automatic-hyperparameter-opt.html#performances",
    "title": "Automatic Hyperparameter Optimization",
    "section": "Performances",
    "text": "Performances\nsearching times\n\ntime1 = @elapsed knns1 = searchbatch(G1, C1, queries, k)\ntime2 = @elapsed knns2 = searchbatch(G2, C2, queries, k)\nrecall1 = macrorecall(gold_knns, knns1)\nrecall2 = macrorecall(gold_knns, knns2)\n\nthe recall is an score value between 0 to 1 where values close to 1 indicate better qualities.\n\n\nbuild time:\n\nbuildtime1: 16.843500805\n\nbuildtime2: 10.951805646\n\n\nsearch time:\n\ntime1: 0.022308873\n\ntime2: 0.021209033\n\n\nrecall values:\n\nrecall1: 0.9206666666666642\n\nrecall2: 0.6424166666666662\n\n\n\n\n\nhere we can see smaller recalls than expected, and this is an effect of the difference between indexed elements (that are those objects used to perform the hyperparameter optimization). In any case, we 1can appreciate the differences among them, showing that high quality constructions may produce faster indexes; this is a consequence of the quality of the underlying structure. Contrary to this example, in higher dimensions or large datasets, we will obtain much higher construction times for high quality constructions."
  },
  {
    "objectID": "tutorials/automatic-hyperparameter-opt.html#optimizing-an-already-created-searchgraph-for-achieving-a-desired-quality",
    "href": "tutorials/automatic-hyperparameter-opt.html#optimizing-an-already-created-searchgraph-for-achieving-a-desired-quality",
    "title": "Automatic Hyperparameter Optimization",
    "section": "Optimizing an already created SearchGraph for achieving a desired quality",
    "text": "Optimizing an already created SearchGraph for achieving a desired quality\nThe hyperparameter optimization is performed in exponential stages while the SearchGraph is created; and therefore, the current hyperparameters could need an update. To optimize an already created SearchGraph we use optimize instead of index\nContext objects are special for construction since they encapsulate several hyperparameters; for searching it contains also caches but it can be shared among indexes; however, if the indexes have different sizes or you expect very different queries, it is better to maintain different context.\n\noptimize_index!(G1, C1, MinRecall(0.9))\noptimize_index!(G2, C1, MinRecall(0.9))\n\nafter optimizing the index its quality and speed are changed\n\ntime1 = @elapsed knns1 = searchbatch(G1, C1, queries, k)\ntime2 = @elapsed knns2 = searchbatch(G2, C1, queries, k)\n\nrecall1 = macrorecall(gold_knns, knns1)\nrecall2 = macrorecall(gold_knns, knns2)\n\nThese results on the following performances:\n\n\nbuild time:\n\nbuildtime1: 16.843500805\n\nbuildtime2: 10.951805646\n\n\nsearch time:\n\ntime1: 0.021069843\n\ntime2: 0.013914675\n\n\nrecall values:\n\nrecall1: 0.5348333333333343\n\nrecall2: 0.6850833333333333\n\n\n\n\n\nPlease note that faster searches are expected for indexes created for higher qualities; but the construction must be paid. Note that recall values are lower than expected, as we explained, due to differences in the distributions (more precisely between points already seen and not seen points)."
  },
  {
    "objectID": "tutorials/automatic-hyperparameter-opt.html#giving-more-realistic-queries-for-optimization",
    "href": "tutorials/automatic-hyperparameter-opt.html#giving-more-realistic-queries-for-optimization",
    "title": "Automatic Hyperparameter Optimization",
    "section": "Giving more realistic queries for optimization",
    "text": "Giving more realistic queries for optimization\nThe default optimization parameters use objects already indexed to tune the hyperparameters, which is too optimistic in real applications, since already indexed objects are particularly easy for this use. We can get a better optimization using external data:\n\noptqueries = MatrixDatabase(rand(Float32, dim, 64))\n\noptimize_index!(G1, C1, MinRecall(0.9); queries=optqueries)\noptimize_index!(G2, C1, MinRecall(0.9); queries=optqueries)\n\nafter optimizing the index its quality and speed are changed\n\ntime1 = @elapsed knns1 = searchbatch(G1, C1, queries, k)\ntime2 = @elapsed knns2 = searchbatch(G2, C1, queries, k)\n\nrecall1 = macrorecall(gold_knns, knns1)\nrecall2 = macrorecall(gold_knns, knns2)\n\nThese results on the following performances:\n\n\nbuild time:\n\nbuildtime1: 16.843500805\n\nbuildtime2: 10.951805646\n\n\nsearch time:\n\ntime1: 0.013584659\n\ntime2: 0.014764835\n\n\nrecall values:\n\nrecall1: 0.8644166666666662\n\nrecall2: 0.8860833333333309\n\n\n\n\n\nThese scores are much closer to those we are looking for.\nBe careful on doing optimize_index!(..., queries=queries) since this can yield to overfitting on your query set."
  },
  {
    "objectID": "tutorials/automatic-hyperparameter-opt.html#environment-and-dependencies",
    "href": "tutorials/automatic-hyperparameter-opt.html#environment-and-dependencies",
    "title": "Automatic Hyperparameter Optimization",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.10\nCommit 95f30e51f41 (2025-06-27 09:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 × Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_NUM_THREADS = auto\n  JULIA_PROJECT = .\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/Research/SimilaritySearchDemos/Project.toml`\n  [aaaa29a8] Clustering v0.15.8\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.8.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.1\n  [682c06a0] JSON v0.21.4\n  [23fbe1c1] Latexify v0.16.10\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\n⌃ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.20\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.1\n  [053f045d] SimilaritySearch v0.13.0\n⌅ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.6\nInfo Packages marked with ⌃ and ⌅ have new versions available. Those with ⌃ may be upgradable, but those with ⌅ are restricted by compatibility constraints from upgrading. To see why use `status --outdated`"
  },
  {
    "objectID": "tutorials/incremental-construction.html",
    "href": "tutorials/incremental-construction.html",
    "title": "Incremental construction with SearchGraph",
    "section": "",
    "text": "by: Eric S. Téllez\nusing SimilaritySearch\nFor incremental construction we need a database backend that supports incremental insertions. Currently, there are two backends for this: DynamicMatrixDatabase and VectorDatabase:\ndim = 8\ndb = DynamicMatrixDatabase(Float32, dim) # or VectorDatabase(Vector{Float32})\ndist = L1Distance()\nit can use any distance function described in SimilaritySearch and Distances.jl, and in fact any SemiMetric as described in the later package. The index construction is made as follows:\nG = SearchGraph(; dist, db)\nctx = SearchGraphContext()\ninstead of index! we can use push_item! and append_items! functions\nfor _ in 1:10^4\n    push_item!(G, ctx, rand(Float32, dim))  # push_item! inserts one item at a time\nend\nwe can also use append_items! if we have a batch of items\nappend_items!(G, ctx, MatrixDatabase(rand(Float32, dim, 10^4))) # append_items! inserts many items at once\nNote that we used a MatrixDatabase to wrap the matrix to be inserted since it will be copied into the index. Now we have a populated index.\n@assert length(G) == 20_000\nthis will display a lot of information in the console, since as construction advances the hyperparameters of the index are adjusted.\nOnce the index is created, the index can solve nearest neighbor queries\n1Q = MatrixDatabase(rand(dim, 30))\n2k = 5\n3knns = searchbatch(G, ctx, Q, k)\ndisplay((typeof(knns), sizeof(knns)))\n\n\n1\n\nCreates the query\n\n2\n\nThe number of nearest neighbors to retrieve\n\n3\n\nSolve queries, returns neighbor identifiers and distances.\n\n\n\n\n(Matrix{IdWeight}, 1200)"
  },
  {
    "objectID": "tutorials/incremental-construction.html#environment-and-dependencies",
    "href": "tutorials/incremental-construction.html#environment-and-dependencies",
    "title": "Incremental construction with SearchGraph",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.10\nCommit 95f30e51f41 (2025-06-27 09:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 × Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_NUM_THREADS = auto\n  JULIA_PROJECT = .\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/Research/SimilaritySearchDemos/Project.toml`\n  [aaaa29a8] Clustering v0.15.8\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.8.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.1\n  [682c06a0] JSON v0.21.4\n  [23fbe1c1] Latexify v0.16.10\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\n⌃ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.20\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.1\n  [053f045d] SimilaritySearch v0.13.0\n⌅ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.6\nInfo Packages marked with ⌃ and ⌅ have new versions available. Those with ⌃ may be upgradable, but those with ⌅ are restricted by compatibility constraints from upgrading. To see why use `status --outdated`"
  },
  {
    "objectID": "tutorials/parallel-construction-and-search.html",
    "href": "tutorials/parallel-construction-and-search.html",
    "title": "Parallel construction and parallel search",
    "section": "",
    "text": "by: Eric S. Téllez\nusing SimilaritySearch\nSimilarity search on very large datasets and high-dimensional datasets require high computational resources. In this example we show how to arallelize both the construction and search to be able to handle this kind of databases.\ndim = 16\n1db = MatrixDatabase(randn(Float32, dim, 10^5))\n2queries = MatrixDatabase(randn(Float32, dim, 30))\n3dist = SqL2Distance()\n4ctx = SearchGraphContext(parallel_first_block=256, parallel_block=512)\n5G = SearchGraph(; dist, db)\n6index!(G, ctx)\n\n\n1\n\nA synthetic database of dimension 16 and \\(10^5\\) vectors.\n\n2\n\nA synthetic query set of \\(30\\) points.\n\n3\n\nThe distance function.\n\n4\n\nThe search context working with SearchGraph; a set of hyperparameters for the index.\n\n5\n\nThe index definition.\n\n6\n\nThe index construction.\nThe SearchGraph construction algorithm is incremental:\nThe parallel construction is made with index! or append_items!; for this matter these functions accept a parallel_block argument via the ctx context, that controls how many elements are inserted at once, i.e., looking for its nearest neighbors in parallel and connected also in parallel.\nAs in the sequential version, a minimum number of elements must exists to work, and therefore, the parallel_first_block argument can also be specified. By default, it is equal to parallel_block. The parallel_block argument should be set to at least the number of available threads, and perhaps multiplying it by a small constant is also a good approach.\nNote that you must not call push_item!, append_items!, or index! from several threads. The default algorithm will takes advantage of the available threads using a single call."
  },
  {
    "objectID": "tutorials/parallel-construction-and-search.html#searching",
    "href": "tutorials/parallel-construction-and-search.html#searching",
    "title": "Parallel construction and parallel search",
    "section": "Searching",
    "text": "Searching\nOnce the index is constructed, you can solve batches in parallel and also single queries. In contrast with append, these functions can be called in multithreading algorithms. However, you must pause the searching requests while perform insertions (parallel or sequential); mixing insertions and search produces an undefined behavior for search results.\n\nknns = searchbatch(G, ctx, queries, 10)\n\nThreads.@threads for i in eachindex(queries)\n    res = search(G, ctx, queries[i], knnqueue(ctx, 10))\n    \n    print(\"=== $i -- nearest neighbor:\")\n    println(nearest(res))\n    print(\"=== $i -- result set:\")\n    println(collect(viewitems(res)))\n    print(\"=== $i -- identifiers:\")\n    println(collect(IdView(res))) # do something with `res`\n    print(\"=== $i -- distances:\")\n    println(collect(DistView(res))) # do something with `res`\nend\n\n=== 4 -- nearest neighbor:=== 18 -- nearest neighbor:=== 5 -- nearest neighbor:=== 2 -- nearest neighbor:=== 25 -- nearest neighbor:=== 16 -- nearest neighbor:=== 11 -- nearest neighbor:=== 9 -- nearest neighbor:=== 22 -- nearest neighbor:=== 14 -- nearest neighbor:IdWeight(=== 13 -- nearest neighbor:=== 15 -- nearest neighbor:=== 29 -- nearest neighbor:=== 12 -- nearest neighbor:=== 3 -- nearest neighbor:=== 23 -- nearest neighbor:=== 6 -- nearest neighbor:=== 20 -- nearest neighbor:=== 21 -- nearest neighbor:=== 8 -- nearest neighbor:=== 19 -- nearest neighbor:=== 10 -- nearest neighbor:=== 30 -- nearest neighbor:=== 17 -- nearest neighbor:=== 24 -- nearest neighbor:=== 26 -- nearest neighbor:=== 27 -- nearest neighbor:0x=== 1 -- nearest neighbor:=== 7 -- nearest neighbor:=== 28 -- nearest neighbor:000016da, 7.475581f0)\n=== 2 -- result set:IdWeight(0x00013680, 4.9501705f0)\n=== 16 -- result set:IdWeight(0x000125c7, 3.8281355f0)\n=== 23 -- result set:IdWeight(0x0000bf56, 3.0849502f0)\n=== 21 -- result set:IdWeight(0x000136ca, 3.826608f0)\nIdWeight=== 30 -- result set:(0x0000f7e7, 4.6755185f0)\n=== 8 -- result set:IdWeight(0x00015d31, 3.6273217f0)\n=== 13 -- result set:IdWeight(0x000160b1, 2.3851268f0)\n=== 28 -- result set:IdWeight(0x0000aeee, 3.5925267f0)\n=== 11 -- result set:IdWeight[IdWeight(0x00015d31, 3.6273217f0), IdWeight(0x0000741a, 4.68003f0), IdWeight(0x00007f8c, 4.6882257f0), IdWeight(0x00001cdb, 4.823663f0), IdWeight(0x0000457e, 4.9092054f0), IdWeight(0x00003b62, 5.076417f0), IdWeight(0x00015c30, 5.1616125f0), IdWeight(0x00012b9a, 5.189806f0), IdWeight(0x0000ce62, 5.21961f0), IdWeight(0x0000af4f, 5.2996163f0)]\n=== 13 -- identifiers:IdWeight(0x0000d133, 4.866582f0)\n=== 18 -- result set:IdWeight[IdWeight(0x0000f7e7, 4.6755185f0), IdWeight(0x0000d4cf, 4.946041f0), IdWeight(0x0000b23b, 5.5497537f0), IdWeight(0x000155a8, 5.938352f0), IdWeight(0x000032ab, 6.959454f0), IdWeight(0x00015c19, 7.180469f0), IdWeight(0x000056d6, 7.3057566f0), IdWeight(0x00001b74, 7.4702315f0), IdWeight(0x0000a034, 7.6433163f0), IdWeight(0x00003876, 7.6469784f0)]\n=== 8 -- identifiers:IdWeight(0x00017958, 3.694816f0)\n=== 7 -- result set:IdWeight(0x0000c5ca, 4.836586f0)\n=== 29 -- result set:IdWeight(0x0000b841, 8.626275f0)\n=== 19 -- result set:IdWeight(0x0001335a, 1.9811906f0)\n=== 26 -- result set:IdWeight(0x00007931, 5.2518964f0)\n=== 6 -- result set:IdWeight(0x00005dfe, 3.8714378f0)\n=== 9 -- result set:IdWeight(0x0001147d, 5.2202907f0)\n=== 4 -- result set:IdWeight[IdWeight(0x0000aeee, 3.5925267f0), IdWeight(0x0000abd8, 4.8545127f0), IdWeight(0x00018285, 4.8720684f0), IdWeight(0x000095f0, 5.0156937f0), IdWeight(0x0001504c, 5.435365f0), IdWeight(0x000155e1, 5.5563474f0), IdWeight(0x000139fc, 5.5843096f0), IdWeight(0x00000b8f, 5.6968827f0), IdWeight(0x00007c65, 5.760248f0), IdWeight(0x00016814, 5.9182396f0)]\n=== 11 -- identifiers:IdWeight(0x00011832, 8.325138f0)\n=== 14 -- result set:IdWeight(0x0001618b, 7.4726634f0)\n=== 27 -- result set:IdWeight[IdWeight(0x00007931, 5.2518964f0), IdWeight(0x00007573, 6.288773f0), IdWeight(0x0000ae65, 6.386692f0), IdWeight(0x0000f57a, 6.7786574f0), IdWeight(0x0000dec7, 6.819204f0), IdWeight(0x00012cd9, 7.134268f0), IdWeight(0x00016e8e, 7.211961f0), IdWeight(0x0000e668, 7.213861f0), IdWeight(0x00005fee, 7.3557243f0), IdWeight(0x0001514d, 7.396805f0)]\n=== 6 -- identifiers:IdWeight[IdWeight(0x00013680, 4.9501705f0), IdWeight(0x0000aa98, 5.1672125f0), IdWeight(0x0000e825, 5.3883085f0), IdWeight(0x00012b73, 5.624281f0), IdWeight(0x0000d45f, 5.640246f0), IdWeight(0x0000cded, 5.6415195f0), IdWeight(0x00012e0a, 5.776929f0), IdWeight(0x00014bfa, 5.7929277f0), IdWeight(0x0000a356, 5.8185754f0), IdWeight(0x00001f22, 6.1403303f0)]\n=== 16 -- identifiers:IdWeight[IdWeight(0x000016da, 7.475581f0), IdWeight(0x00007baf, 8.006167f0), IdWeight(0x0001527c, 8.374749f0), IdWeight(0x00007b77, 8.457133f0), IdWeight(0x00004218, 8.552438f0), IdWeight(0x00007386, 9.258151f0), IdWeight(0x000126e7, 9.500102f0), IdWeight(0x000185fd, 9.53086f0), IdWeight(0x00007e18, 10.121296f0), IdWeight(0x00013d21, 10.250516f0)]\n=== 2 -- identifiers:IdWeight[IdWeight(0x0000c5ca, 4.836586f0), IdWeight(0x0000f32f, 6.0106325f0), IdWeight(0x000153e4, 6.1220074f0), IdWeight(0x0000110a, 6.2072845f0), IdWeight(0x0000d160, 6.2607503f0), IdWeight(0x0000bbd6, 6.4195223f0), IdWeight(0x00006b0b, 6.4675875f0), IdWeight(0x0000fdbf, 6.9372935f0), IdWeight(0x00012f4b, 6.9403267f0), IdWeight(0x00001394, 7.0028744f0)]\n=== 29 -- identifiers:UInt32[0x0000f7e7, 0x0000d4cf, 0x0000b23b, 0x000155a8, 0x000032ab, 0x00015c19, 0x000056d6, 0x00001b74, 0x0000a034, 0x00003876]\n=== 8 -- distances:UInt32[0x00015d31, 0x0000741a, 0x00007f8c, 0x00001cdb, 0x0000457e, 0x00003b62, 0x00015c30, 0x00012b9a, 0x0000ce62, 0x0000af4f]\nIdWeight=== 13 -- distances:(0x0000b80e, 3.8890228f0)\n=== 12 -- result set:IdWeight[IdWeight(0x000160b1, 2.3851268f0), IdWeight(0x0000fdf9, 3.9968753f0), IdWeight(0x000163aa, 4.6616535f0), IdWeight(0x000095d6, 4.8628407f0), IdWeight(0x000036f4, 5.220222f0), IdWeight(0x0000673d, 5.311993f0), IdWeight(0x0000766f, 5.3134274f0), IdWeight(0x0000755f, 5.539219f0), IdWeight(0x00008b38, 5.9165697f0), IdWeight(0x00013e7d, 6.0329785f0)]\n=== 28 -- identifiers:IdWeight(0x000171f9, 3.3012612f0)\n=== 10 -- result set:UInt32[0x0000aeee, 0x0000abd8, 0x00018285, 0x000095f0, 0x0001504c, 0x000155e1, 0x000139fc, 0x00000b8f, 0x00007c65, 0x00016814]\n=== 11 -- distances:UInt32[0x000160b1, 0x0000fdf9, 0x000163aa, 0x000095d6, 0x000036f4, 0x0000673d, 0x0000766f, 0x0000755f, 0x00008b38, 0x00013e7d]\n=== 28 -- distances:IdWeight[IdWeight(0x000125c7, 3.8281355f0), IdWeight(0x000139a8, 4.411647f0), IdWeight(0x00010827, 4.412861f0), IdWeight(0x0000148d, 4.612425f0), IdWeight(0x00017a1b, 4.7452927f0), IdWeight(0x00003349, 4.8092985f0), IdWeight(0x000080b4, 5.1169624f0), IdWeight(0x00017c8d, 5.1910243f0), IdWeight(0x0000e280, 5.2516203f0), IdWeight(0x00004904, 5.3864393f0)]\n=== 23 -- identifiers:IdWeight[IdWeight(0x0001335a, 1.9811906f0), IdWeight(0x0000fff2, 2.7188296f0), IdWeight(0x00002716, 2.8710415f0), IdWeight(0x0000904d, 3.2169006f0), IdWeight(0x0001279d, 3.3474293f0), IdWeight(0x00017a6f, 3.4758518f0), IdWeight(0x00008dc9, 3.535749f0), IdWeight(0x0001794c, 3.6799278f0), IdWeight(0x00001336, 3.680181f0), IdWeight(0x00006122, 3.7101126f0)]\n=== 26 -- identifiers:IdWeight[IdWeight(0x0000bf56, 3.0849502f0), IdWeight(0x00003169, 3.809248f0), IdWeight(0x00007b91, 4.0175047f0), IdWeight(0x000170b9, 4.21555f0), IdWeight(0x0000860c, 4.567765f0), IdWeight(0x00002528, 4.651129f0), IdWeight(0x00002b25, 4.9866815f0), IdWeight(0x0000be55, 5.197236f0), IdWeight(0x00000728, 5.262011f0), IdWeight(0x000086f9, 5.273572f0)]\n=== 21 -- identifiers:IdWeight[IdWeight(0x0000b841, 8.626275f0), IdWeight(0x000170bd, 10.916844f0), IdWeight(0x00002105, 11.194837f0), IdWeight(0x00003050, 11.668236f0), IdWeight(0x00007688, 12.329492f0), IdWeight(0x0000fd5e, 12.629101f0), IdWeight(0x00003572, 12.665984f0), IdWeight(0x0000d552, 12.900963f0), IdWeight(0x00001339, 12.96817f0), IdWeight(0x00012423, 13.102973f0)]\n=== 19 -- identifiers:IdWeight(0x0000dd13, 3.1978405f0)\n=== 15 -- result set:IdWeight(0x00010ef6, 4.618901f0)\n=== 5 -- result set:UInt32[0x000125c7, 0x000139a8, 0x00010827, 0x0000148d, 0x00017a1b, 0x00003349, 0x000080b4, 0x00017c8d, 0x0000e280, 0x00004904]\n=== 23 -- distances:Float32[3.5925267, 4.8545127, 4.8720684, 5.0156937, 5.435365, 5.5563474, 5.5843096, 5.6968827, 5.760248, 5.9182396]\nIdWeight[IdWeight(0x00011832, 8.325138f0), IdWeight(0x0000d7f3, 8.770528f0), IdWeight(0x00017ab3, 9.436805f0), IdWeight(0x00000913, 11.315607f0), IdWeight(0x00009ce0, 11.644699f0), IdWeight(0x00017484, 12.10246f0), IdWeight(0x000042bf, 12.268001f0), IdWeight(0x00005d56, 12.469366f0), IdWeight(0x00004535, 12.628713f0), IdWeight(0x00004471, 12.8754225f0)]\n=== 14 -- identifiers:UInt32[0x00013680, 0x0000aa98, 0x0000e825, 0x00012b73, 0x0000d45f, 0x0000cded, 0x00012e0a, 0x00014bfa, 0x0000a356, 0x00001f22]\n=== 16 -- distances:IdWeight[IdWeight(0x000171f9, 3.3012612f0), IdWeight(0x000065a7, 4.3635774f0), IdWeight(0x00002665, 4.4735656f0), IdWeight(0x0000c13c, 4.477754f0), IdWeight(0x00008df1, 4.544302f0), IdWeight(0x000027ac, 4.616445f0), IdWeight(0x000028eb, 4.885664f0), IdWeight(0x0000a3d3, 5.060929f0), IdWeight(0x0000080b, 5.1638126f0), IdWeight(0x0000f5aa, 5.466307f0)]\n=== 10 -- identifiers:IdWeight(0x0000bdab, 5.939122f0)\nIdWeight=== 1 -- result set:[IdWeight(0x0000dd13, 3.1978405f0), IdWeight(0x00005013, 4.7813525f0), IdWeight(0x00012f9a, 4.946647f0), IdWeight(0x000101cc, 4.9642615f0), IdWeight(0x00016bda, 5.127922f0), IdWeight(0x0000d9ab, 5.484438f0), IdWeight(0x000085cf, 5.5215507f0), IdWeight(0x000174fe, 5.572069f0), IdWeight(0x00015a61, 5.6021905f0), IdWeight(0x00015f3a, 5.624522f0)]\nIdWeight=== 15 -- identifiers:(0x00001b25, 4.318264f0)\n=== 20 -- result set:IdWeight(0x0001765d, 4.811967f0)\n=== 25 -- result set:IdWeight[IdWeight(0x0001618b, 7.4726634f0), IdWeight(0x00013c19, 8.921653f0), IdWeight(0x0000c465, 9.109844f0), IdWeight(0x00002589, 9.152566f0), IdWeight(0x00000e41, 9.217521f0), IdWeight(0x000012b2, 9.565677f0), IdWeight(0x00008613, 9.627638f0), IdWeight(0x0000d960, 9.70625f0), IdWeight(0x0001351e, 9.757255f0), IdWeight(0x0000549c, 9.865978f0)]\n=== 27 -- identifiers:IdWeight(0x000108ba, 5.3042355f0)\n=== 22 -- result set:IdWeight[IdWeight(0x0001147d, 5.2202907f0), IdWeight(0x000147e4, 5.766921f0), IdWeight(0x00007d21, 5.814475f0), IdWeight(0x00006fc3, 6.45201f0), IdWeight(0x00010252, 6.5615616f0), IdWeight(0x0000c4ff, 6.6209016f0), IdWeight(0x000014b7, 6.736498f0), IdWeight(0x00001195, 6.759311f0), IdWeight(0x00012094, 6.8746343f0), IdWeight(0x000155ab, 6.986366f0)]\n=== 4 -- identifiers:UInt32[0x0000bf56, 0x00003169, 0x00007b91, 0x000170b9, 0x0000860c, 0x00002528, 0x00002b25, 0x0000be55, 0x00000728, 0x000086f9]\n=== 21 -- distances:Float32[3.8281355, 4.411647, 4.412861, 4.612425, 4.7452927, 4.8092985, 5.1169624, 5.1910243, 5.2516203, 5.3864393]\nFloat32[2.3851268, 3.9968753, 4.6616535, 4.8628407, 5.220222, 5.311993, 5.3134274, 5.539219, 5.9165697, 6.0329785]\nIdWeight(0x00001753, 4.4825764f0)\n=== 24 -- result set:UInt32[0x0001618b, 0x00013c19, 0x0000c465, 0x00002589, 0x00000e41, 0x000012b2, 0x00008613, 0x0000d960, 0x0001351e, 0x0000549c]\n=== 27 -- distances:IdWeight[IdWeight(0x0000d133, 4.866582f0), IdWeight(0x0000f29c, 5.166498f0), IdWeight(0x00007170, 5.3683376f0), IdWeight(0x0000c668, 5.801767f0), IdWeight(0x00007fe4, 5.9378157f0), IdWeight(0x0000ae10, 5.981952f0), IdWeight(0x000098b4, 6.3435497f0), IdWeight(0x00005b0a, 6.4227424f0), IdWeight(0x0000d512, 6.520656f0), IdWeight(0x00006c2c, 6.749601f0)]\nIdWeight=== 18 -- identifiers:(0x0000b2ca, 8.162801f0)\n=== 3 -- result set:UInt32[0x00007931, 0x00007573, 0x0000ae65, 0x0000f57a, 0x0000dec7, 0x00012cd9, 0x00016e8e, 0x0000e668, 0x00005fee, 0x0001514d]\n=== 6 -- distances:Float32[3.6273217, 4.68003, 4.6882257, 4.823663, 4.9092054, 5.076417, 5.1616125, 5.189806, 5.21961, 5.2996163]\nIdWeight[IdWeight(0x0001765d, 4.811967f0), IdWeight(0x0000f2ba, 6.1820726f0), IdWeight(0x00010e42, 6.619271f0), IdWeight(0x0000f59b, 6.9272494f0), IdWeight(0x0000be57, 7.116349f0), IdWeight(0x000014c7, 7.279584f0), IdWeight(0x00015df7, 7.4337163f0), IdWeight(0x0000102a, 7.463205f0), IdWeight(0x0000f1b8, 8.1107f0), IdWeight(0x00018461, 8.138579f0)]\nIdWeight=== 25 -- identifiers:[IdWeight(0x00001b25, 4.318264f0), IdWeight(0x00005c6b, 4.5169024f0), IdWeight(0x0000b4bd, 4.8121605f0), IdWeight(0x0000cdda, 5.0930715f0), IdWeight(0x00003a64, 5.432807f0), IdWeight(0x000040b0, 5.5089235f0), IdWeight(0x00009fed, 5.5533485f0), IdWeight(0x000025b8, 5.559684f0), IdWeight(0x00007d10, 5.564309f0), IdWeight(0x0000ceaa, 5.599265f0)]\n=== 20 -- identifiers:UInt32[0x0001335a, 0x0000fff2, 0x00002716, 0x0000904d, 0x0001279d, 0x00017a6f, 0x00008dc9, 0x0001794c, 0x00001336, 0x00006122]\nFloat32=== 26 -- distances:[3.0849502, 3.809248, 4.0175047, 4.21555, 4.567765, 4.651129, 4.9866815, 5.197236, 5.262011, 5.273572]\nIdWeight[IdWeight(0x0000bdab, 5.939122f0), IdWeight(0x00000630, 6.1346354f0), IdWeight(0x000165e0, 6.1812754f0), IdWeight(0x00000a0d, 6.23616f0), IdWeight(0x00013a26, 6.284336f0), IdWeight(0x00009c40, 6.6272836f0), IdWeight(0x00000840, 6.6400914f0), IdWeight(0x00017d58, 6.8352456f0), IdWeight(0x0000ba54, 7.066995f0), IdWeight(0x000009ea, 7.0923777f0)]\n=== 1 -- identifiers:UInt32[0x000016da, 0x00007baf, 0x0001527c, 0x00007b77, 0x00004218, 0x00007386, 0x000126e7, 0x000185fd, 0x00007e18, 0x00013d21]\n=== 2 -- distances:UInt32[0x0001765d, 0x0000f2ba, 0x00010e42, 0x0000f59b, 0x0000be57, 0x000014c7, 0x00015df7, 0x0000102a, 0x0000f1b8, 0x00018461]\n=== 25 -- distances:UInt32[0x0000c5ca, 0x0000f32f, 0x000153e4, 0x0000110a, 0x0000d160, 0x0000bbd6, 0x00006b0b, 0x0000fdbf, 0x00012f4b, 0x00001394]\n=== 29 -- distances:IdWeight[IdWeight(0x0000b80e, 3.8890228f0), IdWeight(0x0000f102, 4.003773f0), IdWeight(0x00013d59, 4.313168f0), IdWeight(0x00005843, 4.3866534f0), IdWeight(0x00011f71, 4.606645f0), IdWeight(0x0000834b, 4.7492075f0), IdWeight(0x000115ce, 4.884559f0), IdWeight(0x0000d70f, 5.047111f0), IdWeight(0x0001851f, 5.320671f0), IdWeight(0x00015947, 5.4546676f0)]\n=== 12 -- identifiers:Float32[7.475581, 8.006167, 8.374749, 8.457133, 8.552438, 9.258151, 9.500102, 9.53086, 10.121296, 10.250516]\nIdWeight[IdWeight(0x000108ba, 5.3042355f0), IdWeight(0x000113e0, 6.928343f0), IdWeight(0x00017c69, 7.091271f0), IdWeight(0x00001383, 7.166015f0), IdWeight(0x000022a8, 7.180992f0), IdWeight(0x000080dc, 7.4562817f0), IdWeight(0x0000d99a, 7.6668825f0), IdWeight(0x00003e60, 7.6743126f0), IdWeight(0x000022cc, 7.7288504f0), IdWeight(0x00007e8a, 7.8605657f0)]\n=== 22 -- identifiers:Float32[4.836586, 6.0106325, 6.1220074, 6.2072845, 6.2607503, 6.4195223, 6.4675875, 6.9372935, 6.9403267, 7.0028744]\nIdWeight[IdWeight(0x00001753, 4.4825764f0), IdWeight(0x000093c7, 4.589796f0), IdWeight(0x0000426a, 5.227733f0), IdWeight(0x0000fb83, 5.28668f0), IdWeight(0x000133f7, 5.33499f0), IdWeight(0x00014f38, 5.446783f0), IdWeight(0x0000157f, 5.7493796f0), IdWeight(0x0000fc3c, 5.8062396f0), IdWeight(0x00007e01, 5.9697576f0), IdWeight(0x0000b56a, 6.137463f0)]\n=== 24 -- identifiers:UInt32[0x000171f9, 0x000065a7, 0x00002665, 0x0000c13c, 0x00008df1, 0x000027ac, 0x000028eb, 0x0000a3d3, 0x0000080b, 0x0000f5aa]\n=== 10 -- distances:Float32[7.4726634, 8.921653, 9.109844, 9.152566, 9.217521, 9.565677, 9.627638, 9.70625, 9.757255, 9.865978]\nUInt32[0x000108ba, 0x000113e0, 0x00017c69, 0x00001383, 0x000022a8, 0x000080dc, 0x0000d99a, 0x00003e60, 0x000022cc, 0x00007e8a]\n=== 22 -- distances:UInt32[0x0001147d, 0x000147e4, 0x00007d21, 0x00006fc3, 0x00010252, 0x0000c4ff, 0x000014b7, 0x00001195, 0x00012094, 0x000155ab]\nUInt32=== 4 -- distances:[0x00001753, 0x000093c7, 0x0000426a, 0x0000fb83, 0x000133f7, 0x00014f38, 0x0000157f, 0x0000fc3c, 0x00007e01, 0x0000b56a]\n=== 24 -- distances:UInt32[0x0000b80e, 0x0000f102, 0x00013d59, 0x00005843, 0x00011f71, 0x0000834b, 0x000115ce, 0x0000d70f, 0x0001851f, 0x00015947]\n=== 12 -- distances:Float32[5.2202907, 5.766921, 5.814475, 6.45201, 6.5615616, 6.6209016, 6.736498, 6.759311, 6.8746343, 6.986366]\nFloat32[4.9501705, 5.1672125, 5.3883085, 5.624281, 5.640246, 5.6415195, 5.776929, 5.7929277, 5.8185754, 6.1403303]\nIdWeight[IdWeight(0x00010ef6, 4.618901f0), IdWeight(0x00013bc2, 5.249596f0), IdWeight(0x00012285, 5.2502456f0), IdWeight(0x0000ade7, 5.4808574f0), IdWeight(0x0000b966, 5.543613f0), IdWeight(0x0000c8c6, 5.632665f0), IdWeight(0x00003575, 5.6673555f0), IdWeight(0x00017377, 5.7408757f0), IdWeight(0x0000812d, 5.827993f0), IdWeight(0x0000aeaa, 5.94431f0)]\n=== 5 -- identifiers:Float32[4.811967, 6.1820726, 6.619271, 6.9272494, 7.116349, 7.279584, 7.4337163, 7.463205, 8.1107, 8.138579]\nFloat32[4.4825764, 4.589796, 5.227733, 5.28668, 5.33499, 5.446783, 5.7493796, 5.8062396, 5.9697576, 6.137463]\nUInt32[0x00001b25, 0x00005c6b, 0x0000b4bd, 0x0000cdda, 0x00003a64, 0x000040b0, 0x00009fed, 0x000025b8, 0x00007d10, 0x0000ceaa]\n=== 20 -- distances:IdWeight[IdWeight(0x0000b2ca, 8.162801f0), IdWeight(0x00007f5b, 8.172299f0), IdWeight(0x000008b5, 8.466345f0), IdWeight(0x0000f25c, 8.790724f0), IdWeight(0x000165a0, 8.812614f0), IdWeight(0x00002114, 8.944562f0), IdWeight(0x000179ed, 9.057051f0), IdWeight(0x0000b438, 9.155389f0), IdWeight(0x000105d6, 9.412525f0), IdWeight(0x00017aec, 9.4614725f0)]\n=== 3 -- identifiers:Float32[4.6755185, 4.946041, 5.5497537, 5.938352, 6.959454, 7.180469, 7.3057566, 7.4702315, 7.6433163, 7.6469784]\nFloat32[3.8890228, 4.003773, 4.313168, 4.3866534, 4.606645, 4.7492075, 4.884559, 5.047111, 5.320671, 5.4546676]\nUInt32[0x00011832, 0x0000d7f3, 0x00017ab3, 0x00000913, 0x00009ce0, 0x00017484, 0x000042bf, 0x00005d56, 0x00004535, 0x00004471]\n=== 14 -- distances:UInt32[0x0000d133, 0x0000f29c, 0x00007170, 0x0000c668, 0x00007fe4, 0x0000ae10, 0x000098b4, 0x00005b0a, 0x0000d512, 0x00006c2c]\n=== 18 -- distances:Float32[4.318264, 4.5169024, 4.8121605, 5.0930715, 5.432807, 5.5089235, 5.5533485, 5.559684, 5.564309, 5.599265]\nFloat32[3.3012612, 4.3635774, 4.4735656, 4.477754, 4.544302, 4.616445, 4.885664, 5.060929, 5.1638126, 5.466307]\nIdWeight[IdWeight(0x00005dfe, 3.8714378f0), IdWeight(0x00014824, 4.1736383f0), IdWeight(0x00010c26, 4.1928906f0), IdWeight(0x00007634, 4.4356766f0), IdWeight(0x000101ad, 4.5587573f0), IdWeight(0x000097b2, 4.616823f0), IdWeight(0x00000823, 4.649187f0), IdWeight(0x000073a1, 4.7033167f0), IdWeight(0x0000c687, 5.002816f0), IdWeight(0x0001452f, 5.1380653f0)]\nFloat32=== 9 -- identifiers:[4.866582, 5.166498, 5.3683376, 5.801767, 5.9378157, 5.981952, 6.3435497, 6.4227424, 6.520656, 6.749601]\nIdWeight[IdWeight(0x000136ca, 3.826608f0), IdWeight(0x0000cbd8, 4.0310855f0), IdWeight(0x00000097, 4.4534807f0), IdWeight(0x0000fb78, 4.984945f0), IdWeight(0x00001144, 5.003295f0), IdWeight(0x00011f88, 5.204737f0), IdWeight(0x00000715, 5.342997f0), IdWeight(0x00008b3b, 5.3612533f0), IdWeight(0x0000dcd8, 5.398158f0), IdWeight(0x00011441, 5.6264014f0)]\n=== 30 -- identifiers:UInt32[0x0000dd13, 0x00005013, 0x00012f9a, 0x000101cc, 0x00016bda, 0x0000d9ab, 0x000085cf, 0x000174fe, 0x00015a61, 0x00015f3a]\n=== 15 -- distances:UInt32[0x00005dfe, 0x00014824, 0x00010c26, 0x00007634, 0x000101ad, 0x000097b2, 0x00000823, 0x000073a1, 0x0000c687, 0x0001452f]\n=== 9 -- distances:IdWeight[IdWeight(0x00017958, 3.694816f0), IdWeight(0x0000298e, 4.437228f0), IdWeight(0x00006383, 4.8647146f0), IdWeight(0x00001fb3, 5.173919f0), IdWeight(0x0001082b, 5.5999002f0), IdWeight(0x0000b91e, 5.6336226f0), IdWeight(0x00014b3a, 5.6359906f0), IdWeight(0x00000e6f, 6.0748305f0), IdWeight(0x00013784, 6.212242f0), IdWeight(0x0000de31, 6.2498913f0)]\n=== 7 -- identifiers:Float32[1.9811906, 2.7188296, 2.8710415, 3.2169006, 3.3474293, 3.4758518, 3.535749, 3.6799278, 3.680181, 3.7101126]\nUInt32[0x0000bdab, 0x00000630, 0x000165e0, 0x00000a0d, 0x00013a26, 0x00009c40, 0x00000840, 0x00017d58, 0x0000ba54, 0x000009ea]\n=== 1 -- distances:UInt32[0x000136ca, 0x0000cbd8, 0x00000097, 0x0000fb78, 0x00001144, 0x00011f88, 0x00000715, 0x00008b3b, 0x0000dcd8, 0x00011441]\n=== 30 -- distances:UInt32[0x00017958, 0x0000298e, 0x00006383, 0x00001fb3, 0x0001082b, 0x0000b91e, 0x00014b3a, 0x00000e6f, 0x00013784, 0x0000de31]\n=== 7 -- distances:Float32[5.939122, 6.1346354, 6.1812754, 6.23616, 6.284336, 6.6272836, 6.6400914, 6.8352456, 7.066995, 7.0923777]\nFloat32[3.694816, 4.437228, 4.8647146, 5.173919, 5.5999002, 5.6336226, 5.6359906, 6.0748305, 6.212242, 6.2498913]\nUInt32[0x0000b2ca, 0x00007f5b, 0x000008b5, 0x0000f25c, 0x000165a0, 0x00002114, 0x000179ed, 0x0000b438, 0x000105d6, 0x00017aec]\n=== 3 -- distances:Float32[3.1978405, 4.7813525, 4.946647, 4.9642615, 5.127922, 5.484438, 5.5215507, 5.572069, 5.6021905, 5.624522]\nFloat32[8.325138, 8.770528, 9.436805, 11.315607, 11.644699, 12.10246, 12.268001, 12.469366, 12.628713, 12.8754225]\nFloat32[3.826608, 4.0310855, 4.4534807, 4.984945, 5.003295, 5.204737, 5.342997, 5.3612533, 5.398158, 5.6264014]\nIdWeight(0x0000a64d, 3.0492332f0)\n=== 17 -- result set:Float32[5.3042355, 6.928343, 7.091271, 7.166015, 7.180992, 7.4562817, 7.6668825, 7.6743126, 7.7288504, 7.8605657]\nFloat32[5.2518964, 6.288773, 6.386692, 6.7786574, 6.819204, 7.134268, 7.211961, 7.213861, 7.3557243, 7.396805]\nFloat32[8.162801, 8.172299, 8.466345, 8.790724, 8.812614, 8.944562, 9.057051, 9.155389, 9.412525, 9.4614725]\nUInt32[0x0000b841, 0x000170bd, 0x00002105, 0x00003050, 0x00007688, 0x0000fd5e, 0x00003572, 0x0000d552, 0x00001339, 0x00012423]\n=== 19 -- distances:Float32[3.8714378, 4.1736383, 4.1928906, 4.4356766, 4.5587573, 4.616823, 4.649187, 4.7033167, 5.002816, 5.1380653]\nFloat32[8.626275, 10.916844, 11.194837, 11.668236, 12.329492, 12.629101, 12.665984, 12.900963, 12.96817, 13.102973]\nUInt32[0x00010ef6, 0x00013bc2, 0x00012285, 0x0000ade7, 0x0000b966, 0x0000c8c6, 0x00003575, 0x00017377, 0x0000812d, 0x0000aeaa]\n=== 5 -- distances:IdWeight[IdWeight(0x0000a64d, 3.0492332f0), IdWeight(0x00001e14, 4.57377f0), IdWeight(0x0000373d, 4.6223364f0), IdWeight(0x00009bab, 5.1395545f0), IdWeight(0x00017c0e, 5.399426f0), IdWeight(0x00002168, 5.7276f0), IdWeight(0x00006d71, 5.8193226f0), IdWeight(0x00007623, 6.3015385f0), IdWeight(0x0000df61, 6.599091f0), IdWeight(0x0000fb5c, 6.636065f0)]\n=== 17 -- identifiers:Float32[4.618901, 5.249596, 5.2502456, 5.4808574, 5.543613, 5.632665, 5.6673555, 5.7408757, 5.827993, 5.94431]\nUInt32[0x0000a64d, 0x00001e14, 0x0000373d, 0x00009bab, 0x00017c0e, 0x00002168, 0x00006d71, 0x00007623, 0x0000df61, 0x0000fb5c]\n=== 17 -- distances:Float32[3.0492332, 4.57377, 4.6223364, 5.1395545, 5.399426, 5.7276, 5.8193226, 6.3015385, 6.599091, 6.636065]"
  },
  {
    "objectID": "tutorials/parallel-construction-and-search.html#environment-and-dependencies",
    "href": "tutorials/parallel-construction-and-search.html#environment-and-dependencies",
    "title": "Parallel construction and parallel search",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.10\nCommit 95f30e51f41 (2025-06-27 09:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 × Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_NUM_THREADS = auto\n  JULIA_PROJECT = .\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/Research/SimilaritySearchDemos/Project.toml`\n  [aaaa29a8] Clustering v0.15.8\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.8.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.1\n  [682c06a0] JSON v0.21.4\n  [23fbe1c1] Latexify v0.16.10\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\n⌃ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.20\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.1\n  [053f045d] SimilaritySearch v0.13.0\n⌅ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.6\nInfo Packages marked with ⌃ and ⌅ have new versions available. Those with ⌃ may be upgradable, but those with ⌅ are restricted by compatibility constraints from upgrading. To see why use `status --outdated`"
  },
  {
    "objectID": "demos/emojispace.html",
    "href": "demos/emojispace.html",
    "title": "Visualizing Twitter Messages with Emojis",
    "section": "",
    "text": "This example creates a vector space model for classify emojis in Twitter messages, then process and create vectors from messages and project them using a UMAP model. The projection uses the SimilaritySearch allknn operation.\nusing SimilaritySearch, SimSearchManifoldLearning, TextSearch, CodecZlib, JSON, DataFrames, Plots, StatsBase\nusing Downloads: download\ndownloading the dataset, parsing and vectorizing functions\nmkpath(\"tmp\")\ndbfile = \"tmp/emo50k.json.gz\"\nbaseurl = \"https://github.com/sadit/TextClassificationTutorial/raw/refs/heads/main/data/emo50k.json.gz\"\n!isfile(dbfile) && download(baseurl, dbfile)\n\nfalse\nNow, we load the dataset\nD = DataFrame(open(GzipDecompressorStream, dbfile) do f\n    JSON.parse.(eachline(f))\nend)\n\ncollect(countmap(D.klass))\n\n64-element Vector{Pair{String, Int64}}:\n \"✨\" =&gt; 801\n \"🤤\" =&gt; 771\n \"😁\" =&gt; 794\n \"😡\" =&gt; 776\n \"😏\" =&gt; 757\n \"🤣\" =&gt; 780\n \"👌\" =&gt; 779\n \"😭\" =&gt; 785\n \"🤔\" =&gt; 732\n \"😈\" =&gt; 774\n      ⋮\n \"🙄\" =&gt; 748\n \"💙\" =&gt; 770\n \"🙊\" =&gt; 786\n \"😘\" =&gt; 815\n \"🙈\" =&gt; 772\n \"💕\" =&gt; 747\n \"😑\" =&gt; 812\n \"😔\" =&gt; 782\n \"😳\" =&gt; 839\nD = filter(D) do r\n    r.klass in (\"😭\", \"🤣\", \"😍\", \"😤\")\nend\n\ncollect(countmap(D.klass))\n#H = sort!(collect(countmap(D.klass)), by=first)\n#bar(first.(H), last.(H))\n\n4-element Vector{Pair{String, Int64}}:\n \"🤣\" =&gt; 780\n \"😤\" =&gt; 808\n \"😭\" =&gt; 785\n \"😍\" =&gt; 816\nFunctions create to encode texto into bag-of-word vectors\ntextconfig = TextConfig(\n    group_usr=true,\n    group_url=true,\n    del_diac=true,\n    lc=true,\n    group_num=true,\n    nlist=[1],\n    qlist=[3])\n\n# corpus here can be a sample to avoid double parsing\nvoc = Vocabulary(textconfig, D.text) \n# model = VectorModel(IdfWeighting(), TfWeighting(), voc)\nmodel = VectorModel(EntropyWeighting(), BinaryLocalWeighting(), voc, D.text, D.klass; smooth=1.0)\n#model = VectorModel(IdfWeighting(), TfWeighting(), voc)\nmodel = filter_tokens(model) do t\n    t.weight &gt;= 0.075\nend\nvectors = VectorDatabase(vectorize_corpus(model, D.text))"
  },
  {
    "objectID": "demos/emojispace.html#umap-projections",
    "href": "demos/emojispace.html#umap-projections",
    "title": "Visualizing Twitter Messages with Emojis",
    "section": "UMAP projections",
    "text": "UMAP projections\nUMAP projection can take a while, even on multithreading systems. Note that we are creating 2d and 3d projections.\n\n1e2, e3 = let min_dist=0.5f0,\n             k=16,\n             n_epochs=75,\n             neg_sample_rate=3,\n             tol=1e-3,\n             layout=SpectralLayout(),\n             indexsize=768,\n             dist=NormalizedCosineDistance()\n\n    index = ExhaustiveSearch(; db=rand(vectors, indexsize), dist)\n    @time U2 = fit(UMAP, index; k, neg_sample_rate, layout, n_epochs, tol, min_dist)\n    @time U3 = fit(U2, 3; neg_sample_rate, n_epochs, tol)\n    @time e2 = clamp.(predict(U2, vectors), -10f0, 10f0)\n    @time e3 = clamp.(predict(U3, vectors), -10f0, 10f0)\n    e2, e3\nend\n\n\n1\n\nThe UMAP algorithm has a lot of hyperparameters; min_dist controls the distance between projected points, k is the number of neighbors to be used in the underlying \\(k\\)nn graph, n_epochs the number of epochs used to optimize the projection, neg_sample_rate means for the number of negative examples used in the optimization process, tol the tolerance to converge, layout"
  },
  {
    "objectID": "demos/emojispace.html#visualizations",
    "href": "demos/emojispace.html#visualizations",
    "title": "Visualizing Twitter Messages with Emojis",
    "section": "Visualizations",
    "text": "Visualizations\n\nfunction normcolors(V)\n    min_, max_ = extrema(V)\n    V .= (V .- min_) ./ (max_ - min_)\n    V .= clamp.(V, 0, 1)\nend\n\nnormcolors(@view e3[1, :])\nnormcolors(@view e3[2, :])\nnormcolors(@view e3[3, :])\n\nC = [RGB(c[1], c[2], c[3]) for c in eachcol(e3)]\n\nX = @view e2[1, :]\nY = @view e2[2, :]\nscatter(X, Y, color=C, markersize=4, alpha=0.5)\n\nfor i in 1:100\n    j = rand(1:length(D.klass))\n    annotate!(X[j], Y[j], text(D.klass[j], :blue, :right, 8, \"noto\"))\nend\n\nplot!()"
  },
  {
    "objectID": "demos/emojispace.html#environment-and-dependencies",
    "href": "demos/emojispace.html#environment-and-dependencies",
    "title": "Visualizing Twitter Messages with Emojis",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.10\nCommit 95f30e51f41 (2025-06-27 09:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 × Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_NUM_THREADS = auto\n  JULIA_PROJECT = .\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/Research/SimilaritySearchDemos/Project.toml`\n  [aaaa29a8] Clustering v0.15.8\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.8.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.1\n  [682c06a0] JSON v0.21.4\n  [23fbe1c1] Latexify v0.16.10\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\n⌃ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.20\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.1\n  [053f045d] SimilaritySearch v0.13.0\n⌅ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.6\nInfo Packages marked with ⌃ and ⌅ have new versions available. Those with ⌃ may be upgradable, but those with ⌅ are restricted by compatibility constraints from upgrading. To see why use `status --outdated`"
  },
  {
    "objectID": "demos/index.html",
    "href": "demos/index.html",
    "title": "Tutorials",
    "section": "",
    "text": "We separate the examples by the kind of data, since some of the datasets are quite large and will require a lot of computer power. We also list how to connect SimilaritySearch with other packages that require solving k nearest neighbor queries.\n\n\n\n2d example\n\n\n\n\n\nPrime factors\nManifoldLearning – scurve and prime gaps\n\n\n\n\n\nGlove embeddings\nEmoji space\nPodcast collection\n\n\n\n\n\nMNIST"
  },
  {
    "objectID": "demos/index.html#list-of-examples",
    "href": "demos/index.html#list-of-examples",
    "title": "Tutorials",
    "section": "",
    "text": "We separate the examples by the kind of data, since some of the datasets are quite large and will require a lot of computer power. We also list how to connect SimilaritySearch with other packages that require solving k nearest neighbor queries.\n\n\n\n2d example\n\n\n\n\n\nPrime factors\nManifoldLearning – scurve and prime gaps\n\n\n\n\n\nGlove embeddings\nEmoji space\nPodcast collection\n\n\n\n\n\nMNIST"
  },
  {
    "objectID": "demos/podcast-collection.html",
    "href": "demos/podcast-collection.html",
    "title": "Searching in podcast collection",
    "section": "",
    "text": "using SimilaritySearch, SimSearchManifoldLearning, TextSearch, CodecZlib, JSON, DataFrames, Plots, StatsBase, DataFrames, Clustering, Markdown, Latexify\nusing Downloads: download\nThis example is about searching in a caption/subtitle collection, i.e., looking for passages in audiobooks, youtube videos, conferences, podcasts, etc. The audio should be translated with a speech to text model, i.e., Whisper of OpenAI.\nHaving a WebVTT set of files we need to load the corpus. The files we are using as dataset are WebVTT subtitles, which can be readed with the following code, note that this code is not part of the example and can be ignored.\nNow, we load the dataset\npodcasts = sort!(readdir(\"/home/sadit/sites/SimilaritySearchDemos/podcast-vtt/\", join=true))\nD = DataFrame(idfile=String[], name=String[], tbegin=String[], tend=String[], caption=String[])\n\nfor filename in podcasts\n    webvtt!(filename, basename(filename), D)\nend\n\nD\n\n21013×5 DataFrame20988 rows omitted\n\n\n\nRow\nidfile\nname\ntbegin\ntend\ncaption\n\n\n\nString\nString\nString\nString\nString\n\n\n\n\n1\ntres-patines-y-la-tremenda-corte_0000.vtt\n\n00:00.000\n00:11.000\nAudiencia pública, el tremendo juez de la tremenda corte va a resolver un tremendo caso.\n\n\n2\ntres-patines-y-la-tremenda-corte_0000.vtt\n\n00:11.000\n00:13.000\nBuenas noches, secretario.\n\n\n3\ntres-patines-y-la-tremenda-corte_0000.vtt\n\n00:15.000\n00:18.000\nBuenas noches, señor juez. ¿Cómo se siente hoy?\n\n\n4\ntres-patines-y-la-tremenda-corte_0000.vtt\n\n00:18.000\n00:25.000\nCampana. Hoy me siento panetela. De manera que vamos a ver si acabamos pronto que esta noche me voy de rumba.\n\n\n5\ntres-patines-y-la-tremenda-corte_0000.vtt\n\n00:25.000\n00:27.000\nNo me digas. ¿Se va usted de rumba?\n\n\n6\ntres-patines-y-la-tremenda-corte_0000.vtt\n\n00:27.000\n00:30.000\nSí, tengo un carrito ahí que es algo serio.\n\n\n7\ntres-patines-y-la-tremenda-corte_0000.vtt\n\n00:30.000\n00:32.000\nAh, oígame. ¿Jóven?\n\n\n8\ntres-patines-y-la-tremenda-corte_0000.vtt\n\n00:32.000\n00:36.000\nUn pollito. No tiene más que 46 años.\n\n\n9\ntres-patines-y-la-tremenda-corte_0000.vtt\n\n00:36.000\n00:40.000\n¿Y una mujer de 46 años le llama a usted pollito todavía?\n\n\n10\ntres-patines-y-la-tremenda-corte_0000.vtt\n\n00:40.000\n00:42.000\nClaro que sí. ¿Qué número es gallina en la bola?\n\n\n11\ntres-patines-y-la-tremenda-corte_0000.vtt\n\n00:42.000\n00:43.000\n54.\n\n\n12\ntres-patines-y-la-tremenda-corte_0000.vtt\n\n00:43.000\n00:45.000\nEntonces hasta los 53 sigue siendo un pollito.\n\n\n13\ntres-patines-y-la-tremenda-corte_0000.vtt\n\n00:45.000\n00:47.000\nAh, bueno. ¿Y es bonita?\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n21002\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n16:26.080\n16:26.880\n¿Por qué?\n\n\n21003\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n16:26.880\n16:28.200\nPorque no tuvieron éxito.\n\n\n21004\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n16:28.200\n16:29.800\nEscriba ahí, secretario.\n\n\n21005\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n16:29.840\n16:31.400\nVenga la sentencia.\n\n\n21006\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n16:31.400\n16:35.040\nEl tribunal dictamina que ustedes han hecho leña a la finca de\n\n\n21007\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n16:35.040\n16:37.440\nNananina perjudicando a su dueña.\n\n\n21008\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n16:37.440\n16:40.520\nY por todo ese estropicio que parece obra de locos,\n\n\n21009\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n16:40.520\n16:44.040\npagarán 5,000 cocos más las costas de este juicio.\n\n\n21010\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n16:44.040\n16:47.720\nEscucha el siguiente programa de La Tremenda Corte con Leopoldo\n\n\n21011\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n16:47.720\n16:50.920\nFernández, Mimí Cali y Aníbal de Mar por esta emisora.\n\n\n21012\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n16:50.920\n16:53.720\nHasta entonces, Manolo Iglesias, que les habla,\n\n\n21013\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n16:53.720\n16:56.360\nles dice, muy buena suerte, amigos.\nFunctions create to encode texto into bag-of-word vectors\ntextconfig = TextConfig(\n    group_usr=true,\n    group_url=true,\n    del_diac=true,\n    lc=true,\n    group_num=true,\n    nlist=[1],\n    qlist=[])\n\n# corpus here can be a sample to avoid double parsing\nvoc = Vocabulary(textconfig, D.caption) \nmodel = VectorModel(IdfWeighting(), TfWeighting(), voc)\n# model = VectorModel(EntropyWeighting(), BinaryLocalWeighting(), voc, D.text, D.klass; smooth=1.0)\n#model = VectorModel(IdfWeighting(), TfWeighting(), voc)\nmodel = filter_tokens(model) do t\n    t.weight &gt;= 0.05\nend\n\nvectors = VectorDatabase(vectorize_corpus(model, D.caption))"
  },
  {
    "objectID": "demos/podcast-collection.html#umap-projections",
    "href": "demos/podcast-collection.html#umap-projections",
    "title": "Searching in podcast collection",
    "section": "UMAP projections",
    "text": "UMAP projections\nUMAP projection can take a while, even on multithreading systems. Note that we are creating 2d and 3d projections.\n\n1e2, e3 = let min_dist=0.5f0,\n             k=16,\n             n_epochs=75,\n             neg_sample_rate=3,\n             tol=1e-3,\n             layout=SpectralLayout(),\n             indexsize=2048,\n             dist=NormalizedCosineDistance()\n\n    index = ExhaustiveSearch(; db=rand(vectors, indexsize), dist)\n    @time U2 = fit(UMAP, index; k, neg_sample_rate, layout, n_epochs, tol, min_dist)\n    @time U3 = fit(U2, 3; neg_sample_rate, n_epochs, tol)\n    @time e2 = clamp.(predict(U2, vectors), -10f0, 10f0)\n    @time e3 = clamp.(predict(U3, vectors), -10f0, 10f0)\n    e2, e3\nend\n\n\n1\n\nThe UMAP algorithm has a lot of hyperparameters; min_dist controls the distance between projected points, k is the number of neighbors to be used in the underlying \\(k\\)nn graph, n_epochs the number of epochs used to optimize the projection, neg_sample_rate means for the number of negative examples used in the optimization process, tol the tolerance to converge, layout"
  },
  {
    "objectID": "demos/podcast-collection.html#visualizations",
    "href": "demos/podcast-collection.html#visualizations",
    "title": "Searching in podcast collection",
    "section": "Visualizations",
    "text": "Visualizations\n\nfunction normcolors(V)\n    min_, max_ = extrema(V)\n    V .= (V .- min_) ./ (max_ - min_)\n    V .= clamp.(V, 0, 1)\nend\n\nnormcolors(@view e3[1, :])\nnormcolors(@view e3[2, :])\nnormcolors(@view e3[3, :])\n\nC = [RGB(c[1], c[2], c[3]) for c in eachcol(e3)]\n\nX = @view e2[1, :]\nY = @view e2[2, :]\nscatter(X, Y, color=C, fmt=:png, alpha=0.2, size=(600, 600), ma=0.3, ms=2, msw=0, label=\"\")\n\nplot!()\n\n\n\n\n\ndbscanresult = dbscan(e2, 0.035, min_cluster_size=10);\n\n\ndisplay(length(dbscanresult.clusters))\n\nplot()\nfor (i, c) in enumerate(dbscanresult.clusters)\n    X = @view e2[1, c.core_indices]\n    Y = @view e2[2, c.core_indices]\n    scatter!(X, Y, c=:auto, fmt=:png, size=(600, 600), ma=0.3, a=0.3, ms=1, msw=0, label=\"\")\n    if rand() &lt; 0.1  # just to show some examples \n        X = c.core_indices\n        sampled = \"\"\n        if length(X) &gt; 20\n            sampled = \"-- showing a small sample\"\n            X = rand(X, 20)\n        end\n        display(Markdown.parse(\"## Cluster $i with $(length(c.core_indices)) elements $sampled\"))\n        display(latexify(D[X, :], env=:mdtable, latex=false))\n    end\nend\n\nplot!()\n\n174\n\n\nCluster 20 with 23 elements – showing a small sample\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0018.vtt\n\n14:36.000\n14:37.000\nPero acláreme una cosa.\n\n\ntres-patines-y-la-tremenda-corte_0019.vtt\n\n05:22.000\n05:23.000\nUna cosa que él leyó allí.\n\n\ntres-patines-y-la-tremenda-corte_0037.vtt\n\n05:15.000\n05:17.000\nNada, chicos, esta cosa de la vida.\n\n\ntres-patines-y-la-tremenda-corte_0037.vtt\n\n05:17.000\n05:19.000\nCosa de la vida, cosa suya.\n\n\ntres-patines-y-la-tremenda-corte_0040.vtt\n\n11:39.000\n11:40.000\nBueno, les voy a decir.\n\n\ntres-patines-y-la-tremenda-corte_0040.vtt\n\n11:39.000\n11:40.000\nBueno, les voy a decir.\n\n\ntres-patines-y-la-tremenda-corte_0017.vtt\n\n07:00.000\n07:02.000\nMire cómo es la cosa.\n\n\ntres-patines-y-la-tremenda-corte_0000.vtt\n\n02:49.000\n02:50.000\nPero acláreme una cosa.\n\n\ntres-patines-y-la-tremenda-corte_0018.vtt\n\n14:36.000\n14:37.000\nPero acláreme una cosa.\n\n\ntres-patines-y-la-tremenda-corte_0018.vtt\n\n14:36.000\n14:37.000\nPero acláreme una cosa.\n\n\ntres-patines-y-la-tremenda-corte_0024.vtt\n\n05:38.000\n05:40.000\nQue lo traigo para freír\n\n\ntres-patines-y-la-tremenda-corte_0036.vtt\n\n03:30.000\n03:33.000\nClaro que sí, chico. Si alguien te tiene frito a ti, será ella, chico.\n\n\ntres-patines-y-la-tremenda-corte_0018.vtt\n\n11:27.000\n11:28.000\n¿Que fue usted sorprendida\n\n\ntres-patines-y-la-tremenda-corte_0009.vtt\n\n02:14.000\n02:15.000\nQué cosa, hombre.\n\n\ntres-patines-y-la-tremenda-corte_0011.vtt\n\n13:08.000\n13:09.000\n¿Y no es la misma cosa?\n\n\ntres-patines-y-la-tremenda-corte_0044.vtt\n\n03:36.000\n03:38.000\nMe le paré a la... en la misma carreta le dije setenta mil horroretos.\n\n\ntres-patines-y-la-tremenda-corte_0018.vtt\n\n11:27.000\n11:28.000\n¿Que fue usted sorprendida\n\n\ntres-patines-y-la-tremenda-corte_0044.vtt\n\n11:03.000\n11:04.000\n¿Y eso por qué?\n\n\ntres-patines-y-la-tremenda-corte_0040.vtt\n\n05:16.000\n05:18.000\nEntonces la cosa parece grave.\n\n\ntres-patines-y-la-tremenda-corte_0018.vtt\n\n14:36.000\n14:37.000\nPero acláreme una cosa.\n\n\n\n\n\n\n\nCluster 41 with 40 elements – showing a small sample\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0000.vtt\n\n05:41.000\n05:43.000\nPues cállese entonces, señor.\n\n\ntres-patines-y-la-tremenda-corte_0025.vtt\n\n01:20.440\n01:23.520\nQue los otros días fue a la playa de Boca Ciega.\n\n\ntres-patines-y-la-tremenda-corte_0028.vtt\n\n14:26.000\n14:27.000\n¿Con el cigarro en la boca?\n\n\ntres-patines-y-la-tremenda-corte_0005.vtt\n\n06:47.000\n06:48.000\nCállese ahora, trepatín.\n\n\ntres-patines-y-la-tremenda-corte_0045.vtt\n\n06:01.000\n06:03.000\nBueno, bueno, cállese la boca.\n\n\ntres-patines-y-la-tremenda-corte_0005.vtt\n\n06:47.000\n06:48.000\nCállese ahora, trepatín.\n\n\ntres-patines-y-la-tremenda-corte_0033.vtt\n\n07:21.000\n07:22.000\nCállese la boca\n\n\ntres-patines-y-la-tremenda-corte_0005.vtt\n\n06:47.000\n06:48.000\nCállese ahora, trepatín.\n\n\ntres-patines-y-la-tremenda-corte_0003.vtt\n\n15:42.320\n15:43.320\nCállese la boca.\n\n\ntres-patines-y-la-tremenda-corte_0005.vtt\n\n06:50.000\n06:51.000\nCállese la boca.\n\n\ntres-patines-y-la-tremenda-corte_0018.vtt\n\n05:29.000\n05:31.000\nCáese la boca.\n\n\ntres-patines-y-la-tremenda-corte_0042.vtt\n\n11:26.000\n11:27.000\nCon la boca del tógamo.\n\n\ntres-patines-y-la-tremenda-corte_0010.vtt\n\n07:02.000\n07:04.000\nMire, cállese usted la boca, cállese la boca.\n\n\ntres-patines-y-la-tremenda-corte_0005.vtt\n\n06:50.000\n06:51.000\nCállese la boca.\n\n\ntres-patines-y-la-tremenda-corte_0033.vtt\n\n07:24.000\n07:26.000\nCállese la boca\n\n\ntres-patines-y-la-tremenda-corte_0014.vtt\n\n09:07.000\n09:08.000\nCállese la boca a usted\n\n\ntres-patines-y-la-tremenda-corte_0005.vtt\n\n06:47.000\n06:48.000\nCállese ahora, trepatín.\n\n\ntres-patines-y-la-tremenda-corte_0015.vtt\n\n05:16.000\n05:17.000\nCállese la boca.\n\n\ntres-patines-y-la-tremenda-corte_0015.vtt\n\n05:16.000\n05:17.000\nCállese la boca.\n\n\ntres-patines-y-la-tremenda-corte_0033.vtt\n\n07:24.000\n07:26.000\nCállese la boca\n\n\n\n\n\n\n\nCluster 58 with 34 elements – showing a small sample\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0011.vtt\n\n10:03.000\n10:04.000\nSí, mire.\n\n\ntres-patines-y-la-tremenda-corte_0011.vtt\n\n10:03.000\n10:04.000\nSí, mire.\n\n\ntres-patines-y-la-tremenda-corte_0017.vtt\n\n01:49.000\n01:50.000\nSí, sí, sí. Da gusto consultarse.\n\n\ntres-patines-y-la-tremenda-corte_0011.vtt\n\n12:16.000\n12:18.000\nSí, una comida redonda.\n\n\ntres-patines-y-la-tremenda-corte_0013.vtt\n\n00:47.000\n00:48.000\nSí, estilo Chicago.\n\n\ntres-patines-y-la-tremenda-corte_0044.vtt\n\n13:36.000\n13:37.000\nSí, se subió.\n\n\ntres-patines-y-la-tremenda-corte_0044.vtt\n\n13:36.000\n13:37.000\nSí, se subió.\n\n\ntres-patines-y-la-tremenda-corte_0031.vtt\n\n01:50.000\n01:52.000\nSí, lo felicito.\n\n\ntres-patines-y-la-tremenda-corte_0048.vtt\n\n08:10.000\n08:11.000\nSí, el plan de regalos.\n\n\ntres-patines-y-la-tremenda-corte_0019.vtt\n\n07:34.000\n07:36.000\nMedianoche con pepino, sí.\n\n\ntres-patines-y-la-tremenda-corte_0016.vtt\n\n07:37.160\n07:38.160\nDe los corpulentos, sí.\n\n\ntres-patines-y-la-tremenda-corte_0000.vtt\n\n10:21.000\n10:22.000\nSí, hombre, sí.\n\n\ntres-patines-y-la-tremenda-corte_0037.vtt\n\n02:33.000\n02:35.000\nSí, filantrópico, sí.\n\n\ntres-patines-y-la-tremenda-corte_0037.vtt\n\n02:33.000\n02:35.000\nSí, filantrópico, sí.\n\n\ntres-patines-y-la-tremenda-corte_0020.vtt\n\n05:43.000\n05:44.000\nPalabra que sí.\n\n\ntres-patines-y-la-tremenda-corte_0019.vtt\n\n07:34.000\n07:36.000\nMedianoche con pepino, sí.\n\n\ntres-patines-y-la-tremenda-corte_0009.vtt\n\n14:28.000\n14:30.000\nSí, es angina de pecho.\n\n\ntres-patines-y-la-tremenda-corte_0006.vtt\n\n04:47.000\n04:48.000\nSí, vigente.\n\n\ntres-patines-y-la-tremenda-corte_0031.vtt\n\n09:19.000\n09:20.000\nSí, sí.\n\n\ntres-patines-y-la-tremenda-corte_0018.vtt\n\n11:08.000\n11:09.000\nSí, tú, sí, tú.\n\n\n\n\n\n\n\nCluster 61 with 10 elements\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0000.vtt\n\n13:42.000\n13:43.000\nPero eso lo sabe todo el mundo.\n\n\ntres-patines-y-la-tremenda-corte_0009.vtt\n\n11:38.000\n11:41.000\nY que lo lleven al matadero a ver si no se pone nervioso.\n\n\ntres-patines-y-la-tremenda-corte_0019.vtt\n\n05:24.000\n05:28.000\nDe no sé qué ley, que tampoco sé quién ha hecho una ley de esa índole.\n\n\ntres-patines-y-la-tremenda-corte_0020.vtt\n\n01:57.000\n02:00.000\nVamos a ver usted la estafada, Nananina.\n\n\ntres-patines-y-la-tremenda-corte_0033.vtt\n\n09:17.000\n09:19.000\nA ver, vamos por parte\n\n\ntres-patines-y-la-tremenda-corte_0039.vtt\n\n04:12.600\n04:13.900\nBueno, a ver, explíquemelo.\n\n\ntres-patines-y-la-tremenda-corte_0039.vtt\n\n04:34.300\n04:36.000\nBueno, la cuestión del farol.\n\n\ntres-patines-y-la-tremenda-corte_0040.vtt\n\n13:14.000\n13:15.000\nA ver.\n\n\ntres-patines-y-la-tremenda-corte_0041.vtt\n\n01:27.120\n01:28.520\nA ver, déjeme ver esa letra.\n\n\ntres-patines-y-la-tremenda-corte_0048.vtt\n\n04:45.000\n04:46.000\nA ver.\n\n\n\n\n\n\n\nCluster 74 with 49 elements – showing a small sample\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0004.vtt\n\n09:35.000\n09:37.000\nSí, mamita le tiró el zapato y yo dije, ¡ay!\n\n\ntres-patines-y-la-tremenda-corte_0022.vtt\n\n01:23.000\n01:24.000\n¡Presidente!\n\n\ntres-patines-y-la-tremenda-corte_0028.vtt\n\n12:09.000\n12:10.000\n¡Miao!\n\n\ntres-patines-y-la-tremenda-corte_0041.vtt\n\n12:39.120\n12:41.120\nAh, una gallina cayó eso ¡pam!\n\n\ntres-patines-y-la-tremenda-corte_0028.vtt\n\n11:55.000\n11:56.000\nY empezó a gritar ¡Miao!\n\n\ntres-patines-y-la-tremenda-corte_0042.vtt\n\n01:25.000\n01:27.000\n¡Ay, el fantasma!\n\n\ntres-patines-y-la-tremenda-corte_0028.vtt\n\n12:09.000\n12:10.000\n¡Miao!\n\n\ntres-patines-y-la-tremenda-corte_0006.vtt\n\n01:51.000\n01:53.000\n¡A la reja!\n\n\ntres-patines-y-la-tremenda-corte_0007.vtt\n\n02:59.000\n03:00.000\n¡Silencio!\n\n\ntres-patines-y-la-tremenda-corte_0004.vtt\n\n09:35.000\n09:37.000\nSí, mamita le tiró el zapato y yo dije, ¡ay!\n\n\ntres-patines-y-la-tremenda-corte_0045.vtt\n\n08:00.000\n08:01.000\n¡180 días!\n\n\ntres-patines-y-la-tremenda-corte_0002.vtt\n\n11:18.000\n11:19.000\n¡Tira eso!\n\n\ntres-patines-y-la-tremenda-corte_0027.vtt\n\n08:11.000\n08:12.000\n¡Me morro!\n\n\ntres-patines-y-la-tremenda-corte_0031.vtt\n\n08:50.000\n08:51.000\n¡Namba, qué sorpresa!\n\n\ntres-patines-y-la-tremenda-corte_0004.vtt\n\n09:35.000\n09:37.000\nSí, mamita le tiró el zapato y yo dije, ¡ay!\n\n\ntres-patines-y-la-tremenda-corte_0036.vtt\n\n08:19.000\n08:20.000\n¡Ah!\n\n\ntres-patines-y-la-tremenda-corte_0023.vtt\n\n08:24.600\n08:25.600\n¡Y el peso de lucha!\n\n\ntres-patines-y-la-tremenda-corte_0047.vtt\n\n01:52.000\n01:54.000\n¡A la vea!\n\n\ntres-patines-y-la-tremenda-corte_0048.vtt\n\n11:18.000\n11:19.000\n¡Dígame!\n\n\ntres-patines-y-la-tremenda-corte_0024.vtt\n\n00:02.000\n00:04.000\n¡No se olvide que tenéis que pagar mi lechona!\n\n\n\n\n\n\n\nCluster 83 with 14 elements\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0001.vtt\n\n07:12.000\n07:13.000\n¿A agarrarlo por qué, señor?\n\n\ntres-patines-y-la-tremenda-corte_0014.vtt\n\n14:19.000\n14:21.000\nNo, señor. Eso es fuerza de cara.\n\n\ntres-patines-y-la-tremenda-corte_0015.vtt\n\n04:34.000\n04:35.000\nOiganme, señor juez.\n\n\ntres-patines-y-la-tremenda-corte_0018.vtt\n\n01:21.000\n01:23.000\nEnseguida, señor juez.\n\n\ntres-patines-y-la-tremenda-corte_0019.vtt\n\n01:28.000\n01:30.000\nEnseguida, señor juez.\n\n\ntres-patines-y-la-tremenda-corte_0020.vtt\n\n01:37.000\n01:39.000\nEnseguida, señor juez.\n\n\ntres-patines-y-la-tremenda-corte_0025.vtt\n\n08:24.440\n08:25.040\nMande, señor juez.\n\n\ntres-patines-y-la-tremenda-corte_0025.vtt\n\n08:30.120\n08:32.520\nCuando venía del señor juez,\n\n\ntres-patines-y-la-tremenda-corte_0027.vtt\n\n00:42.000\n00:43.000\nPero mire señor juez.\n\n\ntres-patines-y-la-tremenda-corte_0028.vtt\n\n00:56.000\n01:02.000\nUn escaparate. Pues llámelo complicado en ese escaparaticidio. Enseguida señor juez.\n\n\ntres-patines-y-la-tremenda-corte_0032.vtt\n\n01:01.800\n01:07.960\nen ese español y sí enseguida señor juez rude cingo caldeiro y escobiña presentes\n\n\ntres-patines-y-la-tremenda-corte_0040.vtt\n\n05:42.000\n05:43.000\nClaro, señor juez.\n\n\ntres-patines-y-la-tremenda-corte_0045.vtt\n\n00:44.000\n00:45.000\nEnseguida señor juez.\n\n\ntres-patines-y-la-tremenda-corte_0049.vtt\n\n02:07.000\n02:14.000\nNo, señor, lo único que yo le hice a Rubesindo fue venderle 40 galones de gasolina especial para guagua.\n\n\n\n\n\n\n\nCluster 92 with 14 elements\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0001.vtt\n\n12:37.000\n12:38.000\nDe una caída, sí.\n\n\ntres-patines-y-la-tremenda-corte_0005.vtt\n\n02:27.000\n02:29.000\nNo, pero esa sí.\n\n\ntres-patines-y-la-tremenda-corte_0008.vtt\n\n13:25.000\n13:26.000\nSí, se dobló.\n\n\ntres-patines-y-la-tremenda-corte_0014.vtt\n\n12:05.000\n12:07.000\nEl vapor, sí.\n\n\ntres-patines-y-la-tremenda-corte_0018.vtt\n\n06:18.000\n06:19.000\nMunicipio, sí.\n\n\ntres-patines-y-la-tremenda-corte_0020.vtt\n\n09:54.000\n09:55.000\nSí, mi querido y estimado Dr.\n\n\ntres-patines-y-la-tremenda-corte_0028.vtt\n\n02:41.000\n02:52.000\n¿Sí? Hombre, pues si lo supieran en algún lado ya no sería secreto. Entonces nadie sabe que usted es policía. Bueno, sí, lo sabe una persona nada más.\n\n\ntres-patines-y-la-tremenda-corte_0040.vtt\n\n09:04.000\n09:05.000\nSí, vale.\n\n\ntres-patines-y-la-tremenda-corte_0044.vtt\n\n04:37.000\n04:38.000\nAhora, que eso sí.\n\n\ntres-patines-y-la-tremenda-corte_0044.vtt\n\n06:43.000\n06:44.000\nSí, sí.\n\n\ntres-patines-y-la-tremenda-corte_0044.vtt\n\n09:31.000\n09:32.000\nSí, sí.\n\n\ntres-patines-y-la-tremenda-corte_0045.vtt\n\n07:56.000\n07:58.000\nSí, pero lo que no puedes comer hierba.\n\n\ntres-patines-y-la-tremenda-corte_0049.vtt\n\n12:42.000\n12:44.000\nDe la cuenca sur, sí.\n\n\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n10:56.160\n10:57.160\nSi está de frente a frente.\n\n\n\n\n\n\n\nCluster 95 with 24 elements – showing a small sample\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0009.vtt\n\n00:00.000\n00:12.000\nAudiencia publica, el tremendo juez de la tremenda corte va a resolver un tremendo caso.\n\n\ntres-patines-y-la-tremenda-corte_0039.vtt\n\n10:31.400\n10:35.900\nBueno, no, porque con el boca debajo los pulmones quedan apretados, tú sabes.\n\n\ntres-patines-y-la-tremenda-corte_0031.vtt\n\n07:42.000\n07:44.000\nYo no tengo trapitos sucios ninguno para que se entere.\n\n\ntres-patines-y-la-tremenda-corte_0031.vtt\n\n07:42.000\n07:44.000\nYo no tengo trapitos sucios ninguno para que se entere.\n\n\ntres-patines-y-la-tremenda-corte_0012.vtt\n\n11:50.960\n11:52.960\nropa en la escalera de ese edificio.\n\n\ntres-patines-y-la-tremenda-corte_0039.vtt\n\n10:31.400\n10:35.900\nBueno, no, porque con el boca debajo los pulmones quedan apretados, tú sabes.\n\n\ntres-patines-y-la-tremenda-corte_0012.vtt\n\n11:50.960\n11:52.960\nropa en la escalera de ese edificio.\n\n\ntres-patines-y-la-tremenda-corte_0023.vtt\n\n12:07.600\n12:09.600\nPorque me han dicho que yo tengo condiciones para eso.\n\n\ntres-patines-y-la-tremenda-corte_0023.vtt\n\n12:07.600\n12:09.600\nPorque me han dicho que yo tengo condiciones para eso.\n\n\ntres-patines-y-la-tremenda-corte_0035.vtt\n\n08:06.000\n08:09.000\nPero sé que se venden así porque los he comprado cuando era chiquito.\n\n\ntres-patines-y-la-tremenda-corte_0045.vtt\n\n05:14.000\n05:15.000\nDe una mate mango.\n\n\ntres-patines-y-la-tremenda-corte_0010.vtt\n\n02:49.000\n02:52.000\nmamita puso una cazuela sobre la mesa del comedor.\n\n\ntres-patines-y-la-tremenda-corte_0021.vtt\n\n06:55.000\n06:59.000\nSí, rudecido le dice cuál es la izquierda y entonces yo le digo cuál es la derecha.\n\n\ntres-patines-y-la-tremenda-corte_0039.vtt\n\n10:31.400\n10:35.900\nBueno, no, porque con el boca debajo los pulmones quedan apretados, tú sabes.\n\n\ntres-patines-y-la-tremenda-corte_0003.vtt\n\n09:56.700\n10:04.620\nmotoneta no a pie llevaba su cajóncito igual que el mismo el cajón del limpia\n\n\ntres-patines-y-la-tremenda-corte_0036.vtt\n\n06:40.000\n06:41.000\nSu mamita baila merengue.\n\n\ntres-patines-y-la-tremenda-corte_0045.vtt\n\n05:14.000\n05:15.000\nDe una mate mango.\n\n\ntres-patines-y-la-tremenda-corte_0017.vtt\n\n11:32.000\n11:38.000\nMientras en el mundo haya una ganzúa y una pata de cabra, el hijo de mamita nunca pasará hambre, para que te enteres.\n\n\ntres-patines-y-la-tremenda-corte_0017.vtt\n\n11:32.000\n11:38.000\nMientras en el mundo haya una ganzúa y una pata de cabra, el hijo de mamita nunca pasará hambre, para que te enteres.\n\n\ntres-patines-y-la-tremenda-corte_0036.vtt\n\n06:40.000\n06:41.000\nSu mamita baila merengue.\n\n\n\n\n\n\n\nCluster 109 with 18 elements\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0002.vtt\n\n13:46.000\n13:53.000\nYo te dije que me esperase unas semanas hasta que yo encontrase otro terrenito vacío para mudar el chaleche.\n\n\ntres-patines-y-la-tremenda-corte_0004.vtt\n\n03:01.000\n03:03.000\n¿Y entonces por qué no la suprimen, chico?\n\n\ntres-patines-y-la-tremenda-corte_0007.vtt\n\n06:48.000\n06:51.000\ndebe al lavandero, debe al carnicero.\n\n\ntres-patines-y-la-tremenda-corte_0010.vtt\n\n05:45.000\n05:46.000\n¿Y eso por qué, chico?\n\n\ntres-patines-y-la-tremenda-corte_0010.vtt\n\n11:16.000\n11:19.000\nque cuánto le cobraba por dar un paseo en máquina.\n\n\ntres-patines-y-la-tremenda-corte_0010.vtt\n\n14:46.000\n14:48.000\nYo le dije, entonces, ¿hora y qué hora es?\n\n\ntres-patines-y-la-tremenda-corte_0011.vtt\n\n06:26.000\n06:28.000\nY saliendo de San Diego de los Baños por esa vereda\n\n\ntres-patines-y-la-tremenda-corte_0012.vtt\n\n10:27.640\n10:29.640\n¿Por qué? Porque cada vez que le tocan a la puerta\n\n\ntres-patines-y-la-tremenda-corte_0013.vtt\n\n13:21.000\n13:25.000\nEn vista de eso, pues yo hablé por el revolver, todo el mundo salió corriendo.\n\n\ntres-patines-y-la-tremenda-corte_0014.vtt\n\n07:43.000\n07:44.000\nBueno, por eso\n\n\ntres-patines-y-la-tremenda-corte_0029.vtt\n\n11:00.000\n11:01.000\n¿Por qué, chico?\n\n\ntres-patines-y-la-tremenda-corte_0031.vtt\n\n05:54.000\n05:56.000\npor incitar a la autoridad a jugar al prohibido.\n\n\ntres-patines-y-la-tremenda-corte_0031.vtt\n\n10:55.000\n10:56.000\nYo no entiendo ni media palabra.\n\n\ntres-patines-y-la-tremenda-corte_0032.vtt\n\n12:42.720\n12:47.880\npagado por él porque 200 pesos por ese puesto no iba a encontrar yo nadie que me lo diera pero\n\n\ntres-patines-y-la-tremenda-corte_0035.vtt\n\n03:24.000\n03:26.000\n¿Y entonces por qué te estoy contestando yo?\n\n\ntres-patines-y-la-tremenda-corte_0041.vtt\n\n10:46.120\n10:48.120\nPero es que rudeciendo dice,\n\n\ntres-patines-y-la-tremenda-corte_0043.vtt\n\n11:57.000\n12:02.000\nPues antes de irse a pelar, cuando estuvo en casa, cargó el gato todo el tiempo, oiga,\n\n\ntres-patines-y-la-tremenda-corte_0047.vtt\n\n02:28.000\n02:32.000\nY cuando se enteró de que venía un ciclón se puso muy nerviosa.\n\n\n\n\n\n\n\nCluster 110 with 14 elements\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0002.vtt\n\n13:53.000\n13:55.000\n¿Cuántas semanas le pidió que lo esperase?\n\n\ntres-patines-y-la-tremenda-corte_0011.vtt\n\n08:25.000\n08:26.000\n¿Le gusta?\n\n\ntres-patines-y-la-tremenda-corte_0014.vtt\n\n11:07.000\n11:08.000\nNo, siempre de qué\n\n\ntres-patines-y-la-tremenda-corte_0015.vtt\n\n11:38.000\n11:39.000\n¿Usted cree?\n\n\ntres-patines-y-la-tremenda-corte_0016.vtt\n\n09:07.960\n09:09.360\n¿Y de lo de sudorra?\n\n\ntres-patines-y-la-tremenda-corte_0019.vtt\n\n08:33.000\n08:35.000\n¿usted se quiere reír en esta\n\n\ntres-patines-y-la-tremenda-corte_0037.vtt\n\n13:29.000\n13:30.000\n¿Dónde? Contésteme.\n\n\ntres-patines-y-la-tremenda-corte_0039.vtt\n\n06:20.300\n06:21.100\n¿Seguro?\n\n\ntres-patines-y-la-tremenda-corte_0040.vtt\n\n07:12.000\n07:13.000\n¿En vez de lo cual?\n\n\ntres-patines-y-la-tremenda-corte_0042.vtt\n\n07:24.000\n07:25.000\n¿Y qué hizo usted, Albert?\n\n\ntres-patines-y-la-tremenda-corte_0044.vtt\n\n09:04.000\n09:06.000\nUsted tiene que pagarle su carro, ¿qué país?\n\n\ntres-patines-y-la-tremenda-corte_0044.vtt\n\n10:16.000\n10:18.000\nSi viene a cruzar ahora, él cerró los ojos.\n\n\ntres-patines-y-la-tremenda-corte_0045.vtt\n\n08:09.000\n08:10.000\nDe nada.\n\n\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n04:00.000\n04:01.000\n¿Qué pasó?\n\n\n\n\n\n\n\nCluster 115 with 17 elements\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0003.vtt\n\n00:51.560\n00:54.600\ny la y para el hígado no no un momento\n\n\ntres-patines-y-la-tremenda-corte_0005.vtt\n\n03:30.000\n03:32.000\nSinforosa no existe.\n\n\ntres-patines-y-la-tremenda-corte_0006.vtt\n\n11:37.000\n11:39.000\nPor la chimenea no podemos entrar porque no cabemos.\n\n\ntres-patines-y-la-tremenda-corte_0009.vtt\n\n06:47.000\n06:48.000\nMomento.\n\n\ntres-patines-y-la-tremenda-corte_0009.vtt\n\n12:06.000\n12:07.000\nRubesindo.\n\n\ntres-patines-y-la-tremenda-corte_0011.vtt\n\n10:38.000\n10:39.000\nNo sé.\n\n\ntres-patines-y-la-tremenda-corte_0014.vtt\n\n10:44.000\n10:45.000\nNo\n\n\ntres-patines-y-la-tremenda-corte_0023.vtt\n\n09:47.600\n09:48.600\nQue yo no enseño.\n\n\ntres-patines-y-la-tremenda-corte_0028.vtt\n\n02:34.000\n02:41.000\nNo, porque en la jefatura no saben que yo soy policía. ¿Cómo que no lo sabes? Claro que no, no le estoy diciendo que soy un policía secreto.\n\n\ntres-patines-y-la-tremenda-corte_0032.vtt\n\n07:22.680\n07:28.680\ndomingo y si no no trabajo pero entre miré levantarse tarde bañarme a almorzar dormir la\n\n\ntres-patines-y-la-tremenda-corte_0033.vtt\n\n06:28.000\n06:29.000\nNo\n\n\ntres-patines-y-la-tremenda-corte_0044.vtt\n\n06:52.000\n06:53.000\nNo debería.\n\n\ntres-patines-y-la-tremenda-corte_0044.vtt\n\n09:59.000\n10:00.000\nPero no paró.\n\n\ntres-patines-y-la-tremenda-corte_0046.vtt\n\n02:52.000\n02:55.000\nY no falla nunca eso no falla nunca\n\n\ntres-patines-y-la-tremenda-corte_0046.vtt\n\n09:16.000\n09:18.000\nNo no no un pollito\n\n\ntres-patines-y-la-tremenda-corte_0046.vtt\n\n09:26.000\n09:27.000\nNo era pollito no\n\n\ntres-patines-y-la-tremenda-corte_0046.vtt\n\n09:28.000\n09:29.000\nNo no no\n\n\n\n\n\n\n\nCluster 125 with 10 elements\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0003.vtt\n\n15:22.320\n15:23.320\ny comerme un potaje de garbanzos.\n\n\ntres-patines-y-la-tremenda-corte_0010.vtt\n\n08:18.000\n08:22.000\nUsted me tiene que pagar cuatro horas menos cinco minutos.\n\n\ntres-patines-y-la-tremenda-corte_0010.vtt\n\n12:05.000\n12:08.000\nyo lo afinco aquí con multas de cinco y de cinco y de cinco\n\n\ntres-patines-y-la-tremenda-corte_0011.vtt\n\n09:11.000\n09:12.000\n¿Usted le invitó?\n\n\ntres-patines-y-la-tremenda-corte_0017.vtt\n\n04:21.000\n04:22.000\nDe 8 onzas.\n\n\ntres-patines-y-la-tremenda-corte_0017.vtt\n\n04:54.000\n04:57.000\nQue como el valor de una libra son 16 onzas,\n\n\ntres-patines-y-la-tremenda-corte_0030.vtt\n\n11:46.440\n11:48.440\ny me dijo que por 50 pesos,\n\n\ntres-patines-y-la-tremenda-corte_0033.vtt\n\n05:43.000\n05:44.000\nUn sillón de barbero\n\n\ntres-patines-y-la-tremenda-corte_0035.vtt\n\n08:51.000\n08:52.000\n1918.\n\n\ntres-patines-y-la-tremenda-corte_0036.vtt\n\n08:47.000\n08:48.000\nSiga usted, Anamina.\n\n\n\n\n\n\n\nCluster 128 with 31 elements – showing a small sample\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0005.vtt\n\n08:22.000\n08:24.000\nDiez pesos de multa por esa aclaración.\n\n\ntres-patines-y-la-tremenda-corte_0019.vtt\n\n09:20.000\n09:22.000\nPonle veinte pesos de multa, secretario.\n\n\ntres-patines-y-la-tremenda-corte_0040.vtt\n\n06:17.000\n06:19.000\nNo me costó veinte kilos la macha.\n\n\ntres-patines-y-la-tremenda-corte_0047.vtt\n\n04:45.000\n04:48.000\nPóngale otro 10 pesos de multa, secretario.\n\n\ntres-patines-y-la-tremenda-corte_0017.vtt\n\n04:24.000\n04:27.000\nPongale 50 pesos de multa, rudecido, y que le decomisen la pesa.\n\n\ntres-patines-y-la-tremenda-corte_0040.vtt\n\n06:17.000\n06:19.000\nNo me costó veinte kilos la macha.\n\n\ntres-patines-y-la-tremenda-corte_0048.vtt\n\n10:17.000\n10:19.000\nPóngale cinco pesos más de multa a esta extranjera.\n\n\ntres-patines-y-la-tremenda-corte_0045.vtt\n\n07:53.000\n07:54.000\nVeinte pesos más de multa.\n\n\ntres-patines-y-la-tremenda-corte_0033.vtt\n\n03:24.000\n03:27.000\n10 pesos de multa por insistir\n\n\ntres-patines-y-la-tremenda-corte_0023.vtt\n\n12:51.600\n12:54.600\nfuimos a ver a tres patines para que nos los enseñara los dos.\n\n\ntres-patines-y-la-tremenda-corte_0043.vtt\n\n09:58.000\n10:00.000\nCincuenta pesos de multa.\n\n\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n08:19.000\n08:20.000\nPóngale 50 más.\n\n\ntres-patines-y-la-tremenda-corte_0019.vtt\n\n11:36.000\n11:38.000\nPóngale 23 pesos de multa, secretario.\n\n\ntres-patines-y-la-tremenda-corte_0019.vtt\n\n11:36.000\n11:38.000\nPóngale 23 pesos de multa, secretario.\n\n\ntres-patines-y-la-tremenda-corte_0043.vtt\n\n09:58.000\n10:00.000\nCincuenta pesos de multa.\n\n\ntres-patines-y-la-tremenda-corte_0017.vtt\n\n04:24.000\n04:27.000\nPongale 50 pesos de multa, rudecido, y que le decomisen la pesa.\n\n\ntres-patines-y-la-tremenda-corte_0005.vtt\n\n01:38.000\n01:39.000\nPóngale dos pesos de multa.\n\n\ntres-patines-y-la-tremenda-corte_0047.vtt\n\n04:45.000\n04:48.000\nPóngale otro 10 pesos de multa, secretario.\n\n\ntres-patines-y-la-tremenda-corte_0023.vtt\n\n12:51.600\n12:54.600\nfuimos a ver a tres patines para que nos los enseñara los dos.\n\n\ntres-patines-y-la-tremenda-corte_0011.vtt\n\n06:07.000\n06:09.000\nPongale diez pesos de multa.\n\n\n\n\n\n\n\nCluster 129 with 12 elements\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0004.vtt\n\n08:10.000\n08:11.000\nPalabra que no, chico.\n\n\ntres-patines-y-la-tremenda-corte_0005.vtt\n\n07:33.000\n07:34.000\nPues no se me equivoca más.\n\n\ntres-patines-y-la-tremenda-corte_0005.vtt\n\n08:32.000\n08:33.000\nMe lo pusiste, chico.\n\n\ntres-patines-y-la-tremenda-corte_0005.vtt\n\n14:52.000\n14:54.000\ncarne a la dama, chico.\n\n\ntres-patines-y-la-tremenda-corte_0008.vtt\n\n12:08.000\n12:10.000\nEn el centro gallego, chico.\n\n\ntres-patines-y-la-tremenda-corte_0013.vtt\n\n12:59.000\n13:01.000\nChico, oye, ¿se permite qué, chico?\n\n\ntres-patines-y-la-tremenda-corte_0016.vtt\n\n05:32.560\n05:34.760\nNo seas pócrita, chico.\n\n\ntres-patines-y-la-tremenda-corte_0020.vtt\n\n08:53.000\n08:54.000\nHombre, en el comentario, chico.\n\n\ntres-patines-y-la-tremenda-corte_0021.vtt\n\n04:39.000\n04:41.000\nÓyeme, de ninguna manera, chico.\n\n\ntres-patines-y-la-tremenda-corte_0033.vtt\n\n11:54.000\n11:56.000\nSino los peludos que van a pelarse, chico\n\n\ntres-patines-y-la-tremenda-corte_0042.vtt\n\n01:34.000\n01:36.500\nNo, chico. Yo soy el acusado nomás.\n\n\ntres-patines-y-la-tremenda-corte_0042.vtt\n\n09:14.000\n09:15.000\nTambién, chico.\n\n\n\n\n\n\n\nCluster 149 with 14 elements\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0007.vtt\n\n00:42.000\n00:43.000\nPrimero me pongo una coraza.\n\n\ntres-patines-y-la-tremenda-corte_0013.vtt\n\n04:45.000\n04:53.000\nSí, yo le dije que pusiéramos uno de esos vestidos en la viriera con un letrerito que dijera, lo mejor en encaje con cola.\n\n\ntres-patines-y-la-tremenda-corte_0020.vtt\n\n02:48.000\n02:50.000\nMe dijo usted que estaba colocada en casa de un médico.\n\n\ntres-patines-y-la-tremenda-corte_0025.vtt\n\n04:46.520\n04:50.240\nNada, pues que ahora quedó tan apeñuscado allá adentro\n\n\ntres-patines-y-la-tremenda-corte_0026.vtt\n\n13:23.000\n13:25.000\nse despidió de nosotros,\n\n\ntres-patines-y-la-tremenda-corte_0030.vtt\n\n05:26.440\n05:28.440\nen el transcurso del cual\n\n\ntres-patines-y-la-tremenda-corte_0030.vtt\n\n13:02.440\n13:04.440\nO sea que mamita conseguía\n\n\ntres-patines-y-la-tremenda-corte_0040.vtt\n\n00:45.000\n00:52.000\nQue le dijera que sí, que está dispuesta a ir al cine con usted, pero acompañada por su papá y su mamá.\n\n\ntres-patines-y-la-tremenda-corte_0041.vtt\n\n07:38.120\n07:40.120\nque traía acusado a ese sujeto.\n\n\ntres-patines-y-la-tremenda-corte_0044.vtt\n\n02:19.000\n02:22.000\nEl día ese yo salí fatal del paradero, ¿oíste?\n\n\ntres-patines-y-la-tremenda-corte_0045.vtt\n\n09:52.000\n09:55.000\nNo, señora, yo no ni me ocupé más de las reses para nada.\n\n\ntres-patines-y-la-tremenda-corte_0049.vtt\n\n12:44.000\n12:47.000\nBueno, pues agua lo es de todas maneras, ¿me entiende?\n\n\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n11:47.920\n11:52.120\npatines y en dos meses nada más que estuvieron en la finca me acabaron con ella.\n\n\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n13:14.520\n13:18.800\nEl ñame y los buñatos, eso, el melón y el tronco de yuca honoris causa, ese que ustedes\n\n\n\n\n\n\n\nCluster 155 with 16 elements\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0008.vtt\n\n05:33.000\n05:35.000\nVaya, por Dios.\n\n\ntres-patines-y-la-tremenda-corte_0013.vtt\n\n11:33.000\n11:35.000\nAnote eso, secretario, de modo...\n\n\ntres-patines-y-la-tremenda-corte_0015.vtt\n\n03:25.000\n03:28.000\nPague en efectivo, vaya a la cárcel.\n\n\ntres-patines-y-la-tremenda-corte_0017.vtt\n\n04:43.000\n04:44.000\nVerá usted, doctor.\n\n\ntres-patines-y-la-tremenda-corte_0018.vtt\n\n07:35.000\n07:36.000\nHombre, por Dios.\n\n\ntres-patines-y-la-tremenda-corte_0030.vtt\n\n03:55.240\n03:57.240\nNo se preocupe, Rudecindo, que se le hará justicia.\n\n\ntres-patines-y-la-tremenda-corte_0033.vtt\n\n10:31.000\n10:32.000\nDito Dios\n\n\ntres-patines-y-la-tremenda-corte_0035.vtt\n\n02:18.000\n02:19.000\npara que vaya comiendo.\n\n\ntres-patines-y-la-tremenda-corte_0038.vtt\n\n03:53.000\n03:56.000\nHombre, por Dios, parece hasta mentira\n\n\ntres-patines-y-la-tremenda-corte_0038.vtt\n\n04:59.000\n05:01.000\nHombre, por Dios\n\n\ntres-patines-y-la-tremenda-corte_0039.vtt\n\n04:08.900\n04:09.900\n¿Vista desde dónde?\n\n\ntres-patines-y-la-tremenda-corte_0039.vtt\n\n13:04.400\n13:06.400\nNo, Trespatines, hombre.\n\n\ntres-patines-y-la-tremenda-corte_0042.vtt\n\n10:22.000\n10:25.000\nDe Máximo Plan.\n\n\ntres-patines-y-la-tremenda-corte_0047.vtt\n\n00:39.000\n00:41.000\nVaya, por Dios lo siento señor juez.\n\n\ntres-patines-y-la-tremenda-corte_0048.vtt\n\n09:00.000\n09:01.000\nPero...\n\n\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n00:46.000\n00:48.000\nVaya por Dios, pobrecita ella.\n\n\n\n\n\n\n\nCluster 170 with 43 elements – showing a small sample\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n01:51.000\n01:52.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n01:42.000\n01:43.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n01:42.000\n01:43.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n02:15.000\n02:16.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n04:08.000\n04:09.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n02:16.000\n02:17.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n00:31.000\n00:32.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n00:21.000\n00:22.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n02:16.000\n02:17.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n02:16.000\n02:17.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n03:51.000\n03:52.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n01:14.000\n01:15.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n02:08.000\n02:09.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n02:33.000\n02:34.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n03:51.000\n03:52.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0014.vtt\n\n10:40.000\n10:41.000\nLo denunciaron\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n04:20.000\n04:21.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n03:23.000\n03:24.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n04:20.000\n04:21.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n03:02.000\n03:03.000\n¿Cómo lo hicieron?\n\n\n\n\n\n\n\nCluster 174 with 17 elements\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n00:23.000\n00:24.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n00:33.000\n00:34.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n00:49.000\n00:50.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n00:51.000\n00:52.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n00:52.000\n00:53.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n01:18.000\n01:19.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n01:22.000\n01:23.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n02:21.000\n02:22.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n02:24.000\n02:25.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n02:50.000\n02:51.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n03:01.000\n03:02.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n03:13.000\n03:14.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n03:14.000\n03:15.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n03:46.000\n03:47.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n04:10.000\n04:11.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n04:14.000\n04:15.000\n¿Cómo lo hicieron?\n\n\ntres-patines-y-la-tremenda-corte_0034.vtt\n\n04:26.000\n04:27.000\n¿Cómo lo hicieron?"
  },
  {
    "objectID": "demos/podcast-collection.html#environment-and-dependencies",
    "href": "demos/podcast-collection.html#environment-and-dependencies",
    "title": "Searching in podcast collection",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.10\nCommit 95f30e51f41 (2025-06-27 09:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 × Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_NUM_THREADS = auto\n  JULIA_PROJECT = .\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/Research/SimilaritySearchDemos/Project.toml`\n  [aaaa29a8] Clustering v0.15.8\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.8.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.1\n  [682c06a0] JSON v0.21.4\n  [23fbe1c1] Latexify v0.16.10\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\n⌃ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.20\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.1\n  [053f045d] SimilaritySearch v0.13.0\n⌅ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.6\nInfo Packages marked with ⌃ and ⌅ have new versions available. Those with ⌃ may be upgradable, but those with ⌅ are restricted by compatibility constraints from upgrading. To see why use `status --outdated`"
  },
  {
    "objectID": "demos/syn2d.html",
    "href": "demos/syn2d.html",
    "title": "Visualizing MNIST database",
    "section": "",
    "text": "by: Eric S. Téllez\nThis demonstration shows in a 2D example the functionality of SearchGraph.\nusing SimilaritySearch, SimSearchManifoldLearning, Plots, StatsBase, LinearAlgebra, Markdown, Random, Printf\nn = 100_000\n\nM = randn(Float16, 2, n)\ndb = MatrixDatabase(M)\ndist = SqL2_asf32()\nsize(M)\nNow we can create the index\n1G = SearchGraph(; dist, db)\nctx = SearchGraphContext(hyperparameters_callback=OptimizeParameters(MinRecall(0.99)))\n2index!(G, ctx)\n3optimize_index!(G, ctx, MinRecall(0.9))\n\n\n1\n\nDefines the index and the search context (caches and hyperparameters); particularly, we use a very high quality build MinRecall(0.99); high quality constructions yield to faster queries due to the underlying graph structure.\n\n2\n\nActual indexing procedure using the given search context.\n\n3\n\nOptimizing the index to trade quality and speed."
  },
  {
    "objectID": "demos/syn2d.html#the-set-of-queries",
    "href": "demos/syn2d.html#the-set-of-queries",
    "title": "Visualizing MNIST database",
    "section": "The set of queries",
    "text": "The set of queries\nWe define a small set of queries being close to the border of the dataset and also in the most dense regions of the dataset.\n\nQ = [Float32[-2, -2], Float32[2, -2], Float32[-2, 0], Float32[-0, 2], Float32[0, 0],   Float32[-3, 3],  Float32[4, 4], Float32[1, 0.5]]\nknns = searchbatch(G, ctx, VectorDatabase(Q), 30)\n\nPlease note how queries in low and high dense regions are located.\n\nscatter(view(M, 1, :), view(M, 2, :), fmt=:png, c=:cyan, ma=0.3, a=0.3, ms=1, msw=0)\n\nscatter!(getindex.(Q, 1), getindex.(Q, 2), c=:red, ma=0.7, a=0.7, ms=6, msw=0)\n\nfor c in eachcol(knns)\n    X = M[:, sort!(collect(IdView(c)))]\n    scatter!(view(X, 1, :), view(X, 2, :), c=:blue, ma=0.5, a=0.5, ms=2, msw=0)\n    #scatter!( c=:auto, ms=2)\nend\n\ndisplay(plot!(legend=nothing))\n\n\n\n\nSince points are distributed in several regions with disparate density, their radii are also quite diverse. The next list illustrates the distribution of distances for the set of queries\n\n\n\nquery ID\nx\ny\nradius\n\n\n\n\n1\n-2.0\n-2.0\n0.2132\n\n\n2\n2.0\n-2.0\n0.1704\n\n\n3\n-2.0\n0.0\n0.0740\n\n\n4\n0.0\n2.0\n0.0732\n\n\n5\n0.0\n0.0\n0.0282\n\n\n6\n-3.0\n3.0\n1.1797\n\n\n7\n4.0\n4.0\n2.5466\n\n\n8\n1.0\n0.5\n0.0363\n\n\n\nNote how the central radius are quite dense. ## Environment and dependencies\n\n\nJulia Version 1.10.10\nCommit 95f30e51f41 (2025-06-27 09:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 × Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_PROJECT = .\n  JULIA_NUM_THREADS = auto\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/Research/SimilaritySearchDemos/Project.toml`\n  [aaaa29a8] Clustering v0.15.8\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.8.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.1\n  [682c06a0] JSON v0.21.4\n  [23fbe1c1] Latexify v0.16.10\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\n⌃ [ca7969ec] PlotlyLight v0.11.0\n⌃ [91a5bcdd] Plots v1.40.20\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.2\n  [053f045d] SimilaritySearch v0.13.0\n⌅ [2913bbd2] StatsBase v0.33.21\n⌃ [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.6\nInfo Packages marked with ⌃ and ⌅ have new versions available. Those with ⌃ may be upgradable, but those with ⌅ are restricted by compatibility constraints from upgrading. To see why use `status --outdated`"
  }
]