[
  {
    "objectID": "tutorials/index.html",
    "href": "tutorials/index.html",
    "title": "Tutorials",
    "section": "",
    "text": "Basic usage - Euclidean distance, Random 2D points.\nIncremental construction - Manhattan distance, Random 8D points.\nAutomatic hyperparameter optimization - Squared Euclidean distance Random 16D points.\nSolving single queries - Euclidean distance, Random points.\nParallel construction and search - Euclidean distance, Random 2D points."
  },
  {
    "objectID": "tutorials/parallel-construction-and-search.html",
    "href": "tutorials/parallel-construction-and-search.html",
    "title": "Parallel construction and parallel search",
    "section": "",
    "text": "by: Eric S. TÃ©llez\nusing SimilaritySearch\nSimilarity search on very large datasets and high-dimensional datasets require high computational resources. In this example we show how to arallelize both the construction and search to be able to handle this kind of databases.\ndim = 16\n1db = MatrixDatabase(randn(Float32, dim, 10^5))\n2queries = MatrixDatabase(randn(Float32, dim, 30))\n3dist = SqL2Distance()\n4ctx = SearchGraphContext(parallel_first_block=256, parallel_block=512)\n5G = SearchGraph(; dist, db)\n6index!(G, ctx)\n\n\n1\n\nA synthetic database of dimension 16 and \\(10^5\\) vectors.\n\n2\n\nA synthetic query set of \\(30\\) points.\n\n3\n\nThe distance function.\n\n4\n\nThe search context working with SearchGraph; a set of hyperparameters for the index.\n\n5\n\nThe index definition.\n\n6\n\nThe index construction.\nThe SearchGraph construction algorithm is incremental:\nThe parallel construction is made with index! or append_items!; for this matter these functions accept a parallel_block argument via the ctx context, that controls how many elements are inserted at once, i.e., looking for its nearest neighbors in parallel and connected also in parallel.\nAs in the sequential version, a minimum number of elements must exists to work, and therefore, the parallel_first_block argument can also be specified. By default, it is equal to parallel_block. The parallel_block argument should be set to at least the number of available threads, and perhaps multiplying it by a small constant is also a good approach.\nNote that you must not call push_item!, append_items!, or index! from several threads. The default algorithm will takes advantage of the available threads using a single call."
  },
  {
    "objectID": "tutorials/parallel-construction-and-search.html#searching",
    "href": "tutorials/parallel-construction-and-search.html#searching",
    "title": "Parallel construction and parallel search",
    "section": "Searching",
    "text": "Searching\nOnce the index is constructed, you can solve batches in parallel and also single queries. In contrast with append, these functions can be called in multithreading algorithms. However, you must pause the searching requests while perform insertions (parallel or sequential); mixing insertions and search produces an undefined behavior for search results.\n\nI, D = searchbatch(G, ctx, queries, 10)\n\nThreads.@threads for i in eachindex(queries)\n    p = search(G, ctx, queries[i], KnnResult(10))\n    res = p.res\n    \n    print(\"=== $i -- nearest neighbor:\")\n    println(res[1])\n    print(\"=== $i -- result set:\")\n    println(collect(res))\n    print(\"=== $i -- identifiers:\")\n    println(collect(IdView(res))) # do something with `res`\n    print(\"=== $i -- distances:\")\n    println(collect(DistView(res))) # do something with `res`\nend\n\n=== 7 -- nearest neighbor:=== 19 -- nearest neighbor:=== 15 -- nearest neighbor:=== 11 -- nearest neighbor:=== 10 -- nearest neighbor:=== 27 -- nearest neighbor:=== 25 -- nearest neighbor:=== 29 -- nearest neighbor:=== 26 -- nearest neighbor:=== 5 -- nearest neighbor:=== 18 -- nearest neighbor:=== 14 -- nearest neighbor:=== 22 -- nearest neighbor:=== 12 -- nearest neighbor:=== 4 -- nearest neighbor:=== 30 -- nearest neighbor:=== 6 -- nearest neighbor:=== 13 -- nearest neighbor:=== 3 -- nearest neighbor:=== 1 -- nearest neighbor:=== 2 -- nearest neighbor:=== 16 -- nearest neighbor:=== 20 -- nearest neighbor:=== 23 -- nearest neighbor:=== 9 -- nearest neighbor:=== 21 -- nearest neighbor:=== 17 -- nearest neighbor:IdWeight(=== 24 -- nearest neighbor:=== 28 -- nearest neighbor:=== 8 -- nearest neighbor:0x00009da0, 6.675923f0)\n=== 15 -- result set:IdWeight(0x0000ef27, 4.726558f0)\n=== 24 -- result set:IdWeight(0x0000cd58, 4.528069f0)\n=== 27 -- result set:IdWeight(0x00000ff4, 5.687612f0)\n=== 3 -- result set:IdWeight(0x0000f9b6, 6.8288493f0)\nIdWeight=== 9 -- result set:(0x0000c4a0, 3.047554f0)\n=== 6 -- result set:IdWeight(0x000140bc, 4.0632343f0)\n=== 19 -- result set:IdWeight(0x0001277e, 5.9874015f0)\nIdWeight=== 11 -- result set:(0x00007e99, 5.232687f0)\n=== 10 -- result set:IdWeight(0x0001778a, 5.571958f0)\n=== 23 -- result set:IdWeight(0x0000083b, 2.6822302f0)\n=== 29 -- result set:IdWeight(0x00009d78, 3.5820096f0)\n=== 8 -- result set:IdWeight(0x000150f8, 3.9342616f0)\n=== 13 -- result set:IdWeight(0x0000be28, 6.292833f0)\nIdWeight=== 14 -- result set:(0x0000fe5d, 7.1279845f0)\n=== 30 -- result set:IdWeight(0x00013579, 3.4584124f0)\nIdWeight=== 5 -- result set:(0x000067ba, 2.8870392f0)\nIdWeight=== 18 -- result set:(0x0000b0ba, 2.2960021f0)\nIdWeight=== 22 -- result set:(0x0000a290, 5.2792125f0)\nIdWeight=== 4 -- result set:(0x000118bf, 4.038556f0)\n=== 25 -- result set:IdWeight(0x00012021, 2.6875844f0)\nIdWeight=== 16 -- result set:(0x00004d1a, 3.3135195f0)\nIdWeight=== 1 -- result set:(0x00002ce3, 4.406932f0)\n=== 21 -- result set:IdWeight(0x0000527f, 4.530012f0)\nIdWeight=== 12 -- result set:(0x0000b32d, 3.2068803f0)\n=== 26 -- result set:IdWeight(0x00004736, 6.6390896f0)\n=== 17 -- result set:IdWeight(0x00006e2b, 3.0433564f0)\nIdWeight=== 28 -- result set:(0x0000f274, 3.063364f0)\nIdWeight=== 2 -- result set:(0x00006d0c, 4.363042f0)\n=== 20 -- result set:IdWeight(0x00007b9a, 2.5394197f0)\n=== 7 -- result set:IdWeight[IdWeight(0x00009da0, 6.675923f0), IdWeight(0x000061a6, 7.02988f0), IdWeight(0x00011464, 7.1213803f0), IdWeight(0x0001068c, 7.567528f0), IdWeight(0x00012719, 8.113082f0), IdWeight(0x000079be, 8.482317f0), IdWeight(0x00016ac6, 8.860224f0), IdWeight(0x00000cc5, 8.981895f0), IdWeight(0x000115de, 9.03268f0), IdWeight(0x00010a2e, 9.121991f0)]\n=== 15 -- identifiers:IdWeight[IdWeight(0x0000be28, 6.292833f0), IdWeight(0x0000e60e, 7.7584715f0), IdWeight(0x00000393, 8.022731f0), IdWeight(0x0000788a, 8.082609f0), IdWeight(0x0000702a, 8.101276f0), IdWeight(0x00007fde, 8.145304f0), IdWeight(0x0000264c, 8.16899f0), IdWeight(0x0001653a, 8.294217f0), IdWeight(0x0000c7f5, 8.562826f0), IdWeight(0x00007381, 8.667862f0)]\n=== 14 -- identifiers:IdWeight[IdWeight(0x00002ce3, 4.406932f0), IdWeight(0x0000202e, 4.557166f0), IdWeight(0x0001762e, 4.912068f0), IdWeight(0x00014114, 4.91214f0), IdWeight(0x0000d64f, 4.965306f0), IdWeight(0x0001364f, 4.981351f0), IdWeight(0x00004b95, 4.991246f0), IdWeight(0x00013560, 5.1663833f0), IdWeight(0x00006af8, 5.600113f0), IdWeight(0x00004010, 5.64502f0)]\n=== 21 -- identifiers:IdWeight[IdWeight(0x0000b0ba, 2.2960021f0), IdWeight(0x00002460, 2.8062224f0), IdWeight(0x000042f1, 3.5092864f0), IdWeight(0x0001123c, 3.6508331f0), IdWeight(0x00001b1f, 3.6789362f0), IdWeight(0x0000a461, 3.7138393f0), IdWeight(0x00015f4f, 3.8067896f0), IdWeight(0x000096ce, 3.9141073f0), IdWeight(0x000072bf, 4.0175414f0), IdWeight(0x000181bc, 4.1544557f0)]\n=== 22 -- identifiers:IdWeight[IdWeight(0x00004d1a, 3.3135195f0), IdWeight(0x00016d33, 3.3848624f0), IdWeight(0x0001804d, 4.025727f0), IdWeight(0x00013024, 4.077698f0), IdWeight(0x00002896, 4.366047f0), IdWeight(0x0001727d, 4.375115f0), IdWeight(0x0000f13c, 4.681094f0), IdWeight(0x0000054c, 4.71946f0), IdWeight(0x0000f70a, 4.9946475f0), IdWeight(0x000034b9, 5.0513253f0)]\n=== 1 -- identifiers:IdWeight[IdWeight(0x0001277e, 5.9874015f0), IdWeight(0x00003feb, 6.110808f0), IdWeight(0x0000b894, 6.878881f0), IdWeight(0x000008f9, 7.056838f0), IdWeight(0x00016b3d, 7.3161545f0), IdWeight(0x00001839, 7.4862347f0), IdWeight(0x00005846, 7.9547477f0), IdWeight(0x00002ea3, 8.335855f0), IdWeight(0x00002c44, 8.767622f0), IdWeight(0x00008d45, 8.830698f0)]\n=== 11 -- identifiers:IdWeight[IdWeight(0x00012021, 2.6875844f0), IdWeight(0x00002bee, 4.135638f0), IdWeight(0x00017f60, 4.8320765f0), IdWeight(0x00003067, 5.0121684f0), IdWeight(0x00016933, 5.0521636f0), IdWeight(0x0000f909, 5.074626f0), IdWeight(0x0001222b, 5.080174f0), IdWeight(0x00001893, 5.138646f0), IdWeight(0x00004463, 5.2589445f0), IdWeight(0x00006bce, 5.5174394f0)]\n=== 16 -- identifiers:IdWeight[IdWeight(0x00004736, 6.6390896f0), IdWeight(0x0000a9af, 6.6492963f0), IdWeight(0x00012c60, 7.055795f0), IdWeight(0x0001315a, 7.0637984f0), IdWeight(0x00012a0a, 7.361882f0), IdWeight(0x0000d076, 7.6028204f0), IdWeight(0x000170b5, 7.618756f0), IdWeight(0x0001697b, 7.7091656f0), IdWeight(0x0000b399, 7.9337654f0), IdWeight(0x0000594a, 8.160997f0)]\n=== 17 -- identifiers:IdWeight[IdWeight(0x000067ba, 2.8870392f0), IdWeight(0x00007add, 4.5670953f0), IdWeight(0x00008246, 5.4409337f0), IdWeight(0x00009276, 5.633697f0), IdWeight(0x00014fab, 5.681482f0), IdWeight(0x00014e37, 5.6852694f0), IdWeight(0x0001083c, 5.819864f0), IdWeight(0x0000dfa0, 5.8213906f0), IdWeight(0x0001255f, 5.8465f0), IdWeight(0x0000d796, 5.860892f0)]\n=== 18 -- identifiers:IdWeight[IdWeight(0x00013579, 3.4584124f0), IdWeight(0x0000dbdc, 4.4805098f0), IdWeight(0x00005e87, 4.483524f0), IdWeight(0x00000624, 4.515228f0), IdWeight(0x00016492, 4.5867596f0), IdWeight(0x0000f4ce, 4.593042f0), IdWeight(0x00005d3a, 4.647873f0), IdWeight(0x0000f096, 4.8091617f0), IdWeight(0x00010555, 4.95529f0), IdWeight(0x0000e257, 4.956506f0)]\n=== 5 -- identifiers:IdWeight[IdWeight(0x0000ef27, 4.726558f0), IdWeight(0x0000afc0, 5.0613613f0), IdWeight(0x00000c0a, 5.0821133f0), IdWeight(0x000158a3, 5.130314f0), IdWeight(0x00008272, 5.1979394f0), IdWeight(0x000172a9, 5.204519f0), IdWeight(0x000060bf, 5.3080554f0), IdWeight(0x000021b0, 5.5862293f0), IdWeight(0x000110d8, 5.617485f0), IdWeight(0x000085d1, 5.620654f0)]\n=== 24 -- identifiers:IdWeight[IdWeight(0x0000f274, 3.063364f0), IdWeight(0x0001405f, 3.3474534f0), IdWeight(0x000004ce, 3.7191494f0), IdWeight(0x000112b2, 4.0377135f0), IdWeight(0x0000832b, 4.174683f0), IdWeight(0x000043f0, 4.3115225f0), IdWeight(0x00013d5a, 4.5141444f0), IdWeight(0x000185d1, 4.5508885f0), IdWeight(0x00008b03, 4.661785f0), IdWeight(0x0001672d, 4.676373f0)]\n=== 2 -- identifiers:IdWeight[IdWeight(0x0000f9b6, 6.8288493f0), IdWeight(0x00015bfc, 6.891539f0), IdWeight(0x000080fd, 7.030101f0), IdWeight(0x0001534c, 7.301273f0), IdWeight(0x000066a1, 7.85197f0), IdWeight(0x0000a779, 8.320555f0), IdWeight(0x00000307, 8.374487f0), IdWeight(0x0000fee4, 8.527804f0), IdWeight(0x00013c46, 8.647624f0), IdWeight(0x00002cc2, 8.679995f0)]\n=== 9 -- identifiers:IdWeight[IdWeight(0x0001778a, 5.571958f0), IdWeight(0x00017934, 6.118064f0), IdWeight(0x000056c5, 6.317239f0), IdWeight(0x0000d4a1, 6.4048085f0), IdWeight(0x0000cc8e, 6.5301356f0), IdWeight(0x00004d68, 6.7262073f0), IdWeight(0x00013e8d, 6.735403f0), IdWeight(0x0000afab, 7.560175f0), IdWeight(0x00006c7f, 7.578321f0), IdWeight(0x0000b04a, 8.011299f0)]\n=== 23 -- identifiers:IdWeight[IdWeight(0x00007b9a, 2.5394197f0), IdWeight(0x0000a209, 2.905683f0), IdWeight(0x000121e2, 2.9237483f0), IdWeight(0x00008fe3, 3.4052174f0), IdWeight(0x0000cddd, 3.5397158f0), IdWeight(0x00014e81, 4.1171403f0), IdWeight(0x0001805e, 4.145492f0), IdWeight(0x0000f98a, 4.1695886f0), IdWeight(0x000057ca, 4.2271905f0), IdWeight(0x00003862, 4.251796f0)]\n=== 7 -- identifiers:IdWeight[IdWeight(0x00009d78, 3.5820096f0), IdWeight(0x0000257d, 4.370799f0), IdWeight(0x00010017, 4.6067004f0), IdWeight(0x0000dca0, 4.69836f0), IdWeight(0x000118ad, 4.802515f0), IdWeight(0x0000d212, 4.8357935f0), IdWeight(0x0001779a, 5.011992f0), IdWeight(0x000025a3, 5.0458636f0), IdWeight(0x0001713f, 5.076128f0), IdWeight(0x00014ce3, 5.5756445f0)]\n=== 8 -- identifiers:IdWeight[IdWeight(0x00006e2b, 3.0433564f0), IdWeight(0x00009bb3, 3.3318112f0), IdWeight(0x0000cd92, 3.7610397f0), IdWeight(0x00000165, 3.90755f0), IdWeight(0x000130a6, 4.0177884f0), IdWeight(0x00017a04, 4.163202f0), IdWeight(0x000057b7, 4.3299117f0), IdWeight(0x00001e74, 4.3771844f0), IdWeight(0x00008b59, 4.3801303f0), IdWeight(0x0000a688, 4.3804317f0)]\n=== 28 -- identifiers:IdWeight[IdWeight(0x0000527f, 4.530012f0), IdWeight(0x000000bc, 5.515502f0), IdWeight(0x00006ca3, 5.545234f0), IdWeight(0x0000ca92, 5.5717845f0), IdWeight(0x00006b09, 5.626886f0), IdWeight(0x0000eb0d, 5.6659746f0), IdWeight(0x00003612, 5.763579f0), IdWeight(0x000128f2, 5.8228397f0), IdWeight(0x0000dfd2, 5.8642907f0), IdWeight(0x00007765, 5.9204035f0)]\n=== 12 -- identifiers:IdWeight[IdWeight(0x00007e99, 5.232687f0), IdWeight(0x00009213, 5.4548883f0), IdWeight(0x00003847, 5.5799065f0), IdWeight(0x000098b6, 5.674197f0), IdWeight(0x000049be, 5.8413153f0), IdWeight(0x0001069e, 5.9631867f0), IdWeight(0x0000c190, 5.973559f0), IdWeight(0x00016230, 6.1401963f0), IdWeight(0x0000f28a, 6.173872f0), IdWeight(0x0000418b, 6.268172f0)]\n=== 10 -- identifiers:IdWeight[IdWeight(0x0000fe5d, 7.1279845f0), IdWeight(0x0000eb72, 7.6273737f0), IdWeight(0x0000c7b9, 8.354789f0), IdWeight(0x00016f5b, 8.671972f0), IdWeight(0x000152ea, 9.068197f0), IdWeight(0x000026e5, 9.246054f0), IdWeight(0x00005e52, 9.471013f0), IdWeight(0x000054f8, 10.126999f0), IdWeight(0x000105d6, 10.231085f0), IdWeight(0x000098de, 10.311321f0)]\n=== 30 -- identifiers:IdWeight[IdWeight(0x0000c4a0, 3.047554f0), IdWeight(0x000165ac, 3.065462f0), IdWeight(0x00003efe, 3.508696f0), IdWeight(0x0001758a, 3.91457f0), IdWeight(0x00005003, 4.1052475f0), IdWeight(0x00011d3b, 4.380745f0), IdWeight(0x0000daad, 4.5479016f0), IdWeight(0x00017966, 4.8038964f0), IdWeight(0x0000caa7, 4.816485f0), IdWeight(0x0000680b, 4.827343f0)]\n=== 6 -- identifiers:IdWeight[IdWeight(0x000118bf, 4.038556f0), IdWeight(0x0000baea, 6.57015f0), IdWeight(0x000008e0, 7.129302f0), IdWeight(0x000178e4, 7.193729f0), IdWeight(0x00011fa6, 7.254283f0), IdWeight(0x00007fcf, 7.290628f0), IdWeight(0x0000b426, 7.707114f0), IdWeight(0x000014a6, 7.8612556f0), IdWeight(0x00000414, 7.9704895f0), IdWeight(0x00009b67, 7.97945f0)]\n=== 25 -- identifiers:IdWeight[IdWeight(0x0000083b, 2.6822302f0), IdWeight(0x000062f5, 3.4622371f0), IdWeight(0x0000339d, 3.473967f0), IdWeight(0x000147ab, 3.6882677f0), IdWeight(0x000009da, 3.7322772f0), IdWeight(0x00012156, 3.752961f0), IdWeight(0x00013551, 3.7754538f0), IdWeight(0x000126eb, 3.80498f0), IdWeight(0x00006613, 3.8093596f0), IdWeight(0x000111c4, 3.8456643f0)]\n=== 29 -- identifiers:IdWeight[IdWeight(0x0000a290, 5.2792125f0), IdWeight(0x000082e2, 6.2465644f0), IdWeight(0x00012a73, 6.36628f0), IdWeight(0x000104cd, 6.4137673f0), IdWeight(0x00008685, 6.467493f0), IdWeight(0x0000beff, 6.672741f0), IdWeight(0x00014529, 6.7045493f0), IdWeight(0x0000b3f2, 7.1916842f0), IdWeight(0x00001157, 7.236992f0), IdWeight(0x00011323, 7.3473973f0)]\n=== 4 -- identifiers:IdWeight[IdWeight(0x0000b32d, 3.2068803f0), IdWeight(0x00006779, 4.1885586f0), IdWeight(0x00007a3a, 4.882552f0), IdWeight(0x00014814, 4.9450045f0), IdWeight(0x0000e40b, 5.3147616f0), IdWeight(0x0000c85e, 5.6501484f0), IdWeight(0x0000a4a5, 5.699605f0), IdWeight(0x000021ce, 5.800843f0), IdWeight(0x00007606, 5.985986f0), IdWeight(0x000085d2, 6.112025f0)]\n=== 26 -- identifiers:IdWeight[IdWeight(0x00000ff4, 5.687612f0), IdWeight(0x000086cd, 5.834033f0), IdWeight(0x0001189a, 5.8992977f0), IdWeight(0x0000d54c, 6.2110023f0), IdWeight(0x00006a7e, 6.269251f0), IdWeight(0x00004236, 6.3195744f0), IdWeight(0x00013269, 6.4085903f0), IdWeight(0x00014113, 6.5205083f0), IdWeight(0x00001f82, 6.882298f0), IdWeight(0x00009281, 6.8878827f0)]\n=== 3 -- identifiers:IdWeight[IdWeight(0x000140bc, 4.0632343f0), IdWeight(0x000030a4, 4.0751514f0), IdWeight(0x00010539, 4.5265074f0), IdWeight(0x0001618b, 5.203409f0), IdWeight(0x0001048b, 5.2985888f0), IdWeight(0x0000a539, 5.338418f0), IdWeight(0x0000622d, 5.59543f0), IdWeight(0x00007504, 5.601231f0), IdWeight(0x00016a5c, 6.0236363f0), IdWeight(0x000009ef, 6.0780196f0)]\n=== 19 -- identifiers:IdWeight[IdWeight(0x00006d0c, 4.363042f0), IdWeight(0x000009c3, 5.530006f0), IdWeight(0x000151f7, 6.2204013f0), IdWeight(0x00001269, 6.285384f0), IdWeight(0x00003112, 6.423761f0), IdWeight(0x0000e36e, 6.5526094f0), IdWeight(0x0000f849, 6.797353f0), IdWeight(0x000082c1, 6.897246f0), IdWeight(0x00007eab, 6.8972917f0), IdWeight(0x00017f90, 6.9653015f0)]\n=== 20 -- identifiers:IdWeight[IdWeight(0x0000cd58, 4.528069f0), IdWeight(0x0000bc5f, 4.689286f0), IdWeight(0x000177f6, 5.6855125f0), IdWeight(0x000090a2, 6.0342574f0), IdWeight(0x00005c29, 6.218595f0), IdWeight(0x0001492d, 6.4577646f0), IdWeight(0x0000ee86, 6.4820256f0), IdWeight(0x0000d766, 6.558745f0), IdWeight(0x000000fd, 6.6225147f0), IdWeight(0x00000996, 6.811672f0)]\n=== 27 -- identifiers:UInt32[0x00007b9a, 0x0000a209, 0x000121e2, 0x00008fe3, 0x0000cddd, 0x00014e81, 0x0001805e, 0x0000f98a, 0x000057ca, 0x00003862]\n=== 7 -- distances:UInt32[0x0001277e, 0x00003feb, 0x0000b894, 0x000008f9, 0x00016b3d, 0x00001839, 0x00005846, 0x00002ea3, 0x00002c44, 0x00008d45]\n=== 11 -- distances:UInt32[0x0000083b, 0x000062f5, 0x0000339d, 0x000147ab, 0x000009da, 0x00012156, 0x00013551, 0x000126eb, 0x00006613, 0x000111c4]\n=== 29 -- distances:UInt32[0x0000ef27, 0x0000afc0, 0x00000c0a, 0x000158a3, 0x00008272, 0x000172a9, 0x000060bf, 0x000021b0, 0x000110d8, 0x000085d1]\n=== 24 -- distances:UInt32[0x00012021, 0x00002bee, 0x00017f60, 0x00003067, 0x00016933, 0x0000f909, 0x0001222b, 0x00001893, 0x00004463, 0x00006bce]\n=== 16 -- distances:UInt32[0x00007e99, 0x00009213, 0x00003847, 0x000098b6, 0x000049be, 0x0001069e, 0x0000c190, 0x00016230, 0x0000f28a, 0x0000418b]\n=== 10 -- distances:UInt32[0x00006d0c, 0x000009c3, 0x000151f7, 0x00001269, 0x00003112, 0x0000e36e, 0x0000f849, 0x000082c1, 0x00007eab, 0x00017f90]\n=== 20 -- distances:UInt32[0x0000fe5d, 0x0000eb72, 0x0000c7b9, 0x00016f5b, 0x000152ea, 0x000026e5, 0x00005e52, 0x000054f8, 0x000105d6, 0x000098de]\n=== 30 -- distances:UInt32[0x0000b0ba, 0x00002460, 0x000042f1, 0x0001123c, 0x00001b1f, 0x0000a461, 0x00015f4f, 0x000096ce, 0x000072bf, 0x000181bc]\n=== 22 -- distances:UInt32[0x0000cd58, 0x0000bc5f, 0x000177f6, 0x000090a2, 0x00005c29, 0x0001492d, 0x0000ee86, 0x0000d766, 0x000000fd, 0x00000996]\n=== 27 -- distances:UInt32[0x000067ba, 0x00007add, 0x00008246, 0x00009276, 0x00014fab, 0x00014e37, 0x0001083c, 0x0000dfa0, 0x0001255f, 0x0000d796]\n=== 18 -- distances:UInt32[0x00004736, 0x0000a9af, 0x00012c60, 0x0001315a, 0x00012a0a, 0x0000d076, 0x000170b5, 0x0001697b, 0x0000b399, 0x0000594a]\n=== 17 -- distances:UInt32[0x0000c4a0, 0x000165ac, 0x00003efe, 0x0001758a, 0x00005003, 0x00011d3b, 0x0000daad, 0x00017966, 0x0000caa7, 0x0000680b]\n=== 6 -- distances:IdWeight[IdWeight(0x000150f8, 3.9342616f0), IdWeight(0x000084d2, 4.1718383f0), IdWeight(0x0000b885, 5.519068f0), IdWeight(0x00016c45, 6.1695642f0), IdWeight(0x00016dfc, 6.542225f0), IdWeight(0x00008d2d, 6.8909006f0), IdWeight(0x0000fc9c, 6.907578f0), IdWeight(0x00008c8f, 7.01647f0), IdWeight(0x0001223f, 7.148072f0), IdWeight(0x00012cbc, 7.1572924f0)]\n=== 13 -- identifiers:UInt32[0x000118bf, 0x0000baea, 0x000008e0, 0x000178e4, 0x00011fa6, 0x00007fcf, 0x0000b426, 0x000014a6, 0x00000414, 0x00009b67]\n=== 25 -- distances:UInt32[0x0000be28, 0x0000e60e, 0x00000393, 0x0000788a, 0x0000702a, 0x00007fde, 0x0000264c, 0x0001653a, 0x0000c7f5, 0x00007381]\n=== 14 -- distances:UInt32[0x00004d1a, 0x00016d33, 0x0001804d, 0x00013024, 0x00002896, 0x0001727d, 0x0000f13c, 0x0000054c, 0x0000f70a, 0x000034b9]\n=== 1 -- distances:UInt32[0x00000ff4, 0x000086cd, 0x0001189a, 0x0000d54c, 0x00006a7e, 0x00004236, 0x00013269, 0x00014113, 0x00001f82, 0x00009281]\n=== 3 -- distances:UInt32[0x00006e2b, 0x00009bb3, 0x0000cd92, 0x00000165, 0x000130a6, 0x00017a04, 0x000057b7, 0x00001e74, 0x00008b59, 0x0000a688]\n=== 28 -- distances:UInt32[0x00009d78, 0x0000257d, 0x00010017, 0x0000dca0, 0x000118ad, 0x0000d212, 0x0001779a, 0x000025a3, 0x0001713f, 0x00014ce3]\n=== 8 -- distances:UInt32[0x000140bc, 0x000030a4, 0x00010539, 0x0001618b, 0x0001048b, 0x0000a539, 0x0000622d, 0x00007504, 0x00016a5c, 0x000009ef]\n=== 19 -- distances:UInt32[0x0000f274, 0x0001405f, 0x000004ce, 0x000112b2, 0x0000832b, 0x000043f0, 0x00013d5a, 0x000185d1, 0x00008b03, 0x0001672d]\n=== 2 -- distances:UInt32[0x0000f9b6, 0x00015bfc, 0x000080fd, 0x0001534c, 0x000066a1, 0x0000a779, 0x00000307, 0x0000fee4, 0x00013c46, 0x00002cc2]\n=== 9 -- distances:UInt32[0x000150f8, 0x000084d2, 0x0000b885, 0x00016c45, 0x00016dfc, 0x00008d2d, 0x0000fc9c, 0x00008c8f, 0x0001223f, 0x00012cbc]\n=== 13 -- distances:UInt32[0x0001778a, 0x00017934, 0x000056c5, 0x0000d4a1, 0x0000cc8e, 0x00004d68, 0x00013e8d, 0x0000afab, 0x00006c7f, 0x0000b04a]\n=== 23 -- distances:UInt32[0x0000b32d, 0x00006779, 0x00007a3a, 0x00014814, 0x0000e40b, 0x0000c85e, 0x0000a4a5, 0x000021ce, 0x00007606, 0x000085d2]\n=== 26 -- distances:UInt32[0x0000a290, 0x000082e2, 0x00012a73, 0x000104cd, 0x00008685, 0x0000beff, 0x00014529, 0x0000b3f2, 0x00001157, 0x00011323]\n=== 4 -- distances:UInt32[0x00002ce3, 0x0000202e, 0x0001762e, 0x00014114, 0x0000d64f, 0x0001364f, 0x00004b95, 0x00013560, 0x00006af8, 0x00004010]\n=== 21 -- distances:UInt32[0x00009da0, 0x000061a6, 0x00011464, 0x0001068c, 0x00012719, 0x000079be, 0x00016ac6, 0x00000cc5, 0x000115de, 0x00010a2e]\n=== 15 -- distances:UInt32[0x0000527f, 0x000000bc, 0x00006ca3, 0x0000ca92, 0x00006b09, 0x0000eb0d, 0x00003612, 0x000128f2, 0x0000dfd2, 0x00007765]\n=== 12 -- distances:UInt32[0x00013579, 0x0000dbdc, 0x00005e87, 0x00000624, 0x00016492, 0x0000f4ce, 0x00005d3a, 0x0000f096, 0x00010555, 0x0000e257]\n=== 5 -- distances:Float32[2.5394197, 2.905683, 2.9237483, 3.4052174, 3.5397158, 4.1171403, 4.145492, 4.1695886, 4.2271905, 4.251796]\nFloat32[5.2792125, 6.2465644, 6.36628, 6.4137673, 6.467493, 6.672741, 6.7045493, 7.1916842, 7.236992, 7.3473973]\nFloat32[3.5820096, 4.370799, 4.6067004, 4.69836, 4.802515, 4.8357935, 5.011992, 5.0458636, 5.076128, 5.5756445]\nFloat32[3.0433564, 3.3318112, 3.7610397, 3.90755, 4.0177884, 4.163202, 4.3299117, 4.3771844, 4.3801303, 4.3804317]\nFloat32[2.2960021, 2.8062224, 3.5092864, 3.6508331, 3.6789362, 3.7138393, 3.8067896, 3.9141073, 4.0175414, 4.1544557]\nFloat32[4.726558, 5.0613613, 5.0821133, 5.130314, 5.1979394, 5.204519, 5.3080554, 5.5862293, 5.617485, 5.620654]\nFloat32[4.530012, 5.515502, 5.545234, 5.5717845, 5.626886, 5.6659746, 5.763579, 5.8228397, 5.8642907, 5.9204035]\nFloat32[6.675923, 7.02988, 7.1213803, 7.567528, 8.113082, 8.482317, 8.860224, 8.981895, 9.03268, 9.121991]\nFloat32[4.528069, 4.689286, 5.6855125, 6.0342574, 6.218595, 6.4577646, 6.4820256, 6.558745, 6.6225147, 6.811672]\nFloat32[7.1279845, 7.6273737, 8.354789, 8.671972, 9.068197, 9.246054, 9.471013, 10.126999, 10.231085, 10.311321]\nFloat32[4.0632343, 4.0751514, 4.5265074, 5.203409, 5.2985888, 5.338418, 5.59543, 5.601231, 6.0236363, 6.0780196]\nFloat32[6.292833, 7.7584715, 8.022731, 8.082609, 8.101276, 8.145304, 8.16899, 8.294217, 8.562826, 8.667862]\nFloat32[6.8288493, 6.891539, 7.030101, 7.301273, 7.85197, 8.320555, 8.374487, 8.527804, 8.647624, 8.679995]\nFloat32[3.3135195, 3.3848624, 4.025727, 4.077698, 4.366047, 4.375115, 4.681094, 4.71946, 4.9946475, 5.0513253]\nFloat32[5.232687, 5.4548883, 5.5799065, 5.674197, 5.8413153, 5.9631867, 5.973559, 6.1401963, 6.173872, 6.268172]\nFloat32[3.2068803, 4.1885586, 4.882552, 4.9450045, 5.3147616, 5.6501484, 5.699605, 5.800843, 5.985986, 6.112025]\nFloat32[4.038556, 6.57015, 7.129302, 7.193729, 7.254283, 7.290628, 7.707114, 7.8612556, 7.9704895, 7.97945]\nFloat32[5.571958, 6.118064, 6.317239, 6.4048085, 6.5301356, 6.7262073, 6.735403, 7.560175, 7.578321, 8.011299]\nFloat32[3.9342616, 4.1718383, 5.519068, 6.1695642, 6.542225, 6.8909006, 6.907578, 7.01647, 7.148072, 7.1572924]\nFloat32[5.9874015, 6.110808, 6.878881, 7.056838, 7.3161545, 7.4862347, 7.9547477, 8.335855, 8.767622, 8.830698]\nFloat32[3.4584124, 4.4805098, 4.483524, 4.515228, 4.5867596, 4.593042, 4.647873, 4.8091617, 4.95529, 4.956506]\nFloat32[3.063364, 3.3474534, 3.7191494, 4.0377135, 4.174683, 4.3115225, 4.5141444, 4.5508885, 4.661785, 4.676373]\nFloat32[2.8870392, 4.5670953, 5.4409337, 5.633697, 5.681482, 5.6852694, 5.819864, 5.8213906, 5.8465, 5.860892]\nFloat32[4.363042, 5.530006, 6.2204013, 6.285384, 6.423761, 6.5526094, 6.797353, 6.897246, 6.8972917, 6.9653015]\nFloat32[3.047554, 3.065462, 3.508696, 3.91457, 4.1052475, 4.380745, 4.5479016, 4.8038964, 4.816485, 4.827343]\nFloat32[4.406932, 4.557166, 4.912068, 4.91214, 4.965306, 4.981351, 4.991246, 5.1663833, 5.600113, 5.64502]\nFloat32[5.687612, 5.834033, 5.8992977, 6.2110023, 6.269251, 6.3195744, 6.4085903, 6.5205083, 6.882298, 6.8878827]\nFloat32[2.6875844, 4.135638, 4.8320765, 5.0121684, 5.0521636, 5.074626, 5.080174, 5.138646, 5.2589445, 5.5174394]\nFloat32[6.6390896, 6.6492963, 7.055795, 7.0637984, 7.361882, 7.6028204, 7.618756, 7.7091656, 7.9337654, 8.160997]\nFloat32[2.6822302, 3.4622371, 3.473967, 3.6882677, 3.7322772, 3.752961, 3.7754538, 3.80498, 3.8093596, 3.8456643]"
  },
  {
    "objectID": "tutorials/parallel-construction-and-search.html#environment-and-dependencies",
    "href": "tutorials/parallel-construction-and-search.html#environment-and-dependencies",
    "title": "Parallel construction and parallel search",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.9\nCommit 5595d20a287 (2025-03-10 12:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 Ã Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_PROJECT = .\n  JULIA_NUM_THREADS = auto\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/sites/SimilaritySearchDemos/Project.toml`\n  [aaaa29a8] Clustering v0.15.8\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.7.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.0 `~/.julia/dev/InvertedFiles`\n  [682c06a0] JSON v0.21.4\n  [23fbe1c1] Latexify v0.16.6\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\nâ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.11\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.0 `~/.julia/dev/SimSearchManifoldLearning`\n  [053f045d] SimilaritySearch v0.12.0 `~/.julia/dev/SimilaritySearch`\nâ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.0 `~/.julia/dev/TextSearch`\nInfo Packages marked with â and â have new versions available. Those with â may be upgradable, but those with â are restricted by compatibility constraints from upgrading. To see why use `status --outdated`"
  },
  {
    "objectID": "tutorials/basic-usage.html",
    "href": "tutorials/basic-usage.html",
    "title": "Using the SimilaritySearch package",
    "section": "",
    "text": "by: Eric S. TÃ©llez\nusing SimilaritySearch, Markdown\nThis is a small tutorial showing a minimum example for working with SimilaritySearch it accepts several options that are let to defaults. While this should be enough for many purposes, you are invited to see the rest of the tutorials to take advantage of other features.\nMatrixDatabase is a required wrapper that tells SimilaritySearch how to access underlying objects since it can support different kinds of objects. In this setup, each column is an object and will be accessed through views using the MatrixDatabase. Since the backend doesnât support appends or pushes, the index can be seen as an static index.\nfunction synthetic_benchmark(n, m, dim)\n    db = MatrixDatabase(randn(Float32, dim, n))\n    queries = MatrixDatabase(randn(Float32, dim, m))\n    dist = SqL2Distance()\n    (; db, queries, dist)\nend\nit can use any distance function described in SimilaritySearch and Distances.jl, and in fact any SemiMetric as described in the later package. The index construction is made as follows\nB = synthetic_benchmark(3000, 50, 2)\nG = SearchGraph(; B.dist, B.db)\nctx = SearchGraphContext()\nindex!(G, ctx)\nthis will display a lot of information in the console, since as construction advances the hyperparameters of the index are adjusted. The default optimization try to get a recall of 0.9 which is a typical tradeoff between quality and speed. Once the index is created, the index can solve nearest neighbor queries\nk = 16\n1I, D = searchbatch(G, ctx, B.queries, k)\n\n\n1\n\nThe searchbatch functions takes a set of queries and solve them using the given index. I is a matrix of identifiers in db and D their corresponding distances."
  },
  {
    "objectID": "tutorials/basic-usage.html#visualizing-what-we-just-did",
    "href": "tutorials/basic-usage.html#visualizing-what-we-just-did",
    "title": "Using the SimilaritySearch package",
    "section": "Visualizing what we just did",
    "text": "Visualizing what we just did\n\nusing Plots\n\nscatter(B.db.matrix[1, :], B.db.matrix[2, :], size=(600, 600), color=:cyan, ma=0.3, a=0.3, ms=1, msw=0, label=\"\")\nfor c in eachcol(I)\n    R = B.db.matrix[:, c]\n    @views scatter!(R[1, :], R[2, :], m=:diamond, ma=0.3, a=0.3, color=:auto, ms=2, msw=0, label=\"\")\nend\n\n@views scatter!(B.queries.matrix[1, :], B.queries.matrix[2, :], color=:black, m=:star, ma=0.5, a=0.5, ms=4, msw=0, label=\"\")\n\nplot!()\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCyan points identify the dataset while starts are query points. The nearest neighbor points are colored automatically and can repeat, but they come quite close to query points, in dense areas they are even hidding them."
  },
  {
    "objectID": "tutorials/basic-usage.html#environment-and-dependencies",
    "href": "tutorials/basic-usage.html#environment-and-dependencies",
    "title": "Using the SimilaritySearch package",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.9\nCommit 5595d20a287 (2025-03-10 12:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 Ã Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_PROJECT = .\n  JULIA_NUM_THREADS = auto\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/sites/SimilaritySearchDemos/Project.toml`\n  [aaaa29a8] Clustering v0.15.8\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.7.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.0 `~/.julia/dev/InvertedFiles`\n  [682c06a0] JSON v0.21.4\n  [23fbe1c1] Latexify v0.16.6\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\nâ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.11\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.0 `~/.julia/dev/SimSearchManifoldLearning`\n  [053f045d] SimilaritySearch v0.12.0 `~/.julia/dev/SimilaritySearch`\nâ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.0 `~/.julia/dev/TextSearch`\nInfo Packages marked with â and â have new versions available. Those with â may be upgradable, but those with â are restricted by compatibility constraints from upgrading. To see why use `status --outdated`"
  },
  {
    "objectID": "tutorials/allknn.html",
    "href": "tutorials/allknn.html",
    "title": "Computing all \\(k\\) nearest neighbors",
    "section": "",
    "text": "by: Eric S. TÃ©llez"
  },
  {
    "objectID": "tutorials/allknn.html#introduction",
    "href": "tutorials/allknn.html#introduction",
    "title": "Computing all \\(k\\) nearest neighbors",
    "section": "Introduction",
    "text": "Introduction\nComputing the \\(k\\) nearest neighbors of a dataset (a.k.a. allknn) is a useful task to take knowledge of a given dataset. This is a fundamental problem for some clustering algorithms and non-linear dimensional reduction algorithms.\nGiven a metric database \\((X, dist)\\) and a relatively small \\(k\\) value, the goal is to compute \\(\\{ knn(x) \\mid x \\in X \\}\\) taking into account that each \\(x_i \\in X\\), and therefore, \\(x_i\\) should be removed from the \\(i\\)-th \\(knn\\) result set.\nSolving allknn fast and accuratelly is the goal of this example."
  },
  {
    "objectID": "tutorials/allknn.html#initializing-our-notebook",
    "href": "tutorials/allknn.html#initializing-our-notebook",
    "title": "Computing all \\(k\\) nearest neighbors",
    "section": "Initializing our notebook",
    "text": "Initializing our notebook\nThe first step is to load our basic packages\n\nusing SimilaritySearch, Markdown\n\nwe will use a synthetic dataset\n\nfunction synthetic_benchmark(n, dim)\n1    db = MatrixDatabase(randn(Float32, dim, n))\n2    dist = SqL2Distance()\n3    (; db, dist)\nend\n\n\n1\n\nGenerate \\(n\\) random vectors, of \\(dim\\) dimension. Note that we wrap the matrix as MatrixDatabase to let our index that this is a database; this is necessary since we typically can change the type of objects and distance functions to work.\n\n2\n\nThe squared Euclidean distance; it preserves the order than plain Euclidean distance, but it is faster.\n\n3\n\nReturns a named tuple with the dataset and the distance.\n\n\n\n\n\n1B = synthetic_benchmark(10^5, 16)\n2k = 8\n3etime = @elapsed eknns, edists = allknn(ExhaustiveSearch(; B.db, B.dist),  GenericContext(), k)\n\n\n1\n\nCreates a synthetic dataset of dimension \\(16\\) and \\(10^5\\) points.\n\n2\n\nDefines we will be fetching this number of neighbors.\n\n3\n\nCreates a gold standard for test and compare.\n\n\n\n\n\nG = SearchGraph(; B.dist, B.db)\n2ctx = SearchGraphContext()\n3itime = @elapsed index!(G, ctx)\n4atime = @elapsed knns, dists = allknn(G, ctx, k)\n\n\n2\n\nDefines the SearchGraph index; it does not indexes anything yet!\n\n3\n\nDefines a search context, it contains several hyperparameters that will be applied for the indexing process, default values just work for now.\n\n4\n\nThe actual indexing."
  },
  {
    "objectID": "tutorials/allknn.html#differences-between-allknng-k-and-searchbatchg-x-k",
    "href": "tutorials/allknn.html#differences-between-allknng-k-and-searchbatchg-x-k",
    "title": "Computing all \\(k\\) nearest neighbors",
    "section": "Differences between allknn(G, k) and searchbatch(G, X, k)",
    "text": "Differences between allknn(G, k) and searchbatch(G, X, k)\nWe can solve similarly with searchbatch but self-references should be removed later, and more important, allknn use special pivoting/boosting strategies that yields to faster searches.\n\nstime = @elapsed sknns, sdists = searchbatch(G, ctx, B.db, k)"
  },
  {
    "objectID": "tutorials/allknn.html#comparing-solutions",
    "href": "tutorials/allknn.html#comparing-solutions",
    "title": "Computing all \\(k\\) nearest neighbors",
    "section": "Comparing solutions",
    "text": "Comparing solutions\nWe can measure the quality of SearchGraph in its different modalities against the exhaustive search (exact) solution.\n\nallknn_recall = macrorecall(eknns, knns)\nsearch_recall = macrorecall(eknns, sknns)\n\n\n\nTimes:\n\nindexing: 5.549563584\n\nallknn with SearchGraph: 0.345918259\n\nsearchbatch with SearchGraph: 0.394764559\n\nallknn with Exhaustivesearch: 7.042033922\n\n\nThe search and recall tradeoff:\n\nallknn (SearchGraph): 0.89639125\n\nsearchbatch (SearchGraph): 0.90699625"
  },
  {
    "objectID": "tutorials/allknn.html#final-notes",
    "href": "tutorials/allknn.html#final-notes",
    "title": "Computing all \\(k\\) nearest neighbors",
    "section": "Final notes",
    "text": "Final notes\nExhaustive search will fetch the exact solution but it has a higher cost and this could be more notorious as datasetâs size increases."
  },
  {
    "objectID": "tutorials/allknn.html#environment-and-dependencies",
    "href": "tutorials/allknn.html#environment-and-dependencies",
    "title": "Computing all \\(k\\) nearest neighbors",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.9\nCommit 5595d20a287 (2025-03-10 12:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 Ã Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_PROJECT = .\n  JULIA_NUM_THREADS = auto\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/sites/SimilaritySearchDemos/Project.toml`\n  [aaaa29a8] Clustering v0.15.8\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.7.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.0 `~/.julia/dev/InvertedFiles`\n  [682c06a0] JSON v0.21.4\n  [23fbe1c1] Latexify v0.16.6\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\nâ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.11\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.0 `~/.julia/dev/SimSearchManifoldLearning`\n  [053f045d] SimilaritySearch v0.12.0 `~/.julia/dev/SimilaritySearch`\nâ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.0 `~/.julia/dev/TextSearch`\nInfo Packages marked with â and â have new versions available. Those with â may be upgradable, but those with â are restricted by compatibility constraints from upgrading. To see why use `status --outdated`"
  },
  {
    "objectID": "demos/podcast-collection.html",
    "href": "demos/podcast-collection.html",
    "title": "Searching in podcast collection",
    "section": "",
    "text": "using SimilaritySearch, SimSearchManifoldLearning, TextSearch, CodecZlib, JSON, DataFrames, Plots, StatsBase, DataFrames, Clustering, Markdown, Latexify\nusing Downloads: download\nThis example is about searching in a caption/subtitle collection, i.e., looking for passages in audiobooks, youtube videos, conferences, podcasts, etc. The audio should be translated with a speech to text model, i.e., Whisper of OpenAI.\nHaving a WebVTT set of files we need to load the corpus. The files we are using as dataset are WebVTT subtitles, which can be readed with the following code, note that this code is not part of the example and can be ignored.\nmutable struct EntryVTT\n    type::Symbol\n    name::String\n    tbegin::String\n    tend::String\n    data::Vector{String}\nend\n\nfunction webvtt!(filename, idfile, D)\n    L = []\n    B = nothing\n\n    open(filename) do f\n        lineno = 0\n        while !eof(f)\n            line = readline(f)\n            lineno += 1\n            if line == \"WEBVTT\"\n                B = EntryVTT(:WEBVTT, \"\", \"\", \"\", String[])\n                push!(L, B)\n                continue\n            end\n\n            n = length(line)\n            if n == 0 # flush\n                if B.type === :caption\n                    for caption in B.data\n                        push!(D, (; idfile, B.name, B.tbegin, B.tend, caption))\n                    end\n                end\n                B = nothing\n                continue\n            end\n\n            if B === nothing\n                m = match(r\"^NOTE (.*)\", line)\n                if m !== nothing\n                    B = EntryVTT(:NOTE, \"\", \"\", \"\", String[])\n                    push!(L, B)\n                    if length(m.captures[1]) &gt; 0\n                        push!(B.data, m.captures[1])\n                    end\n\n                    continue\n                end\n\n                if \"REGION\" == line\n                    B = EntryVTT(:REGION, \"\", \"\", \"\", String[])\n                    push!(L, B)\n                    continue\n                end\n\n                if occursin(\"--&gt;\", line)\n                    tbegin, tend = split(line)[[1, 3]]\n                    B = EntryVTT(:caption, \"\", tbegin, tend, String[])\n                    continue\n                end\n\n                B = EntryVTT(:caption, line, \"\", \"\", String[])\n                push!(L, B)\n            else\n                if occursin(\"--&gt;\", line)\n                    B.tbegin, B.tend = split(line)[[1, 3]]\n                    continue\n                end\n                push!(B.data, line) # appends to the last\n            end\n        end\n    end\n\n    B !== nothing && push!(L, B)\n    L, D\nend\nNow, we load the dataset\npodcasts = sort!(readdir(\"/home/sadit/sites/SimilaritySearchDemos/podcast-vtt/\", join=true))\nD = DataFrame(idfile=String[], name=String[], tbegin=String[], tend=String[], caption=String[])\n\nfor filename in podcasts\n    webvtt!(filename, basename(filename), D)\nend\n\nD\n\n21013Ã5 DataFrame20988 rows omitted\n\n\n\nRow\nidfile\nname\ntbegin\ntend\ncaption\n\n\n\nString\nString\nString\nString\nString\n\n\n\n\n1\ntres-patines-y-la-tremenda-corte_0000.vtt\n\n00:00.000\n00:11.000\nAudiencia pÃºblica, el tremendo juez de la tremenda corte va a resolver un tremendo caso.\n\n\n2\ntres-patines-y-la-tremenda-corte_0000.vtt\n\n00:11.000\n00:13.000\nBuenas noches, secretario.\n\n\n3\ntres-patines-y-la-tremenda-corte_0000.vtt\n\n00:15.000\n00:18.000\nBuenas noches, seÃ±or juez. Â¿CÃ³mo se siente hoy?\n\n\n4\ntres-patines-y-la-tremenda-corte_0000.vtt\n\n00:18.000\n00:25.000\nCampana. Hoy me siento panetela. De manera que vamos a ver si acabamos pronto que esta noche me voy de rumba.\n\n\n5\ntres-patines-y-la-tremenda-corte_0000.vtt\n\n00:25.000\n00:27.000\nNo me digas. Â¿Se va usted de rumba?\n\n\n6\ntres-patines-y-la-tremenda-corte_0000.vtt\n\n00:27.000\n00:30.000\nSÃ­, tengo un carrito ahÃ­ que es algo serio.\n\n\n7\ntres-patines-y-la-tremenda-corte_0000.vtt\n\n00:30.000\n00:32.000\nAh, oÃ­game. Â¿JÃ³ven?\n\n\n8\ntres-patines-y-la-tremenda-corte_0000.vtt\n\n00:32.000\n00:36.000\nUn pollito. No tiene mÃ¡s que 46 aÃ±os.\n\n\n9\ntres-patines-y-la-tremenda-corte_0000.vtt\n\n00:36.000\n00:40.000\nÂ¿Y una mujer de 46 aÃ±os le llama a usted pollito todavÃ­a?\n\n\n10\ntres-patines-y-la-tremenda-corte_0000.vtt\n\n00:40.000\n00:42.000\nClaro que sÃ­. Â¿QuÃ© nÃºmero es gallina en la bola?\n\n\n11\ntres-patines-y-la-tremenda-corte_0000.vtt\n\n00:42.000\n00:43.000\n54.\n\n\n12\ntres-patines-y-la-tremenda-corte_0000.vtt\n\n00:43.000\n00:45.000\nEntonces hasta los 53 sigue siendo un pollito.\n\n\n13\ntres-patines-y-la-tremenda-corte_0000.vtt\n\n00:45.000\n00:47.000\nAh, bueno. Â¿Y es bonita?\n\n\nâ®\nâ®\nâ®\nâ®\nâ®\nâ®\n\n\n21002\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n16:26.080\n16:26.880\nÂ¿Por quÃ©?\n\n\n21003\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n16:26.880\n16:28.200\nPorque no tuvieron Ã©xito.\n\n\n21004\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n16:28.200\n16:29.800\nEscriba ahÃ­, secretario.\n\n\n21005\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n16:29.840\n16:31.400\nVenga la sentencia.\n\n\n21006\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n16:31.400\n16:35.040\nEl tribunal dictamina que ustedes han hecho leÃ±a a la finca de\n\n\n21007\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n16:35.040\n16:37.440\nNananina perjudicando a su dueÃ±a.\n\n\n21008\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n16:37.440\n16:40.520\nY por todo ese estropicio que parece obra de locos,\n\n\n21009\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n16:40.520\n16:44.040\npagarÃ¡n 5,000 cocos mÃ¡s las costas de este juicio.\n\n\n21010\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n16:44.040\n16:47.720\nEscucha el siguiente programa de La Tremenda Corte con Leopoldo\n\n\n21011\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n16:47.720\n16:50.920\nFernÃ¡ndez, MimÃ­ Cali y AnÃ­bal de Mar por esta emisora.\n\n\n21012\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n16:50.920\n16:53.720\nHasta entonces, Manolo Iglesias, que les habla,\n\n\n21013\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n16:53.720\n16:56.360\nles dice, muy buena suerte, amigos.\nFunctions create to encode texto into bag-of-word vectors\ntextconfig = TextConfig(\n    group_usr=true,\n    group_url=true,\n    del_diac=true,\n    lc=true,\n    group_num=true,\n    nlist=[1],\n    qlist=[])\n\n# corpus here can be a sample to avoid double parsing\nvoc = Vocabulary(textconfig, D.caption) \nmodel = VectorModel(IdfWeighting(), TfWeighting(), voc)\n# model = VectorModel(EntropyWeighting(), BinaryLocalWeighting(), voc, D.text, D.klass; smooth=1.0)\n#model = VectorModel(IdfWeighting(), TfWeighting(), voc)\nmodel = filter_tokens(model) do t\n    t.weight &gt;= 0.05\nend\n\nvectors = vectorize_corpus(model, D.caption)"
  },
  {
    "objectID": "demos/podcast-collection.html#umap-projections",
    "href": "demos/podcast-collection.html#umap-projections",
    "title": "Searching in podcast collection",
    "section": "UMAP projections",
    "text": "UMAP projections\nUMAP projection can take a while, even on multithreading systems. Note that we are creating 2d and 3d projections.\n\n1e2, e3 = let min_dist=0.5f0,\n             k=16,\n             n_epochs=75,\n             neg_sample_rate=3,\n             tol=1e-3,\n             layout=SpectralLayout(),\n             indexsize=2048,\n             dist=NormalizedCosineDistance()\n\n    index = ExhaustiveSearch(; db=rand(vectors, indexsize), dist)\n    @time U2 = fit(UMAP, index; k, neg_sample_rate, layout, n_epochs, tol, min_dist)\n    @time U3 = fit(U2, 3; neg_sample_rate, n_epochs, tol)\n    @time e2 = clamp.(predict(U2, vectors), -10f0, 10f0)\n    @time e3 = clamp.(predict(U3, vectors), -10f0, 10f0)\n    e2, e3\nend\n\n\n1\n\nThe UMAP algorithm has a lot of hyperparameters; min_dist controls the distance between projected points, k is the number of neighbors to be used in the underlying \\(k\\)nn graph, n_epochs the number of epochs used to optimize the projection, neg_sample_rate means for the number of negative examples used in the optimization process, tol the tolerance to converge, layout"
  },
  {
    "objectID": "demos/podcast-collection.html#visualizations",
    "href": "demos/podcast-collection.html#visualizations",
    "title": "Searching in podcast collection",
    "section": "Visualizations",
    "text": "Visualizations\n\nfunction normcolors(V)\n    min_, max_ = extrema(V)\n    V .= (V .- min_) ./ (max_ - min_)\n    V .= clamp.(V, 0, 1)\nend\n\nnormcolors(@view e3[1, :])\nnormcolors(@view e3[2, :])\nnormcolors(@view e3[3, :])\n\nC = [RGB(c[1], c[2], c[3]) for c in eachcol(e3)]\n\nX = @view e2[1, :]\nY = @view e2[2, :]\nscatter(X, Y, color=C, fmt=:png, alpha=0.2, size=(600, 600), ma=0.3, ms=2, msw=0, label=\"\")\n\nplot!()\n\n\n\n\n\ndbscanresult = dbscan(e2, 0.035, min_cluster_size=10);\n\n\ndisplay(length(dbscanresult.clusters))\n\nplot()\nfor (i, c) in enumerate(dbscanresult.clusters)\n    X = @view e2[1, c.core_indices]\n    Y = @view e2[2, c.core_indices]\n    scatter!(X, Y, c=:auto, fmt=:png, size=(600, 600), ma=0.3, a=0.3, ms=1, msw=0, label=\"\")\n    if rand() &lt; 0.1  # just to show some examples \n        X = c.core_indices\n        sampled = \"\"\n        if length(X) &gt; 20\n            sampled = \"-- sampled from $(length(X)) elements\"\n            X = rand(X, 20)\n        end\n        display(Markdown.parse(\"## Cluster $i $sampled\"))\n        display(latexify(D[X, :], env=:mdtable, latex=false))\n    end\nend\n\nplot!()\n\n165\n\n\nCluster 10 â sampled from 157 elements\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0043.vtt\n\n01:39.000\n01:41.000\nÂ¡Tienes que matarme!\n\n\ntres-patines-y-la-tremenda-corte_0045.vtt\n\n08:00.000\n08:01.000\nÂ¡180 dÃ­as!\n\n\ntres-patines-y-la-tremenda-corte_0023.vtt\n\n07:34.600\n07:35.600\nÂ¡Diez pesos mÃ¡s!\n\n\ntres-patines-y-la-tremenda-corte_0036.vtt\n\n08:46.000\n08:47.000\nÂ¡Oh!\n\n\ntres-patines-y-la-tremenda-corte_0035.vtt\n\n02:45.000\n02:46.000\nÂ¡ay!\n\n\ntres-patines-y-la-tremenda-corte_0027.vtt\n\n08:12.000\n08:13.000\nÂ¡Me morro!\n\n\ntres-patines-y-la-tremenda-corte_0002.vtt\n\n11:43.000\n11:44.000\nÂ¡ChalÃ©!\n\n\ntres-patines-y-la-tremenda-corte_0027.vtt\n\n07:28.000\n07:29.000\nÂ¡Me morro!\n\n\ntres-patines-y-la-tremenda-corte_0020.vtt\n\n16:18.000\n16:20.000\nÂ¡AdiÃ³s!\n\n\ntres-patines-y-la-tremenda-corte_0002.vtt\n\n11:19.000\n11:21.000\nÂ¡Hombre, vuelve a tu cÃ©rcico!\n\n\ntres-patines-y-la-tremenda-corte_0013.vtt\n\n04:59.000\n05:00.000\nÂ¡No!\n\n\ntres-patines-y-la-tremenda-corte_0042.vtt\n\n01:07.000\n01:09.000\nÂ¡Presente!\n\n\ntres-patines-y-la-tremenda-corte_0042.vtt\n\n01:07.000\n01:09.000\nÂ¡Presente!\n\n\ntres-patines-y-la-tremenda-corte_0038.vtt\n\n05:50.000\n05:51.000\nÂ¡Oh, manilla!\n\n\ntres-patines-y-la-tremenda-corte_0045.vtt\n\n07:15.000\n07:17.000\nÂ¡Mira, entre las patrullas!\n\n\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n06:02.000\n06:03.000\nÂ¡No importa!\n\n\ntres-patines-y-la-tremenda-corte_0039.vtt\n\n11:39.900\n11:41.900\nÂ¡Tose! Â¡CÃ¡llese la boca, Trespatines!\n\n\ntres-patines-y-la-tremenda-corte_0013.vtt\n\n04:59.000\n05:00.000\nÂ¡No!\n\n\ntres-patines-y-la-tremenda-corte_0006.vtt\n\n01:45.000\n01:47.000\nÂ¡Olegario Cascarilla!\n\n\ntres-patines-y-la-tremenda-corte_0027.vtt\n\n07:32.000\n07:33.000\nÂ¡Me morro!\n\n\n\n\n\n\n\nCluster 30 â sampled from 136 elements\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0035.vtt\n\n05:10.000\n05:11.000\nNo, no, no.\n\n\ntres-patines-y-la-tremenda-corte_0015.vtt\n\n10:56.000\n10:59.000\nÃigame, cÃ³mo no lo va a hacer, yo no sÃ©.\n\n\ntres-patines-y-la-tremenda-corte_0028.vtt\n\n11:06.000\n11:07.000\nNo, al tacÃ³n no.\n\n\ntres-patines-y-la-tremenda-corte_0019.vtt\n\n11:21.000\n11:23.000\nNo, pero sÃ­, ellos no estaban solos.\n\n\ntres-patines-y-la-tremenda-corte_0019.vtt\n\n08:52.000\n08:53.000\nNo, no, no.\n\n\ntres-patines-y-la-tremenda-corte_0029.vtt\n\n02:50.000\n02:51.000\nNo, ningÃºn comejÃ©n, Â¿saben?\n\n\ntres-patines-y-la-tremenda-corte_0002.vtt\n\n14:08.000\n14:13.000\nBueno, doctor, usted comprenderÃ¡ que yo no podÃ­a aceptar eso debajo ningÃºn concepto, Â¿no?\n\n\ntres-patines-y-la-tremenda-corte_0009.vtt\n\n06:57.000\n06:58.000\nNo, yo no sÃ©.\n\n\ntres-patines-y-la-tremenda-corte_0021.vtt\n\n06:59.000\n07:00.000\nNo, no.\n\n\ntres-patines-y-la-tremenda-corte_0025.vtt\n\n13:13.640\n13:14.640\nNo, no, no, no, no.\n\n\ntres-patines-y-la-tremenda-corte_0023.vtt\n\n05:31.600\n05:32.600\nLo adivinaste, Â¿no?\n\n\ntres-patines-y-la-tremenda-corte_0037.vtt\n\n03:26.000\n03:27.000\nNo, no, asunto.\n\n\ntres-patines-y-la-tremenda-corte_0043.vtt\n\n00:37.000\n00:41.000\nSalvia, limÃ³n, raÃ­ces de guayaba. Eso no sirve.\n\n\ntres-patines-y-la-tremenda-corte_0035.vtt\n\n11:47.000\n11:48.000\nNo, no, no.\n\n\ntres-patines-y-la-tremenda-corte_0009.vtt\n\n01:04.000\n01:05.000\nNo, no.\n\n\ntres-patines-y-la-tremenda-corte_0013.vtt\n\n10:11.000\n10:14.000\nLas damas no, las damas no, no tenemos nada que ver con esto.\n\n\ntres-patines-y-la-tremenda-corte_0023.vtt\n\n08:08.600\n08:09.600\nNo, yo no sabÃ­a eso.\n\n\ntres-patines-y-la-tremenda-corte_0017.vtt\n\n09:59.000\n10:02.000\nNo, rato largo no, para siempre.\n\n\ntres-patines-y-la-tremenda-corte_0030.vtt\n\n10:06.440\n10:08.440\nNo, nananina, no.\n\n\ntres-patines-y-la-tremenda-corte_0020.vtt\n\n13:04.000\n13:08.000\nNo, Rudecindo no hay engaÃ±o, chico, tÃº fuiste quieto o la culpa de eso.\n\n\n\n\n\n\n\nCluster 57\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0001.vtt\n\n02:26.000\n02:28.000\nÂ¿Y entonces por quÃ© dice que no lo trajiste?\n\n\ntres-patines-y-la-tremenda-corte_0007.vtt\n\n08:46.000\n08:50.000\nEn fin, usted alega que hubo engaÃ±o por parte de estos tres seÃ±ores.\n\n\ntres-patines-y-la-tremenda-corte_0013.vtt\n\n12:40.000\n12:42.000\npor lo menos compren algo.\n\n\ntres-patines-y-la-tremenda-corte_0023.vtt\n\n14:18.600\n14:21.600\nÂ¿Y entonces por quÃ© dice usted en el anuncio que es profesor?\n\n\ntres-patines-y-la-tremenda-corte_0036.vtt\n\n11:49.000\n11:53.000\nY explÃ­queme, Tres Patines, Â¿por quÃ© dice usted que fue eso lo que le vendiÃ³ a Rudecillo?\n\n\ntres-patines-y-la-tremenda-corte_0037.vtt\n\n10:41.000\n10:43.000\nÂ¿Por quÃ© sabe usted que la prefiere?\n\n\ntres-patines-y-la-tremenda-corte_0041.vtt\n\n12:11.120\n12:14.120\nÂ¿Por quÃ© se llevaba usted las tres gallinas y el gallo entonces?\n\n\ntres-patines-y-la-tremenda-corte_0043.vtt\n\n06:37.000\n06:39.000\nÂ¿Y por quÃ©, para su desgracia?\n\n\ntres-patines-y-la-tremenda-corte_0046.vtt\n\n10:55.000\n10:56.000\nÂ¿Y eso por quÃ©?\n\n\ntres-patines-y-la-tremenda-corte_0048.vtt\n\n14:37.000\n14:38.000\nÂ¿Por quÃ© hizo eso?\n\n\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n16:37.440\n16:40.520\nY por todo ese estropicio que parece obra de locos,\n\n\n\n\n\n\n\nCluster 66\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0001.vtt\n\n06:41.000\n06:42.000\nÂ¿CuÃ¡ntas carreras tiene usted?\n\n\ntres-patines-y-la-tremenda-corte_0008.vtt\n\n13:12.000\n13:13.000\nÂ¿QuÃ© era entonces?\n\n\ntres-patines-y-la-tremenda-corte_0009.vtt\n\n01:42.000\n01:43.000\nServidor de usted, doctor.\n\n\ntres-patines-y-la-tremenda-corte_0011.vtt\n\n09:21.000\n09:23.000\nY a la vuelta pasÃ³ por la finca.\n\n\ntres-patines-y-la-tremenda-corte_0014.vtt\n\n04:48.000\n04:49.000\nOs pescado grande\n\n\ntres-patines-y-la-tremenda-corte_0019.vtt\n\n12:27.000\n12:29.000\nPorque lo de la operaciÃ³n era mentira, chico.\n\n\ntres-patines-y-la-tremenda-corte_0022.vtt\n\n13:13.700\n13:15.600\nÂ¿Era el primo hermano de Marcaigo?\n\n\ntres-patines-y-la-tremenda-corte_0024.vtt\n\n00:08.000\n00:10.000\nO van todos para el calabozo.\n\n\ntres-patines-y-la-tremenda-corte_0024.vtt\n\n03:18.000\n03:20.000\nla suitaciÃ³n econÃ³mica, Â¿te da cuenta?\n\n\ntres-patines-y-la-tremenda-corte_0030.vtt\n\n10:24.440\n10:26.440\ny empiezan a mover la farola mÃ¡s de lo\n\n\ntres-patines-y-la-tremenda-corte_0035.vtt\n\n06:17.000\n06:18.000\nÂ¿QuÃ© me dijo usted ahÃ­?\n\n\ntres-patines-y-la-tremenda-corte_0042.vtt\n\n09:49.000\n09:50.000\nÂ¿Era barbero?\n\n\n\n\n\n\n\nCluster 71\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0001.vtt\n\n09:31.000\n09:32.000\n100 pesos de multa.\n\n\ntres-patines-y-la-tremenda-corte_0009.vtt\n\n12:32.000\n12:35.000\nDiez pesos de multa por decÃ­rmelo en esa forma.\n\n\ntres-patines-y-la-tremenda-corte_0011.vtt\n\n07:35.000\n07:36.000\nDiez pesos de multa.\n\n\ntres-patines-y-la-tremenda-corte_0014.vtt\n\n10:03.000\n10:05.000\nLe paguÃ© cien pesos a un machante mÃ­o\n\n\ntres-patines-y-la-tremenda-corte_0015.vtt\n\n05:45.000\n05:47.000\nCien pesos de multa.\n\n\ntres-patines-y-la-tremenda-corte_0018.vtt\n\n00:51.000\n00:54.000\nNo se pongase cinco pesos de multa por ser mÃ¡s inteligente que su jefe.\n\n\ntres-patines-y-la-tremenda-corte_0021.vtt\n\n01:00.000\n01:03.000\nPÃ³ngase 20 pesos de multa por esa falta de respeto.\n\n\ntres-patines-y-la-tremenda-corte_0022.vtt\n\n14:21.900\n14:22.900\nCien pesos de multa.\n\n\ntres-patines-y-la-tremenda-corte_0026.vtt\n\n12:08.000\n12:11.000\nuna temporadita de 10 o 12 aÃ±os con esa hija.\n\n\ntres-patines-y-la-tremenda-corte_0029.vtt\n\n04:27.000\n04:28.000\nY es pesos de multa.\n\n\ntres-patines-y-la-tremenda-corte_0030.vtt\n\n07:22.440\n07:24.440\nese idioma. 100 pesos\n\n\ntres-patines-y-la-tremenda-corte_0030.vtt\n\n13:20.440\n13:22.440\npague 100 pesos de multa y cumpla\n\n\ntres-patines-y-la-tremenda-corte_0043.vtt\n\n02:18.000\n02:19.000\nDiez pesos de multa.\n\n\ntres-patines-y-la-tremenda-corte_0043.vtt\n\n02:23.000\n02:25.000\nCincuenta pesos de multa.\n\n\ntres-patines-y-la-tremenda-corte_0043.vtt\n\n09:58.000\n10:00.000\nCincuenta pesos de multa.\n\n\ntres-patines-y-la-tremenda-corte_0044.vtt\n\n09:26.000\n09:27.000\nCien pesos de multa.\n\n\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n11:23.600\n11:24.600\nCien pesos mÃ¡s de multa.\n\n\n\n\n\n\n\nCluster 92\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0002.vtt\n\n13:44.000\n13:45.000\nÂ¿CÃ³mo que no es verdad?\n\n\ntres-patines-y-la-tremenda-corte_0006.vtt\n\n04:09.000\n04:11.000\nNo, Â¿cÃ³mo va a tener la razÃ³n, viejo?\n\n\ntres-patines-y-la-tremenda-corte_0008.vtt\n\n03:20.000\n03:21.000\nÂ¿CÃ³mo que es al revÃ©s?\n\n\ntres-patines-y-la-tremenda-corte_0008.vtt\n\n11:57.000\n11:59.000\ny, oye, chico, Â¿cÃ³mo estaba aquello?\n\n\ntres-patines-y-la-tremenda-corte_0016.vtt\n\n03:40.960\n03:43.160\nÂ¿CÃ³mo usted lo oye, doctor?\n\n\ntres-patines-y-la-tremenda-corte_0031.vtt\n\n06:32.000\n06:33.000\nÂ¿CÃ³mo usted sabe eso?\n\n\ntres-patines-y-la-tremenda-corte_0036.vtt\n\n14:43.000\n14:45.000\nÂ¿CÃ³mo es que no tiene remedio, Trespatino?\n\n\ntres-patines-y-la-tremenda-corte_0042.vtt\n\n01:20.500\n01:23.000\nÂ¿CÃ³mo que no hay mÃ¡s nadie, compadre? Â¿DÃ³nde estÃ¡ el fantasma?\n\n\ntres-patines-y-la-tremenda-corte_0045.vtt\n\n02:41.000\n02:43.000\nÂ¿Y cÃ³mo se pelan entonces?\n\n\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n15:06.680\n15:07.720\nÂ¿CÃ³mo que no producen nada?\n\n\n\n\n\n\n\nCluster 98\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0003.vtt\n\n08:16.460\n08:21.140\nentonces claro claro le dije yo a este claro y eso no lo digo yo y tu dios\n\n\ntres-patines-y-la-tremenda-corte_0005.vtt\n\n15:00.000\n15:02.000\nNo va a estar claro, chico.\n\n\ntres-patines-y-la-tremenda-corte_0008.vtt\n\n08:36.000\n08:38.000\nClaro, tÃº deberÃ­as convencerte antes que yo arranque.\n\n\ntres-patines-y-la-tremenda-corte_0014.vtt\n\n06:46.000\n06:47.000\nClaro, hombre\n\n\ntres-patines-y-la-tremenda-corte_0018.vtt\n\n06:47.000\n06:48.000\nClaro, hombre.\n\n\ntres-patines-y-la-tremenda-corte_0023.vtt\n\n15:21.600\n15:22.600\nPues mira a ver si estaba bien claro yo esto.\n\n\ntres-patines-y-la-tremenda-corte_0026.vtt\n\n14:23.000\n14:25.000\nse lo dije bien claro a chofer\n\n\ntres-patines-y-la-tremenda-corte_0028.vtt\n\n09:25.000\n09:26.000\nSÃ­, claro, claro.\n\n\ntres-patines-y-la-tremenda-corte_0030.vtt\n\n03:47.240\n03:49.240\nClaro que sÃ­. Â¿TÃº no me lo diste para eso, Rudecindo?\n\n\ntres-patines-y-la-tremenda-corte_0033.vtt\n\n08:03.000\n08:05.000\nÂ¿Pero quÃ© tiene que ver analfabeto con antropÃ³fago?\n\n\ntres-patines-y-la-tremenda-corte_0044.vtt\n\n13:06.000\n13:07.000\nPorque yo conozco, yo conozco una mujer que cada vez que usted miraba un pollo le metÃ­a\n\n\n\n\n\n\n\nCluster 101\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0003.vtt\n\n10:10.020\n10:15.180\ncatuchito con el papel que te da el pliego de papel a seis centavos te dan cento dieciocho\n\n\ntres-patines-y-la-tremenda-corte_0003.vtt\n\n11:07.320\n11:09.320\nY te hacÃ­an 24 kilÃ³metros por hora.\n\n\ntres-patines-y-la-tremenda-corte_0007.vtt\n\n05:16.000\n05:18.000\nÂ¿QuÃ© le pasÃ³ a usted con estos seÃ±ores?\n\n\ntres-patines-y-la-tremenda-corte_0015.vtt\n\n07:34.000\n07:36.000\nPero eso era lo que iba usted a decir.\n\n\ntres-patines-y-la-tremenda-corte_0026.vtt\n\n02:22.000\n02:28.000\nNo, seÃ±or. Yo no puedo ser la mamÃ¡ de crianza de Rudecindo porque Rudecindo me lleva a mÃ­ como cuarenta aÃ±os.\n\n\ntres-patines-y-la-tremenda-corte_0028.vtt\n\n12:14.000\n12:15.000\nDe verdad, Â¿y quÃ© pasÃ³?\n\n\ntres-patines-y-la-tremenda-corte_0037.vtt\n\n09:09.000\n09:11.000\nÂ¿CÃ³mo le dije yo?\n\n\ntres-patines-y-la-tremenda-corte_0038.vtt\n\n02:33.000\n02:34.000\nÂ¿QuÃ© le pasÃ³ entonces?\n\n\ntres-patines-y-la-tremenda-corte_0040.vtt\n\n06:00.000\n06:03.000\nla caÃ±a viene para abajo con un tiro.\n\n\ntres-patines-y-la-tremenda-corte_0041.vtt\n\n11:36.120\n11:37.120\nÂ¿QuÃ© pasÃ³ despuÃ©s?\n\n\ntres-patines-y-la-tremenda-corte_0046.vtt\n\n11:49.000\n11:51.000\nMira acÃ¡ ya, su tÃ­a Petronila, Â¿quÃ© le pasÃ³?\n\n\n\n\n\n\n\nCluster 104\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0003.vtt\n\n12:30.820\n12:32.820\nLa segunda vez no hay quien se lo dispare, chico.\n\n\ntres-patines-y-la-tremenda-corte_0009.vtt\n\n04:48.000\n04:53.000\nPorque tÃº, por ejemplo, tÃº tienes tu manera de ser, y yo tengo la manera de ser mÃ­a.\n\n\ntres-patines-y-la-tremenda-corte_0010.vtt\n\n03:12.000\n03:14.000\nEn fin, Â¿quiÃ©n es el estafado?\n\n\ntres-patines-y-la-tremenda-corte_0013.vtt\n\n12:25.000\n12:28.000\nExactamente, quien se va a enfrentar con un bandido que entra en una tienda de rebote\n\n\ntres-patines-y-la-tremenda-corte_0016.vtt\n\n00:59.200\n01:00.600\nÂ¿A quiÃ©n estafaron?\n\n\ntres-patines-y-la-tremenda-corte_0035.vtt\n\n02:00.000\n02:01.000\nÂ¿Y quiÃ©n estÃ¡ frÃ­o?\n\n\ntres-patines-y-la-tremenda-corte_0043.vtt\n\n05:53.000\n05:56.000\nVamos a ver, Rudecindo, Â¿quÃ© fue lo que pasÃ³?\n\n\ntres-patines-y-la-tremenda-corte_0044.vtt\n\n12:03.000\n12:04.000\nÂ¿QuiÃ©n?\n\n\ntres-patines-y-la-tremenda-corte_0047.vtt\n\n07:55.000\n07:56.000\nÂ¿QuiÃ©n dice usted que es el acusado?\n\n\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n07:22.000\n07:24.000\nHay un refrÃ¡n que dice, dime quiÃ©n eres y te dirÃ© con quiÃ©n andas.\n\n\n\n\n\n\n\nCluster 119\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0004.vtt\n\n11:24.000\n11:25.000\nÂ¿CÃ³mo podÃ­a suponer ustedes\n\n\ntres-patines-y-la-tremenda-corte_0008.vtt\n\n08:15.000\n08:17.000\nÂ¿CÃ³mo fue que ocurriÃ³ el choque?\n\n\ntres-patines-y-la-tremenda-corte_0009.vtt\n\n07:27.000\n07:28.000\nÂ¿CÃ³mo que sÃ­ quiero cambiar?\n\n\ntres-patines-y-la-tremenda-corte_0013.vtt\n\n07:02.000\n07:05.000\nEn fin, Â¿cÃ³mo fue el asalto ese, nananina?\n\n\ntres-patines-y-la-tremenda-corte_0015.vtt\n\n06:52.000\n06:53.000\nÂ¿CÃ³mo? Â¿QuiÃ©n dijo eso?\n\n\ntres-patines-y-la-tremenda-corte_0015.vtt\n\n11:52.000\n11:56.000\nQue yo me enterÃ© de que, me parece que no empecÃ© bien.\n\n\ntres-patines-y-la-tremenda-corte_0019.vtt\n\n08:24.000\n08:26.000\nComo no le iba a despreciar la invitaciÃ³n, Â¿verdad?\n\n\ntres-patines-y-la-tremenda-corte_0020.vtt\n\n07:04.000\n07:07.000\nOye, chico, tÃº no haces mÃ¡s que ponerle inconveniente a todo el mundo, chico.\n\n\ntres-patines-y-la-tremenda-corte_0023.vtt\n\n10:29.600\n10:31.600\nÂ¿Y entonces cÃ³mo me la va a poner en el acento el H?\n\n\ntres-patines-y-la-tremenda-corte_0040.vtt\n\n13:40.000\n13:44.000\nÂ¿CÃ³mo yo trespatines que ese peso sonaba plomo?\n\n\ntres-patines-y-la-tremenda-corte_0043.vtt\n\n00:27.000\n00:30.000\nPara el dolor de muela. A ver, Â¿cÃ³mo es el remedio ese?\n\n\ntres-patines-y-la-tremenda-corte_0044.vtt\n\n00:10.000\n00:12.000\nÂ¿CÃ³mo se siente usted hoy?\n\n\ntres-patines-y-la-tremenda-corte_0045.vtt\n\n11:17.000\n11:19.000\nÂ¿Y cÃ³mo va a ir usted a una regata de remo en una gasolidera?\n\n\n\n\n\n\n\nCluster 123\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0005.vtt\n\n01:20.000\n01:21.000\nÂ¿Y Nananena?\n\n\ntres-patines-y-la-tremenda-corte_0007.vtt\n\n01:59.000\n02:00.000\nEn Picota y JesÃºs MarÃ­a.\n\n\ntres-patines-y-la-tremenda-corte_0010.vtt\n\n13:47.000\n13:49.000\nlos seis aÃ±os y un dÃ­a.\n\n\ntres-patines-y-la-tremenda-corte_0011.vtt\n\n10:35.000\n10:36.000\nÂ¿QuÃ© adivinanza?\n\n\ntres-patines-y-la-tremenda-corte_0018.vtt\n\n12:45.000\n12:47.000\nno tenga mÃ¡s que tres aÃ±os?\n\n\ntres-patines-y-la-tremenda-corte_0020.vtt\n\n12:18.000\n12:19.000\nÂ¿QuÃ©?\n\n\ntres-patines-y-la-tremenda-corte_0026.vtt\n\n08:28.000\n08:29.000\nÂ¿CuÃ¡l es el segundo tomo?\n\n\ntres-patines-y-la-tremenda-corte_0028.vtt\n\n10:39.000\n10:40.000\nÂ¿Entonces?\n\n\ntres-patines-y-la-tremenda-corte_0029.vtt\n\n07:58.000\n07:59.000\nÂ¿Y quÃ©?\n\n\ntres-patines-y-la-tremenda-corte_0039.vtt\n\n03:40.700\n03:43.500\nEntre la E y la T hay una P.\n\n\ntres-patines-y-la-tremenda-corte_0039.vtt\n\n05:17.600\n05:19.400\nÂ¿QuÃ© ratonera ni quÃ© nada?\n\n\ntres-patines-y-la-tremenda-corte_0049.vtt\n\n07:48.000\n07:49.000\nÂ¿QuÃ© pugilato de quÃ©?\n\n\n\n\n\n\n\nCluster 124\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0005.vtt\n\n02:57.000\n02:58.000\nPrestame cinco pesos.\n\n\ntres-patines-y-la-tremenda-corte_0017.vtt\n\n02:29.000\n02:31.000\nPÃ³ngale un peso de multa al sobrino de su tÃ­a.\n\n\ntres-patines-y-la-tremenda-corte_0017.vtt\n\n07:46.000\n07:48.000\n10 pesos mÃ¡s arrudeciendo con el mismo interÃ©s.\n\n\ntres-patines-y-la-tremenda-corte_0017.vtt\n\n07:52.000\n07:57.000\n20 pesos mÃ¡s para arrudeciendo, pero esta vez pÃ³ngaselo con el 30% de interÃ©s.\n\n\ntres-patines-y-la-tremenda-corte_0018.vtt\n\n09:54.000\n09:58.000\nporque cuatro setenta y cinco de multa es demasiado.\n\n\ntres-patines-y-la-tremenda-corte_0021.vtt\n\n01:27.000\n01:31.000\nUn curandero que viene acusado de haberle estafado 20 pesos a un espaÃ±ol.\n\n\ntres-patines-y-la-tremenda-corte_0025.vtt\n\n11:34.200\n11:38.480\nDiez pesos de multa a usted y diez pesos a usted, ioles.\n\n\ntres-patines-y-la-tremenda-corte_0035.vtt\n\n00:40.000\n00:42.000\nPues le pongo 30 pesos de multa al estÃ³mago.\n\n\ntres-patines-y-la-tremenda-corte_0036.vtt\n\n10:05.000\n10:07.000\nLe costÃ³ 180 dÃ­as.\n\n\ntres-patines-y-la-tremenda-corte_0040.vtt\n\n14:53.000\n14:55.000\nPÃ³ngale ciento ochenta dÃ­as.\n\n\ntres-patines-y-la-tremenda-corte_0047.vtt\n\n09:24.000\n09:25.000\n40 pesos tienes aquÃ­.\n\n\n\n\n\n\n\nCluster 147\n\n\n\n\n\n\n\nidfile\nname\ntbegin\ntend\ncaption\n\n\ntres-patines-y-la-tremenda-corte_0008.vtt\n\n05:40.000\n05:42.000\nDÃ­game una cosa, tres patines.\n\n\ntres-patines-y-la-tremenda-corte_0010.vtt\n\n03:36.000\n03:41.000\nTengo ahÃ­ un carrito que no va a elegir a la cosa ni nada de eso, Â¿no?\n\n\ntres-patines-y-la-tremenda-corte_0011.vtt\n\n05:16.000\n05:17.000\nOiga, digame una cosa, don Catalino.\n\n\ntres-patines-y-la-tremenda-corte_0011.vtt\n\n15:53.000\n15:55.000\n...para el canciller, chicos, oye, es una cosa asÃ­.\n\n\ntres-patines-y-la-tremenda-corte_0014.vtt\n\n03:49.000\n03:50.000\nLa cosa no es asÃ­\n\n\ntres-patines-y-la-tremenda-corte_0017.vtt\n\n13:06.000\n13:08.000\nSÃ­, Ã©l le llama novia a cualquier cosa, hija.\n\n\ntres-patines-y-la-tremenda-corte_0021.vtt\n\n07:50.000\n07:52.000\nDespuÃ©s que me lo viste hacer asÃ­, mira quÃ© cosa.\n\n\ntres-patines-y-la-tremenda-corte_0029.vtt\n\n08:28.000\n08:30.000\nBueno, sÃ­, pero espÃ©rese una cosa.\n\n\ntres-patines-y-la-tremenda-corte_0031.vtt\n\n06:45.000\n06:47.000\nEsa cosa que le da a uno\n\n\ntres-patines-y-la-tremenda-corte_0036.vtt\n\n06:33.000\n06:36.000\nLo que tengo estÃ¡ una cosa ahÃ­ que me quemÃ© hoy por la tarde.\n\n\ntres-patines-y-la-tremenda-corte_0039.vtt\n\n08:44.100\n08:46.500\nPero aquÃ­ veo una cosa un poco rara, trepatÃ­n.\n\n\ntres-patines-y-la-tremenda-corte_0040.vtt\n\n12:11.000\n12:13.000\nBueno, oiga, si la cosa es esa,\n\n\ntres-patines-y-la-tremenda-corte_0043.vtt\n\n08:49.000\n08:52.000\nSi matan a uno, pues estÃ¡ seguro ahÃ­ que es una cosa que garantiza.\n\n\ntres-patines-y-la-tremenda-corte_0045.vtt\n\n12:13.000\n12:14.000\nUna cosa asÃ­.\n\n\ntres-patines-y-la-tremenda-corte_0046.vtt\n\n04:56.000\n04:59.000\nPara eso voy a una bodega, la compro y me la como allÃ­ mismo, vea quÃ© cosa\n\n\ntres-patines-y-la-tremenda-corte_0050.vtt\n\n02:41.000\n02:45.000\nMire, Trespatines, no me des mÃ¡s lesiones aquÃ­ y aclÃ¡reme una cosa."
  },
  {
    "objectID": "demos/podcast-collection.html#environment-and-dependencies",
    "href": "demos/podcast-collection.html#environment-and-dependencies",
    "title": "Searching in podcast collection",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.9\nCommit 5595d20a287 (2025-03-10 12:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 Ã Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_NUM_THREADS = auto\n  JULIA_PROJECT = .\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/sites/SimilaritySearchDemos/Project.toml`\n  [aaaa29a8] Clustering v0.15.8\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.7.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.0 `~/.julia/dev/InvertedFiles`\n  [682c06a0] JSON v0.21.4\n  [23fbe1c1] Latexify v0.16.6\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\nâ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.11\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.0 `~/.julia/dev/SimSearchManifoldLearning`\n  [053f045d] SimilaritySearch v0.12.0 `~/.julia/dev/SimilaritySearch`\nâ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.0 `~/.julia/dev/TextSearch`\nInfo Packages marked with â and â have new versions available. Those with â may be upgradable, but those with â are restricted by compatibility constraints from upgrading. To see why use `status --outdated`"
  },
  {
    "objectID": "demos/using-manifoldlearning.html",
    "href": "demos/using-manifoldlearning.html",
    "title": "Using with ManifoldLearning",
    "section": "",
    "text": "by: Eric S. TÃ©llez\nThis demonstration is about using SimilaritySearch and ManifoldLearning methods through SimSearchManifoldLearning.\nusing SimilaritySearch, SimSearchManifoldLearning, ManifoldLearning, Primes, Plots, StatsPlots, StatsBase, LinearAlgebra, Markdown, Random"
  },
  {
    "objectID": "demos/using-manifoldlearning.html#scurve-example",
    "href": "demos/using-manifoldlearning.html#scurve-example",
    "title": "Using with ManifoldLearning",
    "section": "SCurve example",
    "text": "SCurve example\n\nX, L = ManifoldLearning.scurve(segments=5)\n\nscatter(X[1, :], X[2, :], X[3, :], color=L, alpha=0.5)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimilaritySearch support exact and approximate algorithms to solve k nearest neighbors. Also, it supports different metrics. For instance, let see how the selection of the distance function modifies the projection.\n\nManhattan distance (\\(L_1\\))\n\nlet Y = predict(fit(Isomap, X, nntype=ApproxManhattan))\n    scatter(Y[1,:], Y[2,:], color=L, alpha=0.5)\nend\n\ncomputing farthest point 1, dmax: Inf, imax: 118, n: 153\ncomputing farthest point 2, dmax: 4.0211563, imax: 77, n: 153\ncomputing farthest point 3, dmax: 3.7380528, imax: 68, n: 153\ncomputing farthest point 4, dmax: 2.7191744, imax: 149, n: 153\ncomputing farthest point 5, dmax: 2.6464257, imax: 114, n: 153\ncomputing farthest point 6, dmax: 2.640573, imax: 46, n: 153\ncomputing farthest point 7, dmax: 2.5892792, imax: 95, n: 153\ncomputing farthest point 8, dmax: 2.2490485, imax: 34, n: 153\ncomputing farthest point 9, dmax: 2.0707157, imax: 35, n: 153\ncomputing farthest point 10, dmax: 1.8713273, imax: 133, n: 153\ncomputing farthest point 11, dmax: 1.6823415, imax: 142, n: 153\ncomputing farthest point 12, dmax: 1.6623374, imax: 53, n: 153\ncomputing farthest point 13, dmax: 1.6203825, imax: 26, n: 153\ncomputing farthest point 14, dmax: 1.5765537, imax: 115, n: 153\ncomputing farthest point 15, dmax: 1.410517, imax: 128, n: 153\ncomputing farthest point 16, dmax: 1.3394569, imax: 83, n: 153\ncomputing farthest point 17, dmax: 1.2512485, imax: 6, n: 153\ncomputing farthest point 18, dmax: 1.2162488, imax: 20, n: 153\ncomputing farthest point 19, dmax: 1.1743883, imax: 99, n: 153\ncomputing farthest point 20, dmax: 1.13403, imax: 152, n: 153\ncomputing farthest point 21, dmax: 1.1250432, imax: 16, n: 153\ncomputing farthest point 22, dmax: 1.0729687, imax: 79, n: 153\ncomputing farthest point 23, dmax: 1.0596776, imax: 94, n: 153\ncomputing farthest point 24, dmax: 0.992541, imax: 84, n: 153\ncomputing farthest point 25, dmax: 0.9615145, imax: 139, n: 153\ncomputing farthest point 26, dmax: 0.9568216, imax: 127, n: 153\ncomputing farthest point 27, dmax: 0.94813186, imax: 11, n: 153\ncomputing farthest point 28, dmax: 0.91824263, imax: 144, n: 153\ncomputing farthest point 29, dmax: 0.9127529, imax: 122, n: 153\ncomputing farthest point 30, dmax: 0.91068125, imax: 1, n: 153\ncomputing farthest point 31, dmax: 0.8962267, imax: 134, n: 153\ncomputing farthest point 32, dmax: 0.87231386, imax: 143, n: 153\ncomputing farthest point 33, dmax: 0.8440936, imax: 18, n: 153\ncomputing farthest point 34, dmax: 0.84028184, imax: 100, n: 153\ncomputing farthest point 35, dmax: 0.83248854, imax: 102, n: 153\ncomputing farthest point 36, dmax: 0.806729, imax: 21, n: 153\n(n, m, k, length(A.centers), length(C)) = (513, 216, 36, 36, 35)\n[ Info: using 32 random queries from the dataset\ncomputing farthest point 1, dmax: Inf, imax: 137, n: 182\ncomputing farthest point 2, dmax: 5.915717, imax: 50, n: 182\ncomputing farthest point 3, dmax: 3.802009, imax: 72, n: 182\ncomputing farthest point 4, dmax: 3.4993076, imax: 42, n: 182\ncomputing farthest point 5, dmax: 2.8268332, imax: 139, n: 182\ncomputing farthest point 6, dmax: 2.6311707, imax: 145, n: 182\ncomputing farthest point 7, dmax: 2.4075136, imax: 158, n: 182\ncomputing farthest point 8, dmax: 2.2946515, imax: 74, n: 182\ncomputing farthest point 9, dmax: 2.1040294, imax: 147, n: 182\ncomputing farthest point 10, dmax: 1.7738006, imax: 114, n: 182\ncomputing farthest point 11, dmax: 1.738389, imax: 106, n: 182\ncomputing farthest point 12, dmax: 1.6103764, imax: 119, n: 182\ncomputing farthest point 13, dmax: 1.4781154, imax: 107, n: 182\ncomputing farthest point 14, dmax: 1.3894738, imax: 29, n: 182\ncomputing farthest point 15, dmax: 1.3378047, imax: 64, n: 182\ncomputing farthest point 16, dmax: 1.323116, imax: 164, n: 182\ncomputing farthest point 17, dmax: 1.314264, imax: 132, n: 182\ncomputing farthest point 18, dmax: 1.2353854, imax: 13, n: 182\ncomputing farthest point 19, dmax: 1.2177114, imax: 82, n: 182\ncomputing farthest point 20, dmax: 1.1549094, imax: 111, n: 182\ncomputing farthest point 21, dmax: 1.126887, imax: 92, n: 182\ncomputing farthest point 22, dmax: 1.097383, imax: 169, n: 182\ncomputing farthest point 23, dmax: 1.014452, imax: 120, n: 182\ncomputing farthest point 24, dmax: 1.0047059, imax: 146, n: 182\ncomputing farthest point 25, dmax: 0.989815, imax: 2, n: 182\ncomputing farthest point 26, dmax: 0.9298565, imax: 33, n: 182\ncomputing farthest point 27, dmax: 0.9104564, imax: 62, n: 182\ncomputing farthest point 28, dmax: 0.8806298, imax: 51, n: 182\ncomputing farthest point 29, dmax: 0.8756791, imax: 84, n: 182\ncomputing farthest point 30, dmax: 0.8525454, imax: 162, n: 182\ncomputing farthest point 31, dmax: 0.8460682, imax: 112, n: 182\ncomputing farthest point 32, dmax: 0.84477603, imax: 174, n: 182\ncomputing farthest point 33, dmax: 0.8063342, imax: 59, n: 182\ncomputing farthest point 34, dmax: 0.77896065, imax: 130, n: 182\ncomputing farthest point 35, dmax: 0.7667773, imax: 166, n: 182\ncomputing farthest point 36, dmax: 0.76588833, imax: 98, n: 182\ncomputing farthest point 37, dmax: 0.7577023, imax: 61, n: 182\ncomputing farthest point 38, dmax: 0.7502051, imax: 25, n: 182\n(n, m, k, length(A.centers), length(C)) = (770, 235, 38, 38, 37)\n[ Info: using 32 random queries from the dataset\ncomputing farthest point 1, dmax: Inf, imax: 43, n: 195\ncomputing farthest point 2, dmax: 5.2367373, imax: 20, n: 195\ncomputing farthest point 3, dmax: 3.7180321, imax: 47, n: 195\ncomputing farthest point 4, dmax: 3.3775744, imax: 56, n: 195\ncomputing farthest point 5, dmax: 2.8840945, imax: 112, n: 195\ncomputing farthest point 6, dmax: 2.4868114, imax: 88, n: 195\ncomputing farthest point 7, dmax: 2.3150055, imax: 188, n: 195\ncomputing farthest point 8, dmax: 2.0486703, imax: 35, n: 195\ncomputing farthest point 9, dmax: 2.0384965, imax: 193, n: 195\ncomputing farthest point 10, dmax: 1.9964312, imax: 34, n: 195\ncomputing farthest point 11, dmax: 1.7749311, imax: 36, n: 195\ncomputing farthest point 12, dmax: 1.6782948, imax: 108, n: 195\ncomputing farthest point 13, dmax: 1.6529802, imax: 177, n: 195\ncomputing farthest point 14, dmax: 1.6158656, imax: 135, n: 195\ncomputing farthest point 15, dmax: 1.6062155, imax: 76, n: 195\ncomputing farthest point 16, dmax: 1.4386594, imax: 156, n: 195\ncomputing farthest point 17, dmax: 1.3821534, imax: 175, n: 195\ncomputing farthest point 18, dmax: 1.3454163, imax: 114, n: 195\ncomputing farthest point 19, dmax: 1.2357537, imax: 120, n: 195\ncomputing farthest point 20, dmax: 1.1884189, imax: 100, n: 195\ncomputing farthest point 21, dmax: 1.1775814, imax: 55, n: 195\ncomputing farthest point 22, dmax: 1.1763892, imax: 183, n: 195\ncomputing farthest point 23, dmax: 1.1216246, imax: 29, n: 195\ncomputing farthest point 24, dmax: 1.0551457, imax: 48, n: 195\ncomputing farthest point 25, dmax: 1.0244915, imax: 116, n: 195\ncomputing farthest point 26, dmax: 1.009263, imax: 25, n: 195\ncomputing farthest point 27, dmax: 0.9924124, imax: 32, n: 195\ncomputing farthest point 28, dmax: 0.9912797, imax: 5, n: 195\ncomputing farthest point 29, dmax: 0.9148598, imax: 71, n: 195\ncomputing farthest point 30, dmax: 0.8952584, imax: 50, n: 195\ncomputing farthest point 31, dmax: 0.88100934, imax: 78, n: 195\ncomputing farthest point 32, dmax: 0.8656275, imax: 145, n: 195\ncomputing farthest point 33, dmax: 0.8407385, imax: 104, n: 195\ncomputing farthest point 34, dmax: 0.8363576, imax: 155, n: 195\ncomputing farthest point 35, dmax: 0.83308464, imax: 105, n: 195\ncomputing farthest point 36, dmax: 0.8036619, imax: 41, n: 195\ncomputing farthest point 37, dmax: 0.7765903, imax: 106, n: 195\ncomputing farthest point 38, dmax: 0.7743584, imax: 18, n: 195\ncomputing farthest point 39, dmax: 0.75459856, imax: 161, n: 195\n(n, m, k, length(A.centers), length(C)) = (1000, 244, 39, 39, 35)\n[ Info: using 32 random queries from the dataset\n[ Info: using 64 random queries from the dataset\n  0.168119 seconds (184.08 k allocations: 11.860 MiB, 99.72% compilation time)\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEuclidean distance (\\(L_2\\))\n\nlet\n    E = predict(fit(Isomap, X, nntype=ApproxEuclidean))\n    scatter(E[1,:], E[2,:], color=L, alpha=0.5)\nend\n\ncomputing farthest point 1, dmax: Inf, imax: 81, n: 136\ncomputing farthest point 2, dmax: 3.1765275, imax: 57, n: 136\ncomputing farthest point 3, dmax: 2.0887954, imax: 31, n: 136\ncomputing farthest point 4, dmax: 2.0824862, imax: 32, n: 136\ncomputing farthest point 5, dmax: 2.0101128, imax: 6, n: 136\ncomputing farthest point 6, dmax: 1.8339777, imax: 58, n: 136\ncomputing farthest point 7, dmax: 1.5729568, imax: 119, n: 136\ncomputing farthest point 8, dmax: 1.5285559, imax: 73, n: 136\ncomputing farthest point 9, dmax: 1.4363505, imax: 51, n: 136\ncomputing farthest point 10, dmax: 1.3445479, imax: 21, n: 136\ncomputing farthest point 11, dmax: 1.3426316, imax: 15, n: 136\ncomputing farthest point 12, dmax: 1.230112, imax: 56, n: 136\ncomputing farthest point 13, dmax: 1.2029935, imax: 42, n: 136\ncomputing farthest point 14, dmax: 1.0324553, imax: 2, n: 136\ncomputing farthest point 15, dmax: 1.0257555, imax: 113, n: 136\ncomputing farthest point 16, dmax: 0.9813445, imax: 33, n: 136\ncomputing farthest point 17, dmax: 0.950305, imax: 85, n: 136\ncomputing farthest point 18, dmax: 0.85221976, imax: 75, n: 136\ncomputing farthest point 19, dmax: 0.80340844, imax: 62, n: 136\ncomputing farthest point 20, dmax: 0.78229374, imax: 37, n: 136\ncomputing farthest point 21, dmax: 0.7375622, imax: 134, n: 136\ncomputing farthest point 22, dmax: 0.7137364, imax: 114, n: 136\ncomputing farthest point 23, dmax: 0.7051105, imax: 72, n: 136\ncomputing farthest point 24, dmax: 0.68795955, imax: 16, n: 136\ncomputing farthest point 25, dmax: 0.6821181, imax: 8, n: 136\ncomputing farthest point 26, dmax: 0.6720803, imax: 97, n: 136\ncomputing farthest point 27, dmax: 0.653411, imax: 99, n: 136\ncomputing farthest point 28, dmax: 0.63688326, imax: 74, n: 136\ncomputing farthest point 29, dmax: 0.61100155, imax: 117, n: 136\ncomputing farthest point 30, dmax: 0.5996261, imax: 63, n: 136\ncomputing farthest point 31, dmax: 0.5886997, imax: 13, n: 136\ncomputing farthest point 32, dmax: 0.5831495, imax: 34, n: 136\ncomputing farthest point 33, dmax: 0.5676932, imax: 96, n: 136\ncomputing farthest point 34, dmax: 0.5461543, imax: 52, n: 136\ncomputing farthest point 35, dmax: 0.53182745, imax: 92, n: 136\ncomputing farthest point 36, dmax: 0.5034151, imax: 93, n: 136\n(n, m, k, length(A.centers), length(C)) = (513, 216, 36, 36, 32)\n[ Info: using 32 random queries from the dataset\ncomputing farthest point 1, dmax: Inf, imax: 114, n: 176\ncomputing farthest point 2, dmax: 4.2590475, imax: 22, n: 176\ncomputing farthest point 3, dmax: 2.3317323, imax: 171, n: 176\ncomputing farthest point 4, dmax: 2.1820593, imax: 52, n: 176\ncomputing farthest point 5, dmax: 1.8651805, imax: 51, n: 176\ncomputing farthest point 6, dmax: 1.855484, imax: 112, n: 176\ncomputing farthest point 7, dmax: 1.6379606, imax: 75, n: 176\ncomputing farthest point 8, dmax: 1.6221762, imax: 102, n: 176\ncomputing farthest point 9, dmax: 1.4285843, imax: 144, n: 176\ncomputing farthest point 10, dmax: 1.2335333, imax: 35, n: 176\ncomputing farthest point 11, dmax: 1.2249413, imax: 82, n: 176\ncomputing farthest point 12, dmax: 1.1653776, imax: 115, n: 176\ncomputing farthest point 13, dmax: 1.0823392, imax: 157, n: 176\ncomputing farthest point 14, dmax: 1.0770983, imax: 86, n: 176\ncomputing farthest point 15, dmax: 1.0537095, imax: 88, n: 176\ncomputing farthest point 16, dmax: 0.9846361, imax: 20, n: 176\ncomputing farthest point 17, dmax: 0.9070302, imax: 170, n: 176\ncomputing farthest point 18, dmax: 0.8937644, imax: 85, n: 176\ncomputing farthest point 19, dmax: 0.83370537, imax: 145, n: 176\ncomputing farthest point 20, dmax: 0.80990356, imax: 83, n: 176\ncomputing farthest point 21, dmax: 0.7718367, imax: 103, n: 176\ncomputing farthest point 22, dmax: 0.76973563, imax: 61, n: 176\ncomputing farthest point 23, dmax: 0.7521878, imax: 108, n: 176\ncomputing farthest point 24, dmax: 0.7453805, imax: 33, n: 176\ncomputing farthest point 25, dmax: 0.7228984, imax: 92, n: 176\ncomputing farthest point 26, dmax: 0.7225953, imax: 6, n: 176\ncomputing farthest point 27, dmax: 0.7109165, imax: 37, n: 176\ncomputing farthest point 28, dmax: 0.69256, imax: 1, n: 176\ncomputing farthest point 29, dmax: 0.65361494, imax: 64, n: 176\ncomputing farthest point 30, dmax: 0.64091974, imax: 107, n: 176\ncomputing farthest point 31, dmax: 0.59408426, imax: 62, n: 176\ncomputing farthest point 32, dmax: 0.5882155, imax: 156, n: 176\ncomputing farthest point 33, dmax: 0.5775966, imax: 128, n: 176\ncomputing farthest point 34, dmax: 0.57226753, imax: 118, n: 176\ncomputing farthest point 35, dmax: 0.5606112, imax: 142, n: 176\ncomputing farthest point 36, dmax: 0.536344, imax: 158, n: 176\ncomputing farthest point 37, dmax: 0.52651685, imax: 122, n: 176\ncomputing farthest point 38, dmax: 0.5259393, imax: 25, n: 176\n(n, m, k, length(A.centers), length(C)) = (770, 235, 38, 38, 37)\n[ Info: using 32 random queries from the dataset\ncomputing farthest point 1, dmax: Inf, imax: 29, n: 187\ncomputing farthest point 2, dmax: 3.830146, imax: 134, n: 187\ncomputing farthest point 3, dmax: 2.5796425, imax: 56, n: 187\ncomputing farthest point 4, dmax: 2.1877341, imax: 144, n: 187\ncomputing farthest point 5, dmax: 1.9068332, imax: 61, n: 187\ncomputing farthest point 6, dmax: 1.7362905, imax: 22, n: 187\ncomputing farthest point 7, dmax: 1.7227757, imax: 59, n: 187\ncomputing farthest point 8, dmax: 1.714947, imax: 15, n: 187\ncomputing farthest point 9, dmax: 1.373168, imax: 126, n: 187\ncomputing farthest point 10, dmax: 1.2260824, imax: 39, n: 187\ncomputing farthest point 11, dmax: 1.2162443, imax: 30, n: 187\ncomputing farthest point 12, dmax: 1.212902, imax: 161, n: 187\ncomputing farthest point 13, dmax: 1.102339, imax: 133, n: 187\ncomputing farthest point 14, dmax: 1.0960392, imax: 125, n: 187\ncomputing farthest point 15, dmax: 1.0665832, imax: 186, n: 187\ncomputing farthest point 16, dmax: 1.0401922, imax: 106, n: 187\ncomputing farthest point 17, dmax: 0.8400171, imax: 32, n: 187\ncomputing farthest point 18, dmax: 0.8089342, imax: 10, n: 187\ncomputing farthest point 19, dmax: 0.80517256, imax: 17, n: 187\ncomputing farthest point 20, dmax: 0.8015938, imax: 116, n: 187\ncomputing farthest point 21, dmax: 0.79428023, imax: 107, n: 187\ncomputing farthest point 22, dmax: 0.7830063, imax: 158, n: 187\ncomputing farthest point 23, dmax: 0.7447058, imax: 105, n: 187\ncomputing farthest point 24, dmax: 0.71653545, imax: 141, n: 187\ncomputing farthest point 25, dmax: 0.6906978, imax: 110, n: 187\ncomputing farthest point 26, dmax: 0.6894929, imax: 78, n: 187\ncomputing farthest point 27, dmax: 0.6626851, imax: 168, n: 187\ncomputing farthest point 28, dmax: 0.6571361, imax: 180, n: 187\ncomputing farthest point 29, dmax: 0.6434514, imax: 25, n: 187\ncomputing farthest point 30, dmax: 0.63434345, imax: 148, n: 187\ncomputing farthest point 31, dmax: 0.63132244, imax: 117, n: 187\ncomputing farthest point 32, dmax: 0.6117757, imax: 28, n: 187\ncomputing farthest point 33, dmax: 0.5996607, imax: 108, n: 187\ncomputing farthest point 34, dmax: 0.5982805, imax: 187, n: 187\ncomputing farthest point 35, dmax: 0.56903, imax: 137, n: 187\ncomputing farthest point 36, dmax: 0.56004924, imax: 90, n: 187\ncomputing farthest point 37, dmax: 0.55774206, imax: 3, n: 187\ncomputing farthest point 38, dmax: 0.5408214, imax: 16, n: 187\ncomputing farthest point 39, dmax: 0.52153254, imax: 14, n: 187\n(n, m, k, length(A.centers), length(C)) = (1000, 244, 39, 39, 37)\n[ Info: using 32 random queries from the dataset\n[ Info: using 64 random queries from the dataset\n  0.146815 seconds (176.19 k allocations: 11.329 MiB, 99.66% compilation time)\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChebyshev distance (\\(L_\\infty\\))\n\nlet\n    Ch = predict(fit(Isomap, X, nntype=ApproxChebyshev))\n    scatter(Ch[1,:], Ch[2,:], color=L, alpha=0.5)\nend\n\ncomputing farthest point 1, dmax: Inf, imax: 37, n: 138\ncomputing farthest point 2, dmax: 3.681346, imax: 136, n: 138\ncomputing farthest point 3, dmax: 1.8167326, imax: 88, n: 138\ncomputing farthest point 4, dmax: 1.5577658, imax: 19, n: 138\ncomputing farthest point 5, dmax: 1.4974395, imax: 93, n: 138\ncomputing farthest point 6, dmax: 1.3243232, imax: 55, n: 138\ncomputing farthest point 7, dmax: 1.1247166, imax: 65, n: 138\ncomputing farthest point 8, dmax: 1.104864, imax: 56, n: 138\ncomputing farthest point 9, dmax: 1.0830495, imax: 80, n: 138\ncomputing farthest point 10, dmax: 0.9983501, imax: 53, n: 138\ncomputing farthest point 11, dmax: 0.9559294, imax: 23, n: 138\ncomputing farthest point 12, dmax: 0.933417, imax: 16, n: 138\ncomputing farthest point 13, dmax: 0.90263486, imax: 11, n: 138\ncomputing farthest point 14, dmax: 0.84324414, imax: 4, n: 138\ncomputing farthest point 15, dmax: 0.8017093, imax: 77, n: 138\ncomputing farthest point 16, dmax: 0.75653005, imax: 101, n: 138\ncomputing farthest point 17, dmax: 0.72419083, imax: 134, n: 138\ncomputing farthest point 18, dmax: 0.71365297, imax: 113, n: 138\ncomputing farthest point 19, dmax: 0.66759443, imax: 51, n: 138\ncomputing farthest point 20, dmax: 0.6181785, imax: 75, n: 138\ncomputing farthest point 21, dmax: 0.60782164, imax: 13, n: 138\ncomputing farthest point 22, dmax: 0.5979855, imax: 21, n: 138\ncomputing farthest point 23, dmax: 0.5911692, imax: 31, n: 138\ncomputing farthest point 24, dmax: 0.5825815, imax: 85, n: 138\ncomputing farthest point 25, dmax: 0.5791361, imax: 87, n: 138\ncomputing farthest point 26, dmax: 0.54057574, imax: 125, n: 138\ncomputing farthest point 27, dmax: 0.49795043, imax: 94, n: 138\ncomputing farthest point 28, dmax: 0.496994, imax: 104, n: 138\ncomputing farthest point 29, dmax: 0.49253204, imax: 7, n: 138\ncomputing farthest point 30, dmax: 0.48707512, imax: 112, n: 138\ncomputing farthest point 31, dmax: 0.48348525, imax: 49, n: 138\ncomputing farthest point 32, dmax: 0.47950244, imax: 52, n: 138\ncomputing farthest point 33, dmax: 0.47066557, imax: 119, n: 138\ncomputing farthest point 34, dmax: 0.46259525, imax: 127, n: 138\ncomputing farthest point 35, dmax: 0.45734242, imax: 24, n: 138\ncomputing farthest point 36, dmax: 0.4561991, imax: 28, n: 138\n(n, m, k, length(A.centers), length(C)) = (513, 216, 36, 36, 32)\n[ Info: using 32 random queries from the dataset\ncomputing farthest point 1, dmax: Inf, imax: 16, n: 172\ncomputing farthest point 2, dmax: 3.7887464, imax: 22, n: 172\ncomputing farthest point 3, dmax: 1.9140197, imax: 4, n: 172\ncomputing farthest point 4, dmax: 1.7988492, imax: 101, n: 172\ncomputing farthest point 5, dmax: 1.5327418, imax: 64, n: 172\ncomputing farthest point 6, dmax: 1.4871794, imax: 33, n: 172\ncomputing farthest point 7, dmax: 1.4807838, imax: 159, n: 172\ncomputing farthest point 8, dmax: 1.4417468, imax: 136, n: 172\ncomputing farthest point 9, dmax: 1.3102832, imax: 100, n: 172\ncomputing farthest point 10, dmax: 1.1919875, imax: 109, n: 172\ncomputing farthest point 11, dmax: 1.1184697, imax: 167, n: 172\ncomputing farthest point 12, dmax: 1.0664252, imax: 79, n: 172\ncomputing farthest point 13, dmax: 0.92027813, imax: 55, n: 172\ncomputing farthest point 14, dmax: 0.91349506, imax: 66, n: 172\ncomputing farthest point 15, dmax: 0.86564094, imax: 115, n: 172\ncomputing farthest point 16, dmax: 0.83629006, imax: 53, n: 172\ncomputing farthest point 17, dmax: 0.75365174, imax: 113, n: 172\ncomputing farthest point 18, dmax: 0.7529488, imax: 70, n: 172\ncomputing farthest point 19, dmax: 0.7194774, imax: 150, n: 172\ncomputing farthest point 20, dmax: 0.7169178, imax: 6, n: 172\ncomputing farthest point 21, dmax: 0.6541379, imax: 154, n: 172\ncomputing farthest point 22, dmax: 0.64790004, imax: 86, n: 172\ncomputing farthest point 23, dmax: 0.6473165, imax: 91, n: 172\ncomputing farthest point 24, dmax: 0.6438238, imax: 46, n: 172\ncomputing farthest point 25, dmax: 0.61353356, imax: 142, n: 172\ncomputing farthest point 26, dmax: 0.60014266, imax: 99, n: 172\ncomputing farthest point 27, dmax: 0.5818377, imax: 161, n: 172\ncomputing farthest point 28, dmax: 0.5551741, imax: 19, n: 172\ncomputing farthest point 29, dmax: 0.54581636, imax: 35, n: 172\ncomputing farthest point 30, dmax: 0.5301293, imax: 24, n: 172\ncomputing farthest point 31, dmax: 0.5186341, imax: 32, n: 172\ncomputing farthest point 32, dmax: 0.5180221, imax: 95, n: 172\ncomputing farthest point 33, dmax: 0.49686342, imax: 152, n: 172\ncomputing farthest point 34, dmax: 0.48940948, imax: 49, n: 172\ncomputing farthest point 35, dmax: 0.4677162, imax: 132, n: 172\ncomputing farthest point 36, dmax: 0.42519245, imax: 117, n: 172\ncomputing farthest point 37, dmax: 0.421064, imax: 63, n: 172\ncomputing farthest point 38, dmax: 0.4169775, imax: 165, n: 172\n(n, m, k, length(A.centers), length(C)) = (770, 235, 38, 38, 34)\n[ Info: using 32 random queries from the dataset\ncomputing farthest point 1, dmax: Inf, imax: 92, n: 187\ncomputing farthest point 2, dmax: 3.7251282, imax: 89, n: 187\ncomputing farthest point 3, dmax: 1.8172259, imax: 25, n: 187\ncomputing farthest point 4, dmax: 1.6521376, imax: 111, n: 187\ncomputing farthest point 5, dmax: 1.547313, imax: 162, n: 187\ncomputing farthest point 6, dmax: 1.4839215, imax: 153, n: 187\ncomputing farthest point 7, dmax: 1.347505, imax: 40, n: 187\ncomputing farthest point 8, dmax: 1.2894305, imax: 102, n: 187\ncomputing farthest point 9, dmax: 1.2813725, imax: 175, n: 187\ncomputing farthest point 10, dmax: 1.2733448, imax: 106, n: 187\ncomputing farthest point 11, dmax: 1.1018052, imax: 78, n: 187\ncomputing farthest point 12, dmax: 1.0599717, imax: 27, n: 187\ncomputing farthest point 13, dmax: 0.9225848, imax: 187, n: 187\ncomputing farthest point 14, dmax: 0.8804724, imax: 150, n: 187\ncomputing farthest point 15, dmax: 0.78911364, imax: 184, n: 187\ncomputing farthest point 16, dmax: 0.7773338, imax: 146, n: 187\ncomputing farthest point 17, dmax: 0.76996124, imax: 6, n: 187\ncomputing farthest point 18, dmax: 0.70446193, imax: 125, n: 187\ncomputing farthest point 19, dmax: 0.69819665, imax: 129, n: 187\ncomputing farthest point 20, dmax: 0.68887055, imax: 163, n: 187\ncomputing farthest point 21, dmax: 0.68304276, imax: 19, n: 187\ncomputing farthest point 22, dmax: 0.65774864, imax: 59, n: 187\ncomputing farthest point 23, dmax: 0.63491076, imax: 80, n: 187\ncomputing farthest point 24, dmax: 0.6217184, imax: 67, n: 187\ncomputing farthest point 25, dmax: 0.60838157, imax: 44, n: 187\ncomputing farthest point 26, dmax: 0.58522314, imax: 52, n: 187\ncomputing farthest point 27, dmax: 0.5583265, imax: 115, n: 187\ncomputing farthest point 28, dmax: 0.5512252, imax: 93, n: 187\ncomputing farthest point 29, dmax: 0.5377479, imax: 32, n: 187\ncomputing farthest point 30, dmax: 0.52359104, imax: 53, n: 187\ncomputing farthest point 31, dmax: 0.5048922, imax: 62, n: 187\ncomputing farthest point 32, dmax: 0.49204767, imax: 22, n: 187\ncomputing farthest point 33, dmax: 0.48676142, imax: 185, n: 187\ncomputing farthest point 34, dmax: 0.47781816, imax: 31, n: 187\ncomputing farthest point 35, dmax: 0.4739993, imax: 142, n: 187\ncomputing farthest point 36, dmax: 0.4638383, imax: 165, n: 187\ncomputing farthest point 37, dmax: 0.45496857, imax: 95, n: 187\ncomputing farthest point 38, dmax: 0.44374564, imax: 139, n: 187\ncomputing farthest point 39, dmax: 0.43240353, imax: 34, n: 187\n(n, m, k, length(A.centers), length(C)) = (1000, 244, 39, 39, 37)\n[ Info: using 32 random queries from the dataset\n[ Info: using 64 random queries from the dataset\n  0.146462 seconds (176.20 k allocations: 11.335 MiB, 99.70% compilation time)"
  },
  {
    "objectID": "demos/using-manifoldlearning.html#visualizing-prime-gaps",
    "href": "demos/using-manifoldlearning.html#visualizing-prime-gaps",
    "title": "Using with ManifoldLearning",
    "section": "Visualizing prime gaps",
    "text": "Visualizing prime gaps\nThe difference between contiguous prime numbers is called a Prime gap. We use this series of values as a time series example due to its interesting behavior and since it can be computed without downloading more than the necessary packages.\nThis example shows how to generate the dataset and index it. We will use the ManifoldLearning for generating the 2d visualization.\n\nGeneration of the dataset\nThe time series is represented with windows of size w, we also take log of gaps to reduce variance in gap values. We create a matrix to avoid redefinition of the knn interface for ManifoldLearning.\n\nfunction create_database_primes_diff(n, w)\n    T = log2.(diff(primes(n)))\n    M = Matrix{Float32}(undef, w, length(T) - w)\n    @info size(M)\n    for i in 1:size(M, 2)\n        M[:, i] .= view(T, i:(i+w-1))\n    end\n\n    M\nend\n\n\nx, y = let\n    P = create_database_primes_diff(3 * 10^4, 5)\n    # or LLE\n    primesgap = fit(Isomap, P; k=16, maxoutdim=2, nntype=ApproxEuclidean)\n    \n    p = predict(primesgap)\n    p[1, :], p[2, :]\nend\n\nA 2D histogram\n\nhistogram2d(x, y; nbins=100)"
  },
  {
    "objectID": "demos/using-manifoldlearning.html#environment-and-dependencies",
    "href": "demos/using-manifoldlearning.html#environment-and-dependencies",
    "title": "Using with ManifoldLearning",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.9\nCommit 5595d20a287 (2025-03-10 12:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 Ã Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_PROJECT = .\n  JULIA_NUM_THREADS = auto\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/sites/SimilaritySearchDemos/Project.toml`\n  [aaaa29a8] Clustering v0.15.8\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.7.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.0 `~/.julia/dev/InvertedFiles`\n  [682c06a0] JSON v0.21.4\n  [23fbe1c1] Latexify v0.16.6\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\nâ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.11\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.0 `~/.julia/dev/SimSearchManifoldLearning`\n  [053f045d] SimilaritySearch v0.12.0 `~/.julia/dev/SimilaritySearch`\nâ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.0 `~/.julia/dev/TextSearch`\nInfo Packages marked with â and â have new versions available. Those with â may be upgradable, but those with â are restricted by compatibility constraints from upgrading. To see why use `status --outdated`"
  },
  {
    "objectID": "demos/syn2d.html",
    "href": "demos/syn2d.html",
    "title": "Visualizing MNIST database",
    "section": "",
    "text": "by: Eric S. TÃ©llez\nThis demonstration shows in a 2D example the functionality of SearchGraph.\nusing SimilaritySearch, SimSearchManifoldLearning, Plots, StatsBase, LinearAlgebra, Markdown, Random\nn = 100_000\n\nM = randn(Float16, 2, n)\ndb = MatrixDatabase(M)\ndist = SqL2_asf32()\nsize(M)\nNow we can create the index\n1G = SearchGraph(; dist, db)\nctx = SearchGraphContext(hyperparameters_callback=OptimizeParameters(MinRecall(0.99)))\n2index!(G, ctx)\n3optimize_index!(G, ctx, MinRecall(0.9))\n\n\n1\n\nDefines the index and the search context (caches and hyperparameters); particularly, we use a very high quality build MinRecall(0.99); high quality constructions yield to faster queries due to the underlying graph structure.\n\n2\n\nActual indexing procedure using the given search context.\n\n3\n\nOptimizing the index to trade quality and speed."
  },
  {
    "objectID": "demos/syn2d.html#the-set-of-queries",
    "href": "demos/syn2d.html#the-set-of-queries",
    "title": "Visualizing MNIST database",
    "section": "The set of queries",
    "text": "The set of queries\nWe define a small set of queries being close to the border of the dataset and also in the most dense regions of the dataset.\n\nQ = [Float32[-2, -2], Float32[2, -2], Float32[-2, 0], Float32[-0, 2], Float32[0, 0],   Float32[-3, 3],  Float32[4, 4], Float32[1, 0.5]]\nI, D = searchbatch(G, ctx, VectorDatabase(Q), 30)\n\nPlease note how queries in low and high dense regions are located.\n\nscatter(view(M, 1, :), view(M, 2, :), fmt=:png, c=:cyan, ma=0.3, a=0.3, ms=1, msw=0)\n\nscatter!(getindex.(Q, 1), getindex.(Q, 2), c=:red, ma=0.7, a=0.7, ms=6, msw=0)\n\nfor c in eachcol(I)\n    X = M[:, c]\n    scatter!(view(X, 1, :), view(X, 2, :), c=:blue, ma=0.5, a=0.5, ms=2, msw=0)\n    #scatter!( c=:auto, ms=2)\nend\n\nplot!(legend=nothing)\n\nSince points are distributed in several regions with disparate density, their radii are also quite diverse. The next figure illustrates this effect."
  },
  {
    "objectID": "demos/syn2d.html#distribution-of-distances-for-the-set-of-queries",
    "href": "demos/syn2d.html#distribution-of-distances-for-the-set-of-queries",
    "title": "Visualizing MNIST database",
    "section": "Distribution of distances for the set of queries",
    "text": "Distribution of distances for the set of queries\n\nplot(D, m=:auto, yscale=:log10, title=\"knn distances for elements in Q\", fmt=:png)"
  },
  {
    "objectID": "demos/syn2d.html#environment-and-dependencies",
    "href": "demos/syn2d.html#environment-and-dependencies",
    "title": "Visualizing MNIST database",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.9\nCommit 5595d20a287 (2025-03-10 12:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 Ã Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_PROJECT = .\n  JULIA_NUM_THREADS = auto\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/sites/SimilaritySearchDemos/Project.toml`\n  [aaaa29a8] Clustering v0.15.8\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.7.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.0 `~/.julia/dev/InvertedFiles`\n  [682c06a0] JSON v0.21.4\n  [23fbe1c1] Latexify v0.16.6\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\nâ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.11\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.0 `~/.julia/dev/SimSearchManifoldLearning`\n  [053f045d] SimilaritySearch v0.12.0 `~/.julia/dev/SimilaritySearch`\nâ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.0 `~/.julia/dev/TextSearch`\nInfo Packages marked with â and â have new versions available. Those with â may be upgradable, but those with â are restricted by compatibility constraints from upgrading. To see why use `status --outdated`"
  },
  {
    "objectID": "demos/glove.html",
    "href": "demos/glove.html",
    "title": "Visualizing Twitter Messages with Emojis",
    "section": "",
    "text": "by: Eric S. TÃ©llez\nThis example creates a visualization of Glove word embeddings using Embeddings.jl package to fetch them.\nNote: This example needs a lot of computing power; therefore you may want to set the environment variable JULIA_NUM_THREADS=auto before running julia.\nusing SimilaritySearch, SimSearchManifoldLearning, TextSearch, CodecZlib, JSON, DataFrames, Plots, StatsBase, LinearAlgebra, Markdown, Embeddings, Random\nusing Downloads: download\nemb, vocab = let emb = load_embeddings(GloVe{:en}, 2)  # you can change with any of the available embeddings in `Embeddings`\n    for c in eachcol(emb.embeddings)\n1        normalize!(c)\n    end\n\n2    Float16.(emb.embeddings), emb.vocab\nend\n\n3dist = NormalizedCosine_asf32()\n4vocab2id = Dict(w =&gt; i for (i, w) in enumerate(vocab))\n\n\n1\n\nNormalizes all vectors to have a unitary norm; this allow us to use the dot product as similarity (see point 3)\n\n2\n\nThe speed can be improved through memoryâs bandwidth using less memory per vector; using Float16 as memory representation is a good idea even if your computer doesnât support 16-bit floating point arithmetic natively.\n\n3\n\nSince we have unitary norm vectors we can simplify the cosine distance (i.e., \\(1 - dot(\\cdot, \\cdot)\\)); note that we are using Float16 and the suffix _asf32 will select a distance function that converts numbers to Float32 just before performing arithmetic operations.\n\n4\n\nInverse map from words to identifiers in vocab.\nNow we can create the index\n1index = SearchGraph(; dist, db=MatrixDatabase(emb))\nctx = SearchGraphContext(hyperparameters_callback=OptimizeParameters(MinRecall(0.99)))\n2index!(index, ctx)\n3optimize_index!(index, ctx, MinRecall(0.9))\n\n\n1\n\nDefines the index and the search context (caches and hyperparameters); particularly, we use a very high quality build MinRecall(0.99); high quality constructions yield to faster queries due to the underlying graph structure.\n\n2\n\nActual indexing procedure using the given search context.\n\n3\n\nOptimizing the index to trade quality and speed."
  },
  {
    "objectID": "demos/glove.html#umap-visualization",
    "href": "demos/glove.html#umap-visualization",
    "title": "Visualizing Twitter Messages with Emojis",
    "section": "UMAP Visualization",
    "text": "UMAP Visualization\n\nfunction normcolors(V)\n    min_, max_ = extrema(V)\n    V .= (V .- min_) ./ (max_ - min_)\n    V .= clamp.(V, 0, 1)\nend\n\nnormcolors(@view e3[1, :])\nnormcolors(@view e3[2, :])\nnormcolors(@view e3[3, :])\n\nlet C = [RGB(c[1], c[2], c[3]) for c in eachcol(e3)],\n    X = view(e2, 1, :),\n    Y = view(e2, 2, :)\n    scatter(X, Y, color=C, fmt=:png, alpha=0.2, size=(600, 600), ma=0.3, ms=2, msw=0, label=\"\", yticks=nothing, xticks=nothing, xaxis=false, yaxis=false)\nend\n\nplot!()\n\n\n\n\n\ne2, e3 = let min_dist=0.5f0,\n             k=12,\n             n_epochs=75,\n             neg_sample_rate=3,\n             tol=1e-3,\n             layout=RandomLayout()\n\n    @time \"Compute 2D UMAP model\" U2 = fit(UMAP, index; k, neg_sample_rate, layout, n_epochs, tol, min_dist)\n    @time \"Compute 3D UMAP model\" U3 = fit(U2, 3; neg_sample_rate, n_epochs, tol)\n    @time \"predicting 2D embeddings\" e2 = clamp.(predict(U2), -10f0, 10f0)\n    @time \"predicting 3D embeddings\" e3 = clamp.(predict(U3), -10f0, 10f0)\n    e2, e3\nend"
  },
  {
    "objectID": "demos/glove.html#final-notes",
    "href": "demos/glove.html#final-notes",
    "title": "Visualizing Twitter Messages with Emojis",
    "section": "Final notes",
    "text": "Final notes\nThis example shows how to index and search dense vector databases, in particular GloVe word embeddings using the cosine distance. Low dimensional projections are made with SimSearchManifoldLearning, note that SimilaritySearch is also used for computing the all \\(k\\) nearest neighbors needed by the UMAP model. Note that this notebook should be ran with several threads to reduce time costs."
  },
  {
    "objectID": "demos/glove.html#environment-and-dependencies",
    "href": "demos/glove.html#environment-and-dependencies",
    "title": "Visualizing Twitter Messages with Emojis",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.9\nCommit 5595d20a287 (2025-03-10 12:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 Ã Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_PROJECT = .\n  JULIA_NUM_THREADS = auto\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/sites/SimilaritySearchDemos/Project.toml`\n  [aaaa29a8] Clustering v0.15.8\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.7.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.0 `~/.julia/dev/InvertedFiles`\n  [682c06a0] JSON v0.21.4\n  [23fbe1c1] Latexify v0.16.6\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\nâ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.11\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.0 `~/.julia/dev/SimSearchManifoldLearning`\n  [053f045d] SimilaritySearch v0.12.0 `~/.julia/dev/SimilaritySearch`\nâ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.0 `~/.julia/dev/TextSearch`\nInfo Packages marked with â and â have new versions available. Those with â may be upgradable, but those with â are restricted by compatibility constraints from upgrading. To see why use `status --outdated`"
  },
  {
    "objectID": "datasets.html",
    "href": "datasets.html",
    "title": "Datasets for Nearest Neighbor Search",
    "section": "",
    "text": "MNIST. Very used in vision tasks, pretty old and not very challenging. However it is very easy to use. From MNIST site, it corresponds to 60k 28x28 handwritten numbers. We use the MLDatasets.jl package to simplify downloading and loading it.\nWiktionary. Took from Wiktionary site, we select English terms from the english wiktionary.\nWIT-300K. From Clip and WIT, we downloaded the first 300K annotated images for the Spanish Wikipedia and take the Clip embeddings of them. Available from the demo subfolder.\nGlove. Very used as dataset in papers but not yet vigent with respect to state of the art methods in different Natural Language Processing tasks. From Glove site, it corresponds to the 100d, 6B tokens. We use the Embeddings.jl package to simplify downloading and loading it.\n\n\n\nThe versions used in the demonstrations are not splitted in train and test, but those used in the paper are splitted. If you want to reproduce the same results, please use the datasets by ann-benchmarks and its repo.\nFor WIT and Twitter-2M, please use the following HDF5 files, they follow a similar structure than those found in the ann-benchmarks.\n\nWIT-300K\nTwitter-2M. These word embeddings corresponds to that model labeled as ALL-2M in the Regional Spanish Models site, yet partitioned for using as similarity search benchmark."
  },
  {
    "objectID": "datasets.html#real-world",
    "href": "datasets.html#real-world",
    "title": "Datasets for Nearest Neighbor Search",
    "section": "",
    "text": "MNIST. Very used in vision tasks, pretty old and not very challenging. However it is very easy to use. From MNIST site, it corresponds to 60k 28x28 handwritten numbers. We use the MLDatasets.jl package to simplify downloading and loading it.\nWiktionary. Took from Wiktionary site, we select English terms from the english wiktionary.\nWIT-300K. From Clip and WIT, we downloaded the first 300K annotated images for the Spanish Wikipedia and take the Clip embeddings of them. Available from the demo subfolder.\nGlove. Very used as dataset in papers but not yet vigent with respect to state of the art methods in different Natural Language Processing tasks. From Glove site, it corresponds to the 100d, 6B tokens. We use the Embeddings.jl package to simplify downloading and loading it.\n\n\n\nThe versions used in the demonstrations are not splitted in train and test, but those used in the paper are splitted. If you want to reproduce the same results, please use the datasets by ann-benchmarks and its repo.\nFor WIT and Twitter-2M, please use the following HDF5 files, they follow a similar structure than those found in the ann-benchmarks.\n\nWIT-300K\nTwitter-2M. These word embeddings corresponds to that model labeled as ALL-2M in the Regional Spanish Models site, yet partitioned for using as similarity search benchmark."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This site is an effort to document and give comprehensive resources to use the SimilaritySearch.jl Julia package. The contributors are:\n\nEric S. TÃ©llez https://sadit.github.io/, SECIHTI-INFOTEC, Aguascalientes, MÃ©xico.\nGuillermo Ruiz, INFOTEC, Aguascalientes, MÃ©xico."
  },
  {
    "objectID": "demos/emojispace.html",
    "href": "demos/emojispace.html",
    "title": "Visualizing Twitter Messages with Emojis",
    "section": "",
    "text": "This example creates a vector space model for classify emojis in Twitter messages, then process and create vectors from messages and project them using a UMAP model. The projection uses the SimilaritySearch allknn operation.\nusing SimilaritySearch, SimSearchManifoldLearning, TextSearch, CodecZlib, JSON, DataFrames, Plots, StatsBase\nusing Downloads: download\ndownloading the dataset, parsing and vectorizing functions\nmkpath(\"tmp\")\ndbfile = \"tmp/emo50k.json.gz\"\nbaseurl = \"https://github.com/sadit/TextClassificationTutorial/raw/refs/heads/main/data/emo50k.json.gz\"\n!isfile(dbfile) && download(baseurl, dbfile)\n\nfalse\nNow, we load the dataset\nD = DataFrame(open(GzipDecompressorStream, dbfile) do f\n    JSON.parse.(eachline(f))\nend)\n\ncollect(countmap(D.klass))\n\n64-element Vector{Pair{String, Int64}}:\n \"â¨\" =&gt; 801\n \"ð¤¤\" =&gt; 771\n \"ð\" =&gt; 794\n \"ð¡\" =&gt; 776\n \"ð\" =&gt; 757\n \"ð¤£\" =&gt; 780\n \"ð\" =&gt; 779\n \"ð­\" =&gt; 785\n \"ð¤\" =&gt; 732\n \"ð\" =&gt; 774\n      â®\n \"ð\" =&gt; 748\n \"ð\" =&gt; 770\n \"ð\" =&gt; 786\n \"ð\" =&gt; 815\n \"ð\" =&gt; 772\n \"ð\" =&gt; 747\n \"ð\" =&gt; 812\n \"ð\" =&gt; 782\n \"ð³\" =&gt; 839\nD = filter(D) do r\n    r.klass in (\"ð­\", \"ð¤£\", \"ð\", \"ð¤\")\nend\n\ncollect(countmap(D.klass))\n#H = sort!(collect(countmap(D.klass)), by=first)\n#bar(first.(H), last.(H))\n\n4-element Vector{Pair{String, Int64}}:\n \"ð¤£\" =&gt; 780\n \"ð¤\" =&gt; 808\n \"ð­\" =&gt; 785\n \"ð\" =&gt; 816\nFunctions create to encode texto into bag-of-word vectors\ntextconfig = TextConfig(\n    group_usr=true,\n    group_url=true,\n    del_diac=true,\n    lc=true,\n    group_num=true,\n    nlist=[1],\n    qlist=[3])\n\n# corpus here can be a sample to avoid double parsing\nvoc = Vocabulary(textconfig, D.text) \n# model = VectorModel(IdfWeighting(), TfWeighting(), voc)\nmodel = VectorModel(EntropyWeighting(), BinaryLocalWeighting(), voc, D.text, D.klass; smooth=1.0)\n#model = VectorModel(IdfWeighting(), TfWeighting(), voc)\nmodel = filter_tokens(model) do t\n    t.weight &gt;= 0.075\nend\nvectors = vectorize_corpus(model, D.text)"
  },
  {
    "objectID": "demos/emojispace.html#umap-projections",
    "href": "demos/emojispace.html#umap-projections",
    "title": "Visualizing Twitter Messages with Emojis",
    "section": "UMAP projections",
    "text": "UMAP projections\nUMAP projection can take a while, even on multithreading systems. Note that we are creating 2d and 3d projections.\n\n1e2, e3 = let min_dist=0.5f0,\n             k=16,\n             n_epochs=75,\n             neg_sample_rate=3,\n             tol=1e-3,\n             layout=SpectralLayout(),\n             indexsize=768,\n             dist=NormalizedCosineDistance()\n\n    index = ExhaustiveSearch(; db=rand(vectors, indexsize), dist)\n    @time U2 = fit(UMAP, index; k, neg_sample_rate, layout, n_epochs, tol, min_dist)\n    @time U3 = fit(U2, 3; neg_sample_rate, n_epochs, tol)\n    @time e2 = clamp.(predict(U2, vectors), -10f0, 10f0)\n    @time e3 = clamp.(predict(U3, vectors), -10f0, 10f0)\n    e2, e3\nend\n\n\n1\n\nThe UMAP algorithm has a lot of hyperparameters; min_dist controls the distance between projected points, k is the number of neighbors to be used in the underlying \\(k\\)nn graph, n_epochs the number of epochs used to optimize the projection, neg_sample_rate means for the number of negative examples used in the optimization process, tol the tolerance to converge, layout"
  },
  {
    "objectID": "demos/emojispace.html#visualizations",
    "href": "demos/emojispace.html#visualizations",
    "title": "Visualizing Twitter Messages with Emojis",
    "section": "Visualizations",
    "text": "Visualizations\n\nfunction normcolors(V)\n    min_, max_ = extrema(V)\n    V .= (V .- min_) ./ (max_ - min_)\n    V .= clamp.(V, 0, 1)\nend\n\nnormcolors(@view e3[1, :])\nnormcolors(@view e3[2, :])\nnormcolors(@view e3[3, :])\n\nC = [RGB(c[1], c[2], c[3]) for c in eachcol(e3)]\n\nX = @view e2[1, :]\nY = @view e2[2, :]\nscatter(X, Y, color=C, markersize=4, alpha=0.5)\n\nfor i in 1:100\n    j = rand(1:length(D.klass))\n    annotate!(X[j], Y[j], text(D.klass[j], :blue, :right, 8, \"noto\"))\nend\n\nplot!()\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nð­\n\n\nð­\n\n\nð¤\n\n\nð\n\n\nð\n\n\nð¤\n\n\nð\n\n\nð¤£\n\n\nð­\n\n\nð\n\n\nð­\n\n\nð¤\n\n\nð¤£\n\n\nð­\n\n\nð­\n\n\nð¤\n\n\nð¤\n\n\nð¤£\n\n\nð¤£\n\n\nð\n\n\nð¤\n\n\nð¤£\n\n\nð¤\n\n\nð¤£\n\n\nð¤\n\n\nð¤£\n\n\nð¤\n\n\nð¤£\n\n\nð­\n\n\nð¤\n\n\nð­\n\n\nð­\n\n\nð¤\n\n\nð\n\n\nð¤\n\n\nð¤\n\n\nð¤£\n\n\nð¤£\n\n\nð¤\n\n\nð¤£\n\n\nð\n\n\nð­\n\n\nð¤£\n\n\nð\n\n\nð\n\n\nð\n\n\nð­\n\n\nð\n\n\nð­\n\n\nð\n\n\nð\n\n\nð¤\n\n\nð­\n\n\nð\n\n\nð¤£\n\n\nð¤\n\n\nð­\n\n\nð¤\n\n\nð­\n\n\nð¤\n\n\nð­\n\n\nð­\n\n\nð\n\n\nð\n\n\nð¤£\n\n\nð\n\n\nð\n\n\nð¤\n\n\nð¤£\n\n\nð\n\n\nð\n\n\nð¤\n\n\nð\n\n\nð¤\n\n\nð¤£\n\n\nð¤£\n\n\nð¤£\n\n\nð¤£\n\n\nð¤£\n\n\nð¤£\n\n\nð\n\n\nð¤£\n\n\nð¤£\n\n\nð\n\n\nð¤\n\n\nð­\n\n\nð¤\n\n\nð¤£\n\n\nð­\n\n\nð¤£\n\n\nð¤£\n\n\nð¤£\n\n\nð¤\n\n\nð­\n\n\nð¤£\n\n\nð\n\n\nð¤£\n\n\nð¤£\n\n\nð\n\n\nð"
  },
  {
    "objectID": "demos/emojispace.html#environment-and-dependencies",
    "href": "demos/emojispace.html#environment-and-dependencies",
    "title": "Visualizing Twitter Messages with Emojis",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.9\nCommit 5595d20a287 (2025-03-10 12:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 Ã Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_PROJECT = .\n  JULIA_NUM_THREADS = auto\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/sites/SimilaritySearchDemos/Project.toml`\n  [aaaa29a8] Clustering v0.15.8\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.7.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.0 `~/.julia/dev/InvertedFiles`\n  [682c06a0] JSON v0.21.4\n  [23fbe1c1] Latexify v0.16.6\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\nâ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.11\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.0 `~/.julia/dev/SimSearchManifoldLearning`\n  [053f045d] SimilaritySearch v0.12.0 `~/.julia/dev/SimilaritySearch`\nâ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.0 `~/.julia/dev/TextSearch`\nInfo Packages marked with â and â have new versions available. Those with â may be upgradable, but those with â are restricted by compatibility constraints from upgrading. To see why use `status --outdated`"
  },
  {
    "objectID": "demos/mnist.html",
    "href": "demos/mnist.html",
    "title": "Visualizing MNIST database",
    "section": "",
    "text": "by: Eric S. TÃ©llez\nThis example creates a visualization of the MNIST images (hand written digits) using MLDatasets.jl to retrieve it.\nNote: This example needs a lot of computing power; therefore you may want to set the environment variable JULIA_NUM_THREADS=auto before running julia.\nusing SimilaritySearch, SimSearchManifoldLearning, Plots, StatsBase, LinearAlgebra, Markdown, MLDatasets, Random\ndb, y, dist = let data = MNIST(split=:train)\n    T, y = data.features, data.targets\n    n = size(T, 3)\n    MatrixDatabase(Float32.(reshape(T, (28*28, n)))), y, SqL2_asf32()\nend\nNow we can create the index\n1index = SearchGraph(; dist, db)\nctx = SearchGraphContext(hyperparameters_callback=OptimizeParameters(MinRecall(0.99)))\n2index!(index, ctx)\n3optimize_index!(index, ctx, MinRecall(0.95))\n\n\n1\n\nDefines the index and the search context (caches and hyperparameters); particularly, we use a very high quality build MinRecall(0.99); high quality constructions yield to faster queries due to the underlying graph structure.\n\n2\n\nActual indexing procedure using the given search context.\n\n3\n\nOptimizing the index to trade quality and speed."
  },
  {
    "objectID": "demos/mnist.html#umap-visualization",
    "href": "demos/mnist.html#umap-visualization",
    "title": "Visualizing MNIST database",
    "section": "UMAP Visualization",
    "text": "UMAP Visualization\n\nfunction normcolors(V)\n    min_, max_ = extrema(V)\n    V .= (V .- min_) ./ (max_ - min_)\n    V .= clamp.(V, 0, 1)\nend\n\nnormcolors(@view e3[1, :])\nnormcolors(@view e3[2, :])\nnormcolors(@view e3[3, :])\n\nlet C = [RGB(c[1], c[2], c[3]) for c in eachcol(e3)],\n    X = view(e2, 1, :),\n    Y = view(e2, 2, :)\n    scatter(X, Y, color=C, fmt=:png, alpha=0.2, size=(600, 600), ma=0.3, ms=2, msw=0, label=\"\", yticks=nothing, xticks=nothing, xaxis=false, yaxis=false)\n    for i in 1:100\n        j = rand(1:length(y))\n        annotate!(X[j], Y[j], text(y[j], :black, :right, 8, \"noto\"))\n    end\nend\n\nplot!()\n\n\n\n\n\ne2, e3 = let min_dist=0.5f0,\n             k=7,\n             n_epochs=75,\n             neg_sample_rate=3,\n             tol=1e-3,\n             layout=SpectralLayout()\n\n    @time \"Compute 2D UMAP model\" U2 = fit(UMAP, index; k, neg_sample_rate, layout, n_epochs, tol, min_dist)\n    @time \"Compute 3D UMAP model\" U3 = fit(U2, 3; neg_sample_rate, n_epochs, tol)\n    @time \"predicting 2D embeddings\" e2 = clamp.(predict(U2), -10f0, 10f0)\n    @time \"predicting 3D embeddings\" e3 = clamp.(predict(U3), -10f0, 10f0)\n    e2, e3\nend"
  },
  {
    "objectID": "demos/mnist.html#final-notes",
    "href": "demos/mnist.html#final-notes",
    "title": "Visualizing MNIST database",
    "section": "Final notes",
    "text": "Final notes\nThis example shows how to index and visualize the MNIST dataset using UMAP low dimensional projections. Low dimensional projections are made with SimSearchManifoldLearning, note that SimilaritySearch is also used for computing the all \\(k\\) nearest neighbors needed by the UMAP model. Note that this notebook should be ran with several threads to reduce time costs."
  },
  {
    "objectID": "demos/mnist.html#environment-and-dependencies",
    "href": "demos/mnist.html#environment-and-dependencies",
    "title": "Visualizing MNIST database",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.9\nCommit 5595d20a287 (2025-03-10 12:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 Ã Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_PROJECT = .\n  JULIA_NUM_THREADS = auto\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/sites/SimilaritySearchDemos/Project.toml`\n  [aaaa29a8] Clustering v0.15.8\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.7.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.0 `~/.julia/dev/InvertedFiles`\n  [682c06a0] JSON v0.21.4\n  [23fbe1c1] Latexify v0.16.6\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\nâ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.11\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.0 `~/.julia/dev/SimSearchManifoldLearning`\n  [053f045d] SimilaritySearch v0.12.0 `~/.julia/dev/SimilaritySearch`\nâ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.0 `~/.julia/dev/TextSearch`\nInfo Packages marked with â and â have new versions available. Those with â may be upgradable, but those with â are restricted by compatibility constraints from upgrading. To see why use `status --outdated`"
  },
  {
    "objectID": "demos/primes.html",
    "href": "demos/primes.html",
    "title": "Prime numbers",
    "section": "",
    "text": "by: Eric S. TÃ©llez\nThis demonstration is about prime numbers and its similarity based on its factors. This is a well-known demonstration of SimSearchManifoldLearning.jl. This notebook does not requires to download any dataset.\nNote: This example needs a lot of computing power; therefore you may want to set the environment variable JULIA_NUM_THREADS=auto before running julia.\nusing SimilaritySearch, SimSearchManifoldLearning, Primes, Plots, StatsBase, LinearAlgebra, Markdown, Random\nNow, we can define our dataset. The set of factors are found using the Primes package. Note that we use VectorDatabase to represent the dataset.\nn = 100_000\nF = Vector{Vector{Int32}}(undef, n+1)\n\nfunction encode_factors(num)\n    sort!(Int32[convert(Int32, f) for f in factor(Set, num)])\nend\n\nF[1] = Int32[1]\n\nfor i in 2:n+1\n    s = encode_factors(i)\n    F[i] = s\nend\n\ndb = VectorDatabase(F)\n#dist = JaccardDistance()  # Other distances from SimilaritySearch\n#dist = IntersectionDissimilarity()\n#dist = CosineDistanceSet()\ndist = DiceDistance()\nWe use Int32 ordered arrays to store prime factors to represent each integer. In the following cell define the cosine distance equivalent for this representation. While other representations may perform faster, this is quite straighforward and demonstrates the use of userâs defined distance functions."
  },
  {
    "objectID": "demos/primes.html#index-construction",
    "href": "demos/primes.html#index-construction",
    "title": "Prime numbers",
    "section": "Index construction",
    "text": "Index construction\nNote that the primes factors are pretty large for some large \\(n\\) and this imply challengues for metric indexes (since it is related with the intrinsic dimension of the dataset). We used a kernel that starts 64 threads, it solves \\(100000\\) in a few seconds but it can take pretty large time using single threads and larger \\(n\\) values. The construction of the index is used by the visualization algorithm (UMAP) to construct an all-knn graph, which can be a quite costly procedure.\n\nG = SearchGraph(; db, dist)\n1ctx = SearchGraphContext(hyperparameters_callback=OptimizeParameters(MinRecall(0.95)))\n2index!(G, ctx)\n3optimize_index!(G, ctx, MinRecall(0.9))\n\n\n1\n\nDefines the index and the search context (caches and hyperparameters); particularly, we use a very high quality build MinRecall(0.95); high quality constructions yield to faster queries due to the underlying graph structure.\n\n2\n\nActual indexing procedure using the given search context.\n\n3\n\nOptimizing the index to trade quality and speed."
  },
  {
    "objectID": "demos/primes.html#visualizing-with-umap-projection",
    "href": "demos/primes.html#visualizing-with-umap-projection",
    "title": "Prime numbers",
    "section": "Visualizing with UMAP projection",
    "text": "Visualizing with UMAP projection\nWe select to initialize the embedding randomly, this could yield to low quality embeddings, but it is much faster than other techniques like spectral layout. Note that we pass the Search graph G. We also use a second call to compute a 3D embedding for computing a kind of colour embedding, here we pass U2 to avoid recomputing several of the involved structures.\n\nfunction normcolors(V)\n    min_, max_ = extrema(V)\n    V .= (V .- min_) ./ (max_ - min_)\n    V .= clamp.(V, 0, 1)\nend\n\nnormcolors(@view e3[1, :])\nnormcolors(@view e3[2, :])\nnormcolors(@view e3[3, :])\n\nlet C = [RGB(c[1], c[2], c[3]) for c in eachcol(e3)],\n    X = view(e2, 1, :),\n    Y = view(e2, 2, :)\n    scatter(X, Y, color=C, fmt=:png, alpha=0.2, size=(600, 600), ma=0.3, ms=2, msw=0, label=\"\", yticks=nothing, xticks=nothing, xaxis=false, yaxis=false)\nend\n\nplot!()\n\n\n\n\n\ne2, e3 = let min_dist=0.5f0,\n             k=20,\n             n_epochs=75,\n             neg_sample_rate=3,\n             tol=1e-3,\n             layout=SpectralLayout()\n\n    @time \"Compute 2D UMAP model\" U2 = fit(UMAP, G; k, neg_sample_rate, layout, n_epochs, tol, min_dist)\n    @time \"Compute 3D UMAP model\" U3 = fit(U2, 3; neg_sample_rate, n_epochs, tol)\n    @time \"predicting 2D embeddings\" e2 = clamp.(predict(U2), -10f0, 10f0)\n    @time \"predicting 3D embeddings\" e3 = clamp.(predict(U3), -10f0, 10f0)\n    e2, e3\nend"
  },
  {
    "objectID": "demos/primes.html#environment-and-dependencies",
    "href": "demos/primes.html#environment-and-dependencies",
    "title": "Prime numbers",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.9\nCommit 5595d20a287 (2025-03-10 12:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 Ã Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_PROJECT = .\n  JULIA_NUM_THREADS = auto\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/sites/SimilaritySearchDemos/Project.toml`\n  [aaaa29a8] Clustering v0.15.8\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.7.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.0 `~/.julia/dev/InvertedFiles`\n  [682c06a0] JSON v0.21.4\n  [23fbe1c1] Latexify v0.16.6\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\nâ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.11\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.0 `~/.julia/dev/SimSearchManifoldLearning`\n  [053f045d] SimilaritySearch v0.12.0 `~/.julia/dev/SimilaritySearch`\nâ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.0 `~/.julia/dev/TextSearch`\nInfo Packages marked with â and â have new versions available. Those with â may be upgradable, but those with â are restricted by compatibility constraints from upgrading. To see why use `status --outdated`"
  },
  {
    "objectID": "demos/index.html",
    "href": "demos/index.html",
    "title": "Tutorials",
    "section": "",
    "text": "We separate the examples by the kind of data, since some of the datasets are quite large and will require a lot of computer power. We also list how to connect SimilaritySearch with other packages that require solving k nearest neighbor queries.\n\n\n\n2d example\n\n\n\n\n\nPrime factors\nManifoldLearning â scurve and prime gaps\n\n\n\n\n\nGlove embeddings\nEmoji space\nPodcast collection\n\n\n\n\n\nMNIST"
  },
  {
    "objectID": "demos/index.html#list-of-examples",
    "href": "demos/index.html#list-of-examples",
    "title": "Tutorials",
    "section": "",
    "text": "We separate the examples by the kind of data, since some of the datasets are quite large and will require a lot of computer power. We also list how to connect SimilaritySearch with other packages that require solving k nearest neighbor queries.\n\n\n\n2d example\n\n\n\n\n\nPrime factors\nManifoldLearning â scurve and prime gaps\n\n\n\n\n\nGlove embeddings\nEmoji space\nPodcast collection\n\n\n\n\n\nMNIST"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tutorials and Examples for the SimilaritySearch.jl package",
    "section": "",
    "text": "Here you will find several examples for the SimilaritySearch.jl package."
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "Tutorials and Examples for the SimilaritySearch.jl package",
    "section": "Installation",
    "text": "Installation\nYou need a Julia installation https://julialang.org/downloads/, in particular, we recommend to use Julia \\(v1.10\\) since \\(v1.11\\) has several performance regressions with respect to SimilaritySearch.\nWe present our examples just to copy and paste on the REPL but also provide some in Jupyter and Pluto notebooks; you must install IJulia and Pluto packages, just run the following commands in the REPL\nusing Pkg; Pkg.add([\"IJulia\", \"Pluto\"])\nPlease check their documentation:\n\nIJulia.\nJupyter.\nPluto\n\nThis website was made with Quarto with the Julia engine."
  },
  {
    "objectID": "index.html#notes-about-multithreading",
    "href": "index.html#notes-about-multithreading",
    "title": "Tutorials and Examples for the SimilaritySearch.jl package",
    "section": "Notes about multithreading",
    "text": "Notes about multithreading\nNearest neighbor search can be computationally expensive, therefore SimilaritySearch has multithreading support. You should want to run jupyter or julia using all available threads, that is\nJULIA_NUM_THREADS=auto jupyter-lab .\nor\nJULIA_NUM_THREADS=auto julia\nPerhaps all your threads may become your computer useless for a while, so you can replace auto by some other more conservative number that allow you to work on the same computer."
  },
  {
    "objectID": "index.html#news",
    "href": "index.html#news",
    "title": "Tutorials and Examples for the SimilaritySearch.jl package",
    "section": "News",
    "text": "News\n\nmarch 20th, 2025: the site is behind the SimilaritySearch API; I will be working on updating examples and moving the site to Quarto.\njune 5th, 2023: adds news section, some installation requirements, Jupyter notebookes were updated to work with the v0.10 and with the current julia release v1.9. I also moved most plots to Makie."
  },
  {
    "objectID": "index.html#problem-statement",
    "href": "index.html#problem-statement",
    "title": "Tutorials and Examples for the SimilaritySearch.jl package",
    "section": "Problem statement",
    "text": "Problem statement\nGiven a finite dataset, \\(S \\subseteq U\\) where \\(n = |S|\\), and a metric distance function \\(d\\) working with any pair of elements in \\(U\\), the similarity search problem consists on retrieving similar items to a given query \\(q\\), for example, the \\(k\\) most similar items to \\(q\\) in \\(S\\) (\\(k\\) nearest neighbors).\nAt first glance, the problem is simple since it can be solved using an exhaustive evaluation of all possible results \\(d(u_1, q), \\cdots, d(u_n, q)\\) (that is, for all \\(u_i \\in S\\)) and select those \\(k\\) items \\(\\{u_i\\}\\) having the least distance to \\(q\\). This solution is impractical when \\(n\\) is large or when the number of expected queries is high. In these cases, it is necessary to create a data structure that preprocess the dataset and reduce the cost of solving queries, it is often called a metric index. When the dataset is pretty large or the metric space is quite complex, sometimes we can loose the ability of retrieving the exact solution to gain speed, clearly, the approximation quality becomes a major concern and these approximate methods require a lot of knowledge to trade speed retrieval process also kept high the solutionâs quality. Additionally, the amount of memory used by the index and the construction time are also concerns whenever \\(n\\) is big.\nThe SearchGraph index in the SimilaritySearch.jl package is a competitive alternative for solving search queries that automatically tune search speed and quality and also remains very competitive in memory and construction costs. Here we show some demostrations of how using SimilaritySearch.jl in several synthetic and real problems."
  },
  {
    "objectID": "tutorials/automatic-hyperparameter-opt.html",
    "href": "tutorials/automatic-hyperparameter-opt.html",
    "title": "Automatic Hyperparameter Optimization",
    "section": "",
    "text": "by: Eric S. TÃ©llez\nThis example optimizes different kinds of optimizations that allow different tradeoffs\n\nusing SimilaritySearch, Markdown\n\n1dim = 16\n2db = MatrixDatabase(rand(Float32, dim, 10^5))\n3queries = MatrixDatabase(rand(Float32, dim, 10^3))\n4dist = SqL2Distance()\n5k = 12\n\n\n1\n\nThe dimension to use in the synthetic data\n\n2\n\nThe synthetic database\n\n3\n\nThe synthetic queries\n\n4\n\nThe distance function; we will use the squared L2, which preserves the order of L2 but is faster to compute.\n\n5\n\nThe number of neighbors to retrieve"
  },
  {
    "objectID": "tutorials/automatic-hyperparameter-opt.html#automatic-hyperparameter-optimization",
    "href": "tutorials/automatic-hyperparameter-opt.html#automatic-hyperparameter-optimization",
    "title": "Automatic Hyperparameter Optimization",
    "section": "",
    "text": "by: Eric S. TÃ©llez\nThis example optimizes different kinds of optimizations that allow different tradeoffs\n\nusing SimilaritySearch, Markdown\n\n1dim = 16\n2db = MatrixDatabase(rand(Float32, dim, 10^5))\n3queries = MatrixDatabase(rand(Float32, dim, 10^3))\n4dist = SqL2Distance()\n5k = 12\n\n\n1\n\nThe dimension to use in the synthetic data\n\n2\n\nThe synthetic database\n\n3\n\nThe synthetic queries\n\n4\n\nThe distance function; we will use the squared L2, which preserves the order of L2 but is faster to compute.\n\n5\n\nThe number of neighbors to retrieve"
  },
  {
    "objectID": "tutorials/automatic-hyperparameter-opt.html#computing-ground-truth",
    "href": "tutorials/automatic-hyperparameter-opt.html#computing-ground-truth",
    "title": "Automatic Hyperparameter Optimization",
    "section": "Computing ground truth",
    "text": "Computing ground truth\nWe will generate a ground truth with an exhaustive method.\n\ngoldI, goldD = searchbatch(ExhaustiveSearch(; db, dist), GenericContext(), queries, k)"
  },
  {
    "objectID": "tutorials/automatic-hyperparameter-opt.html#different-hyperparameter-optimization-strategies",
    "href": "tutorials/automatic-hyperparameter-opt.html#different-hyperparameter-optimization-strategies",
    "title": "Automatic Hyperparameter Optimization",
    "section": "Different hyperparameter optimization strategies",
    "text": "Different hyperparameter optimization strategies\nThe way of specifying the hyperparameter optimization strategy and objective is with a SearchGraphContext object, as follows:\n\nG1 = SearchGraph(; dist, db)\nC1 = SearchGraphContext(hyperparameters_callback=OptimizeParameters(MinRecall(0.99)))\nbuildtime1 = @elapsed index!(G1, C1)\n\nThe previous construction optimizes the construction to have a very high recall, which can be very costly but also produces a high quality index.\n\nG2 = SearchGraph(; dist, db)\nC2 = SearchGraphContext(hyperparameters_callback=OptimizeParameters(MinRecall(0.9)))\nbuildtime2 = @elapsed index!(G2, C2)\n\nsearch, searchbatch, index!, append_items!, and push_item! accept context arguments."
  },
  {
    "objectID": "tutorials/automatic-hyperparameter-opt.html#performances",
    "href": "tutorials/automatic-hyperparameter-opt.html#performances",
    "title": "Automatic Hyperparameter Optimization",
    "section": "Performances",
    "text": "Performances\nsearching times\n\ntime1 = @elapsed I1, D1 = searchbatch(G1, C1, queries, k)\ntime2 = @elapsed I2, D2 = searchbatch(G2, C2, queries, k)\nrecall1 = macrorecall(goldI, I1)\nrecall2 = macrorecall(goldI, I2)\n\nthe recall is an score value between 0 to 1 where values close to 1 indicate better qualities.\n\n\nbuild time:\n\nbuildtime1: 5.648114106\n\nbuildtime2: 0.523501032\n\n\nsearch time:\n\ntime1: 0.002314346\n\ntime2: 0.001370323\n\n\nrecall values:\n\nrecall1: 0.96783333333333\n\nrecall2: 0.8649999999999989\n\n\n\n\n\nhere we can see smaller recalls than expected, and this is an effect of the difference between indexed elements (that are those objects used to perform the hyperparameter optimization). In any case, we 1can appreciate the differences among them, showing that high quality constructions may produce faster indexes; this is a consequence of the quality of the underlying structure. Contrary to this example, in higher dimensions or large datasets, we will obtain much higher construction times for high quality constructions."
  },
  {
    "objectID": "tutorials/automatic-hyperparameter-opt.html#optimizing-an-already-created-searchgraph-for-achieving-a-desired-quality",
    "href": "tutorials/automatic-hyperparameter-opt.html#optimizing-an-already-created-searchgraph-for-achieving-a-desired-quality",
    "title": "Automatic Hyperparameter Optimization",
    "section": "Optimizing an already created SearchGraph for achieving a desired quality",
    "text": "Optimizing an already created SearchGraph for achieving a desired quality\nThe hyperparameter optimization is performed in exponential stages while the SearchGraph is created; and therefore, the current hyperparameters could need an update. To optimize an already created SearchGraph we use optimize instead of index\nContext objects are special for construction since they encapsulate several hyperparameters; for searching it contains also caches but it can be shared among indexes; however, if the indexes have different sizes or you expect very different queries, it is better to maintain different context.\n\noptimize_index!(G1, C1, MinRecall(0.9))\noptimize_index!(G2, C1, MinRecall(0.9))\n\nafter optimizing the index its quality and speed are changed\n\ntime1 = @elapsed I1, D1 = searchbatch(G1, C1, queries, k)\ntime2 = @elapsed I2, D2 = searchbatch(G2, C1, queries, k)\n\nrecall1 = macrorecall(goldI, I1)\nrecall2 = macrorecall(goldI, I2)\n\nThese results on the following performances:\n\n\nbuild time:\n\nbuildtime1: 5.648114106\n\nbuildtime2: 0.523501032\n\n\nsearch time:\n\ntime1: 0.001014245\n\ntime2: 0.000905641\n\n\nrecall values:\n\nrecall1: 0.6443333333333329\n\nrecall2: 0.7148333333333333\n\n\n\n\n\nPlease note that faster searches are expected for indexes created for higher qualities; but the construction must be paid. Note that recall values are lower than expected, as we explained, due to differences in the distributions (more precisely between points already seen and not seen points)."
  },
  {
    "objectID": "tutorials/automatic-hyperparameter-opt.html#giving-more-realistic-queries-for-optimization",
    "href": "tutorials/automatic-hyperparameter-opt.html#giving-more-realistic-queries-for-optimization",
    "title": "Automatic Hyperparameter Optimization",
    "section": "Giving more realistic queries for optimization",
    "text": "Giving more realistic queries for optimization\nThe default optimization parameters use objects already indexed to tune the hyperparameters, which is too optimistic in real applications, since already indexed objects are particularly easy for this use. We can get a better optimization using external data:\n\noptqueries = MatrixDatabase(rand(Float32, dim, 64))\n\noptimize_index!(G1, C1, MinRecall(0.9); queries=optqueries)\noptimize_index!(G2, C1, MinRecall(0.9); queries=optqueries)\n\nafter optimizing the index its quality and speed are changed\n\ntime1 = @elapsed I1, D1 = searchbatch(G1, C1, queries, k)\ntime2 = @elapsed I2, D2 = searchbatch(G2, C1, queries, k)\n\nrecall1 = macrorecall(goldI, I1)\nrecall2 = macrorecall(goldI, I2)\n\nThese results on the following performances:\n\n\nbuild time:\n\nbuildtime1: 5.648114106\n\nbuildtime2: 0.523501032\n\n\nsearch time:\n\ntime1: 0.013517147\n\ntime2: 0.010678581\n\n\nrecall values:\n\nrecall1: 0.9045833333333309\n\nrecall2: 0.9097499999999987\n\n\n\n\n\nThese scores are much closer to those we are looking for.\nBe careful on doing optimize_index!(..., queries=queries) since this can yield to overfitting on your query set."
  },
  {
    "objectID": "tutorials/automatic-hyperparameter-opt.html#environment-and-dependencies",
    "href": "tutorials/automatic-hyperparameter-opt.html#environment-and-dependencies",
    "title": "Automatic Hyperparameter Optimization",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.9\nCommit 5595d20a287 (2025-03-10 12:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 Ã Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_PROJECT = .\n  JULIA_NUM_THREADS = auto\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/sites/SimilaritySearchDemos/Project.toml`\n  [aaaa29a8] Clustering v0.15.8\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.7.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.0 `~/.julia/dev/InvertedFiles`\n  [682c06a0] JSON v0.21.4\n  [23fbe1c1] Latexify v0.16.6\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\nâ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.11\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.0 `~/.julia/dev/SimSearchManifoldLearning`\n  [053f045d] SimilaritySearch v0.12.0 `~/.julia/dev/SimilaritySearch`\nâ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.0 `~/.julia/dev/TextSearch`\nInfo Packages marked with â and â have new versions available. Those with â may be upgradable, but those with â are restricted by compatibility constraints from upgrading. To see why use `status --outdated`"
  },
  {
    "objectID": "tutorials/incremental-construction.html",
    "href": "tutorials/incremental-construction.html",
    "title": "Incremental construction with SearchGraph",
    "section": "",
    "text": "by: Eric S. TÃ©llez\nusing SimilaritySearch\nFor incremental construction we need a database backend that supports incremental insertions. Currently, there are two backends for this: DynamicMatrixDatabase and VectorDatabase:\ndim = 8\ndb = DynamicMatrixDatabase(Float32, dim) # or VectorDatabase(Vector{Float32})\ndist = L1Distance()\nit can use any distance function described in SimilaritySearch and Distances.jl, and in fact any SemiMetric as described in the later package. The index construction is made as follows:\nG = SearchGraph(; dist, db)\nctx = SearchGraphContext()\ninstead of index! we can use push_item! and append_items! functions\nfor _ in 1:10^4\n    push_item!(G, ctx, rand(Float32, dim))  # push_item! inserts one item at a time\nend\nwe can also use append_items! if we have a batch of items\nappend_items!(G, ctx, MatrixDatabase(rand(Float32, dim, 10^4))) # append_items! inserts many items at once\nNote that we used a MatrixDatabase to wrap the matrix to be inserted since it will be copied into the index. Now we have a populated index.\n@assert length(G) == 20_000\nthis will display a lot of information in the console, since as construction advances the hyperparameters of the index are adjusted.\nOnce the index is created, the index can solve nearest neighbor queries\n1Q = MatrixDatabase(rand(dim, 30))\n2k = 5\n3I, D = searchbatch(G, ctx, Q, k)\ndisplay((typeof(I), typeof(D)))\ndisplay((size(I), size(D)))\n\n\n1\n\nCreates the query\n\n2\n\nThe number of nearest neighbors to retrieve\n\n3\n\nSolve queries, returns neighbor identifiers and distances.\n\n\n\n\n(Matrix{Int32}, Matrix{Float32})\n\n\n((5, 30), (5, 30))"
  },
  {
    "objectID": "tutorials/incremental-construction.html#environment-and-dependencies",
    "href": "tutorials/incremental-construction.html#environment-and-dependencies",
    "title": "Incremental construction with SearchGraph",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.9\nCommit 5595d20a287 (2025-03-10 12:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 Ã Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_PROJECT = .\n  JULIA_NUM_THREADS = auto\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/sites/SimilaritySearchDemos/Project.toml`\n  [aaaa29a8] Clustering v0.15.8\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.7.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.0 `~/.julia/dev/InvertedFiles`\n  [682c06a0] JSON v0.21.4\n  [23fbe1c1] Latexify v0.16.6\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\nâ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.11\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.0 `~/.julia/dev/SimSearchManifoldLearning`\n  [053f045d] SimilaritySearch v0.12.0 `~/.julia/dev/SimilaritySearch`\nâ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.0 `~/.julia/dev/TextSearch`\nInfo Packages marked with â and â have new versions available. Those with â may be upgradable, but those with â are restricted by compatibility constraints from upgrading. To see why use `status --outdated`"
  },
  {
    "objectID": "tutorials/solving-single-queries.html",
    "href": "tutorials/solving-single-queries.html",
    "title": "Solving single queries",
    "section": "",
    "text": "by: Eric S. TÃ©llez\nusing SimilaritySearch\nThis example shows how to perform single queries instead of solving a batch of them. This is particularly useful for some applications, and we also show how they are solved, which could be used to avoid some memory allocations.\ndim = 8\ndb = MatrixDatabase(randn(Float32, dim, 10^4))\nqueries = db = MatrixDatabase(randn(Float32, dim, 100))\ndist = SqL2Distance()\nG = SearchGraph(; dist, db)\nctx = SearchGraphContext()\nindex!(G, ctx)\nSuppose you want to compute some \\(k\\) nearest neighbors, for this we use the structure KnnResult which is a priority queue of maximum size \\(k\\).\nfor _ in 1:10\n    res = KnnResult(3)\n\n    @time search(G, ctx, randn(Float32, dim), res)\n    @show minimum(res), maximum(res), argmin(res), argmax(res)\n    @show collect(IdView(res))\n    @show collect(DistView(res))\nend\n\n  0.207479 seconds (118.20 k allocations: 7.439 MiB, 99.96% compilation time)\n(minimum(res), maximum(res), argmin(res), argmax(res)) = (2.17419f0, 3.781705f0, 0x00000042, 0x00000023)\ncollect(IdView(res)) = UInt32[0x00000042, 0x0000001c, 0x00000023]\ncollect(DistView(res)) = Float32[2.17419, 2.7570584, 3.781705]\n  0.000015 seconds (3 allocations: 160 bytes)\n(minimum(res), maximum(res), argmin(res), argmax(res)) = (2.9567637f0, 8.3428545f0, 0x00000009, 0x00000059)\ncollect(IdView(res)) = UInt32[0x00000009, 0x00000047, 0x00000059]\ncollect(DistView(res)) = Float32[2.9567637, 6.4577327, 8.3428545]\n  0.000006 seconds (3 allocations: 160 bytes)\n(minimum(res), maximum(res), argmin(res), argmax(res)) = (1.8161318f0, 2.363171f0, 0x00000051, 0x00000007)\ncollect(IdView(res)) = UInt32[0x00000051, 0x00000023, 0x00000007]\ncollect(DistView(res)) = Float32[1.8161318, 2.3379018, 2.363171]\n  0.000008 seconds (3 allocations: 160 bytes)\n(minimum(res), maximum(res), argmin(res), argmax(res)) = (1.8514413f0, 3.9120069f0, 0x00000003, 0x0000001f)\ncollect(IdView(res)) = UInt32[0x00000003, 0x0000003c, 0x0000001f]\ncollect(DistView(res)) = Float32[1.8514413, 3.377074, 3.9120069]\n  0.000004 seconds (3 allocations: 160 bytes)\n(minimum(res), maximum(res), argmin(res), argmax(res)) = (3.570466f0, 3.9146912f0, 0x0000002c, 0x00000064)\ncollect(IdView(res)) = UInt32[0x0000002c, 0x00000058, 0x00000064]\ncollect(DistView(res)) = Float32[3.570466, 3.8789546, 3.9146912]\n  0.000004 seconds (3 allocations: 160 bytes)\n(minimum(res), maximum(res), argmin(res), argmax(res)) = (2.2877853f0, 5.390996f0, 0x0000004f, 0x00000013)\ncollect(IdView(res)) = UInt32[0x0000004f, 0x0000003f, 0x00000013]\ncollect(DistView(res)) = Float32[2.2877853, 4.867247, 5.390996]\n  0.000004 seconds (3 allocations: 160 bytes)\n(minimum(res), maximum(res), argmin(res), argmax(res)) = (4.23781f0, 5.603115f0, 0x00000023, 0x00000032)\ncollect(IdView(res)) = UInt32[0x00000023, 0x0000004f, 0x00000032]\ncollect(DistView(res)) = Float32[4.23781, 5.4622717, 5.603115]\n  0.000004 seconds (3 allocations: 160 bytes)\n(minimum(res), maximum(res), argmin(res), argmax(res)) = (4.6007833f0, 5.5480776f0, 0x0000002a, 0x0000001b)\ncollect(IdView(res)) = UInt32[0x0000002a, 0x00000023, 0x0000001b]\ncollect(DistView(res)) = Float32[4.6007833, 5.0899153, 5.5480776]\n  0.000004 seconds (3 allocations: 160 bytes)\n(minimum(res), maximum(res), argmin(res), argmax(res)) = (4.8126698f0, 4.8592696f0, 0x00000024, 0x00000001)\ncollect(IdView(res)) = UInt32[0x00000024, 0x00000004, 0x00000001]\ncollect(DistView(res)) = Float32[4.8126698, 4.813215, 4.8592696]\n  0.000003 seconds (3 allocations: 160 bytes)\n(minimum(res), maximum(res), argmin(res), argmax(res)) = (2.365991f0, 4.04924f0, 0x0000002c, 0x00000020)\ncollect(IdView(res)) = UInt32[0x0000002c, 0x00000003, 0x00000020]\ncollect(DistView(res)) = Float32[2.365991, 3.51064, 4.04924]"
  },
  {
    "objectID": "tutorials/solving-single-queries.html#knnresult",
    "href": "tutorials/solving-single-queries.html#knnresult",
    "title": "Solving single queries",
    "section": "KnnResult",
    "text": "KnnResult\nThis structure is the container for the result and it is also used to specify the number of elements to retrieve. As mentioned before, it is a priority queue\n\n\nres = KnnResult(4)\npush_item!(res, 1, 10)\npush_item!(res, 2, 9)\npush_item!(res, 3, 8)\npush_item!(res, 4, 7)\npush_item!(res, 6, 5)\n@show res\n\n# it also supports removals\n@show :popfirst! =&gt; popfirst!(res)\npush_item!(res, 7, 0.1)\n@show :push_item! =&gt; res\n@show :pop! =&gt; pop!(res)\nres\n# It can be iterated\n\n@show collect(res)\n\nres = SimilaritySearch.KnnResult(SimilaritySearch.AdjacencyLists.IdWeight[SimilaritySearch.AdjacencyLists.IdWeight(0x00000006, 5.0f0), SimilaritySearch.AdjacencyLists.IdWeight(0x00000004, 7.0f0), SimilaritySearch.AdjacencyLists.IdWeight(0x00000003, 8.0f0), SimilaritySearch.AdjacencyLists.IdWeight(0x00000002, 9.0f0)], 4)\n:popfirst! =&gt; popfirst!(res) = :popfirst! =&gt; SimilaritySearch.AdjacencyLists.IdWeight(0x00000006, 5.0f0)\n:push_item! =&gt; res = :push_item! =&gt; SimilaritySearch.KnnResult(SimilaritySearch.AdjacencyLists.IdWeight[SimilaritySearch.AdjacencyLists.IdWeight(0x00000007, 0.1f0), SimilaritySearch.AdjacencyLists.IdWeight(0x00000004, 7.0f0), SimilaritySearch.AdjacencyLists.IdWeight(0x00000003, 8.0f0), SimilaritySearch.AdjacencyLists.IdWeight(0x00000002, 9.0f0)], 4)\n:pop! =&gt; pop!(res) = :pop! =&gt; SimilaritySearch.AdjacencyLists.IdWeight(0x00000002, 9.0f0)\ncollect(res) = SimilaritySearch.AdjacencyLists.IdWeight[SimilaritySearch.AdjacencyLists.IdWeight(0x00000007, 0.1f0), SimilaritySearch.AdjacencyLists.IdWeight(0x00000004, 7.0f0), SimilaritySearch.AdjacencyLists.IdWeight(0x00000003, 8.0f0)]\n\n\n3-element Vector{IdWeight}:\n IdWeight(0x00000007, 0.1f0)\n IdWeight(0x00000004, 7.0f0)\n IdWeight(0x00000003, 8.0f0)"
  },
  {
    "objectID": "tutorials/solving-single-queries.html#environment-and-dependencies",
    "href": "tutorials/solving-single-queries.html#environment-and-dependencies",
    "title": "Solving single queries",
    "section": "Environment and dependencies",
    "text": "Environment and dependencies\n\n\nJulia Version 1.10.9\nCommit 5595d20a287 (2025-03-10 12:51 UTC)\nBuild Info:\n  Official https://julialang.org/ release\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 64 Ã Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-15.0.7 (ORCJIT, cascadelake)\nThreads: 64 default, 0 interactive, 32 GC (on 64 virtual cores)\nEnvironment:\n  JULIA_PROJECT = .\n  JULIA_NUM_THREADS = auto\n  JULIA_LOAD_PATH = @:@stdlib\nStatus `~/sites/SimilaritySearchDemos/Project.toml`\n  [aaaa29a8] Clustering v0.15.8\n  [944b1d66] CodecZlib v0.7.8\n  [a93c6f00] DataFrames v1.7.0\n  [c5bfea45] Embeddings v0.4.6\n  [f67ccb44] HDF5 v0.17.2\n  [b20bd276] InvertedFiles v0.8.0 `~/.julia/dev/InvertedFiles`\n  [682c06a0] JSON v0.21.4\n  [23fbe1c1] Latexify v0.16.6\n  [eb30cadb] MLDatasets v0.7.18\n  [06eb3307] ManifoldLearning v0.9.0\nâ [ca7969ec] PlotlyLight v0.11.0\n  [91a5bcdd] Plots v1.40.11\n  [27ebfcd6] Primes v0.5.7\n  [ca7ab67e] SimSearchManifoldLearning v0.3.0 `~/.julia/dev/SimSearchManifoldLearning`\n  [053f045d] SimilaritySearch v0.12.0 `~/.julia/dev/SimilaritySearch`\nâ [2913bbd2] StatsBase v0.33.21\n  [f3b207a7] StatsPlots v0.15.7\n  [7f6f6c8a] TextSearch v0.19.0 `~/.julia/dev/TextSearch`\nInfo Packages marked with â and â have new versions available. Those with â may be upgradable, but those with â are restricted by compatibility constraints from upgrading. To see why use `status --outdated`"
  }
]